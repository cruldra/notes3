"use strict";(self.webpackChunknotes_3=self.webpackChunknotes_3||[]).push([[4174],{48382:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>i,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"AI/Pytorch/CUDA/\u7b80\u4ecb","title":"\u7b80\u4ecb","description":"torch.cuda \u662f PyTorch \u4e0e NVIDIA GPU \u8fdb\u884c\u4ea4\u4e92\u7684\u6838\u5fc3\u63a5\u53e3\u5305\u3002\u5b83\u4e0d\u4ec5\u5c01\u88c5\u4e86 CUDA Runtime API\uff0c\u8fd8\u5b9e\u73b0\u4e86\u4e00\u5957\u590d\u6742\u7684\u5185\u5b58\u7ba1\u7406\u673a\u5236 (Caching Allocator) \u548c\u5f02\u6b65\u6267\u884c\u6a21\u578b (Asynchronous Execution)\uff0c\u4ee5\u6700\u5927\u5316\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u7684\u541e\u5410\u91cf\u4e26\u964d\u4f4e CPU \u5f00\u9500\u3002","source":"@site/docs/AI/Pytorch/CUDA/\u7b80\u4ecb.md","sourceDirName":"AI/Pytorch/CUDA","slug":"/AI/Pytorch/CUDA/\u7b80\u4ecb","permalink":"/notes3/docs/AI/Pytorch/CUDA/\u7b80\u4ecb","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/Pytorch/CUDA/\u7b80\u4ecb.md","tags":[],"version":"current","frontMatter":{},"sidebar":"ai","previous":{"title":"Linear","permalink":"/notes3/docs/AI/Pytorch/\u795e\u7ecf\u7f51\u7edc/Linear"},"next":{"title":"\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6","permalink":"/notes3/docs/AI/Pytorch/CUDA/\u81ea\u52a8\u6df7\u5408\u7cbe\u5ea6"}}');var c=r(23420),t=r(54213);const l={},o=void 0,i={},a=[{value:"2. \u5185\u5b58\u7ba1\u7406\u673a\u5236 (Memory Management)",id:"2-\u5185\u5b58\u7ba1\u7406\u673a\u5236-memory-management",level:2},{value:"2.1 Caching Allocator \u67b6\u6784",id:"21-caching-allocator-\u67b6\u6784",level:3},{value:"\u6838\u5fc3\u7ec4\u4ef6",id:"\u6838\u5fc3\u7ec4\u4ef6",level:4},{value:"2.2 \u5185\u5b58\u72b6\u6001\u4e0e\u76d1\u63a7",id:"22-\u5185\u5b58\u72b6\u6001\u4e0e\u76d1\u63a7",level:3},{value:"3. \u5f02\u6b65\u6267\u884c\u6a21\u578b (Asynchronous Execution)",id:"3-\u5f02\u6b65\u6267\u884c\u6a21\u578b-asynchronous-execution",level:2},{value:"3.1 Streams (\u6d41)",id:"31-streams-\u6d41",level:3},{value:"3.2 Events (\u4e8b\u4ef6)",id:"32-events-\u4e8b\u4ef6",level:3},{value:"4. \u9ad8\u7ea7\u6027\u80fd\u4f18\u5316 (Advanced Optimization)",id:"4-\u9ad8\u7ea7\u6027\u80fd\u4f18\u5316-advanced-optimization",level:2},{value:"4.1 Pinned Memory (\u9875\u9501\u5b9a\u5185\u5b58)",id:"41-pinned-memory-\u9875\u9501\u5b9a\u5185\u5b58",level:3},{value:"4.2 CUDA Graphs",id:"42-cuda-graphs",level:3},{value:"5. \u8c03\u8bd5\u4e0e\u73af\u5883\u53d8\u91cf (Debugging)",id:"5-\u8c03\u8bd5\u4e0e\u73af\u5883\u53d8\u91cf-debugging",level:2},{value:"6. \u53c2\u8003\u8d44\u6599 (References)",id:"6-\u53c2\u8003\u8d44\u6599-references",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,c.jsxs)(c.Fragment,{children:[(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.code,{children:"torch.cuda"})," \u662f PyTorch \u4e0e NVIDIA GPU \u8fdb\u884c\u4ea4\u4e92\u7684\u6838\u5fc3\u63a5\u53e3\u5305\u3002\u5b83\u4e0d\u4ec5\u5c01\u88c5\u4e86 CUDA Runtime API\uff0c\u8fd8\u5b9e\u73b0\u4e86\u4e00\u5957\u590d\u6742\u7684",(0,c.jsx)(n.strong,{children:"\u5185\u5b58\u7ba1\u7406\u673a\u5236 (Caching Allocator)"})," \u548c",(0,c.jsx)(n.strong,{children:"\u5f02\u6b65\u6267\u884c\u6a21\u578b (Asynchronous Execution)"}),"\uff0c\u4ee5\u6700\u5927\u5316\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u7684\u541e\u5410\u91cf\u4e26\u964d\u4f4e CPU \u5f00\u9500\u3002"]}),"\n",(0,c.jsxs)(n.p,{children:["\u7406\u89e3 ",(0,c.jsx)(n.code,{children:"torch.cuda"})," \u7684\u5e95\u5c42\u539f\u7406\u5bf9\u4e8e\u89e3\u51b3 Out Of Memory (OOM) \u9519\u8bef\u3001\u4f18\u5316\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\u4ee5\u53ca\u8fdb\u884c\u9ad8\u6027\u80fd\u7b97\u5b50\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u3002"]}),"\n",(0,c.jsx)(n.h2,{id:"2-\u5185\u5b58\u7ba1\u7406\u673a\u5236-memory-management",children:"2. \u5185\u5b58\u7ba1\u7406\u673a\u5236 (Memory Management)"}),"\n",(0,c.jsxs)(n.p,{children:["PyTorch \u5e76\u4e0d\u76f4\u63a5\u5bf9\u6bcf\u4e00\u6b21 Tensor \u5206\u914d\u90fd\u8c03\u7528 CUDA \u539f\u751f\u7684 ",(0,c.jsx)(n.code,{children:"cudaMalloc"})," \u548c ",(0,c.jsx)(n.code,{children:"cudaFree"}),"\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u7cfb\u7edf\u8c03\u7528\uff08System Calls\uff09\u4f1a\u5bfc\u81f4\u8bbe\u5907\u540c\u6b65\uff08Device Synchronization\uff09\uff0c\u4ece\u800c\u663e\u8457\u963b\u585e CPU \u7ebf\u7a0b\uff0c\u7834\u574f\u6d41\u6c34\u7ebf\u5e76\u884c\u3002"]}),"\n",(0,c.jsx)(n.h3,{id:"21-caching-allocator-\u67b6\u6784",children:"2.1 Caching Allocator \u67b6\u6784"}),"\n",(0,c.jsxs)(n.p,{children:["PyTorch \u5b9e\u73b0\u4e86\u4e00\u4e2a ",(0,c.jsx)(n.strong,{children:"Caching Allocator"}),"\uff08\u7f13\u5b58\u5206\u914d\u5668\uff09\uff0c\u5176\u6838\u5fc3\u7b56\u7565\u662f\uff1a",(0,c.jsx)(n.strong,{children:"\u5411 CUDA \u7533\u8bf7\u5927\u5757\u5185\u5b58\uff0c\u7136\u540e\u5728\u5185\u90e8\u8fdb\u884c\u5207\u5206\u7ba1\u7406\uff0c\u91ca\u653e\u65f6\u5f52\u8fd8\u7ed9\u7f13\u5b58\u800c\u975e\u64cd\u4f5c\u7cfb\u7edf"}),"\u3002"]}),"\n",(0,c.jsx)(n.h4,{id:"\u6838\u5fc3\u7ec4\u4ef6",children:"\u6838\u5fc3\u7ec4\u4ef6"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Block"}),": \u5185\u5b58\u5757\u7684\u57fa\u672c\u5355\u4f4d\uff0c\u5305\u542b\u5143\u6570\u636e\uff08\u5927\u5c0f\u3001\u662f\u5426\u7a7a\u95f2\u3001\u6240\u5c5e Stream\uff09\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Pools"}),":","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Small Pool"}),": \u7ba1\u7406\u5c0f\u4e8e 1MB \u7684 allocations\u3002\u901a\u5e38\u5206\u914d 2MB \u7684 Page\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Large Pool"}),": \u7ba1\u7406\u5927\u4e8e 1MB \u7684 allocations\u3002\u901a\u5e38\u5206\u914d 20MB \u7684 Page\u3002"]}),"\n"]}),"\n"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Split & Merge"}),": \u5206\u914d\u5668\u4f1a\u5c1d\u8bd5\u5c06\u5927 Block \u5207\u5206\u4e3a\u5c0f Block \u4ee5\u6ee1\u8db3\u8bf7\u6c42\uff1b\u91ca\u653e\u65f6\u4f1a\u5c1d\u8bd5\u5408\u5e76\u76f8\u90bb\u7684\u7a7a\u95f2 Block \u4ee5\u51cf\u5c11\u788e\u7247\u3002"]}),"\n"]}),"\n",(0,c.jsx)(n.mermaid,{value:"flowchart TD\n    Req[Tensor Allocation Request] --\x3e CheckCache{Check Cache Pools}\n    \n    CheckCache -- Hit (Found Free Block) --\x3e Split[Split Block if too large]\n    Split --\x3e ReturnPtr[Return Pointer]\n    \n    CheckCache -- Miss --\x3e SysAlloc[Call cudaMalloc]\n    SysAlloc -- Success --\x3e AddPool[Add to Pool]\n    AddPool --\x3e ReturnPtr\n    \n    SysAlloc -- OOM --\x3e TryFree[Try Free Unused Cached Blocks]\n    TryFree --\x3e SysAllocRetry[Retry cudaMalloc]\n    SysAllocRetry -- OOM --\x3e Error[Raise RuntimeError: CUDA out of memory]"}),"\n",(0,c.jsx)(n.h3,{id:"22-\u5185\u5b58\u72b6\u6001\u4e0e\u76d1\u63a7",children:"2.2 \u5185\u5b58\u72b6\u6001\u4e0e\u76d1\u63a7"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Allocated Memory"}),": \u5b9e\u9645\u88ab Tensor \u5360\u7528\u7684\u5185\u5b58\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Reserved Memory"}),": PyTorch \u4ece CUDA \u7533\u8bf7\u5e76\u7f13\u5b58\u7684\u603b\u5185\u5b58\uff08\u5305\u542b Allocated \u548c\u672a\u88ab\u4f7f\u7528\u7684 Cached Memory\uff09\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Fragmentation"}),": \u5f53 Reserved \u8fdc\u5927\u4e8e Allocated \u4f46\u4ecd\u53d1\u751f OOM \u65f6\uff0c\u901a\u5e38\u662f\u56e0\u4e3a\u5185\u5b58\u788e\u7247\u5316\uff08Memory Fragmentation\uff09\u3002"]}),"\n"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-python",children:"import torch\n\n# \u6253\u5370\u5185\u5b58\u7edf\u8ba1\u6458\u8981\nprint(torch.cuda.memory_summary())\n\n# \u91ca\u653e\u672a\u4f7f\u7528\u7684\u7f13\u5b58\uff08\u4e0d\u63a8\u8350\u9891\u7e41\u8c03\u7528\uff0c\u4f1a\u589e\u52a0\u540e\u7eed\u5206\u914d\u5f00\u9500\uff09\ntorch.cuda.empty_cache()\n"})}),"\n",(0,c.jsx)(n.h2,{id:"3-\u5f02\u6b65\u6267\u884c\u6a21\u578b-asynchronous-execution",children:"3. \u5f02\u6b65\u6267\u884c\u6a21\u578b (Asynchronous Execution)"}),"\n",(0,c.jsxs)(n.p,{children:["\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cPyTorch \u7684 CUDA \u64cd\u4f5c\u662f\u5f02\u6b65\u7684\u3002\u5f53 CPU \u53d1\u8d77\u4e00\u4e2a GPU Kernel \u8c03\u7528\u65f6\uff0c\u5b83\u53ea\u662f\u5c06\u547d\u4ee4\u653e\u5165 ",(0,c.jsx)(n.strong,{children:"Command Queue"}),"\uff08\u547d\u4ee4\u961f\u5217\uff09\u540e\u7acb\u5373\u8fd4\u56de\uff0c\u800c\u4e0d\u4f1a\u7b49\u5f85 GPU \u6267\u884c\u5b8c\u6bd5\u3002"]}),"\n",(0,c.jsx)(n.h3,{id:"31-streams-\u6d41",children:"3.1 Streams (\u6d41)"}),"\n",(0,c.jsx)(n.p,{children:"Stream \u662f GPU \u4e0a\u6267\u884c\u5e8f\u5217\u7684\u62bd\u8c61\u3002"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Default Stream (Stream 0)"}),": \u9ed8\u8ba4\u4f7f\u7528\u7684\u6d41\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Non-default Streams"}),": \u7528\u6237\u521b\u5efa\u7684\u6d41\uff0c\u652f\u6301\u5e76\u53d1\u6267\u884c\u3002"]}),"\n"]}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.strong,{children:"\u5e76\u53d1\u539f\u7406"}),"\uff1a\u4e0d\u540c Stream \u4e2d\u7684 Kernel \u53ef\u4ee5\u5e76\u884c\u6267\u884c\uff08\u53d7\u9650\u4e8e GPU \u786c\u4ef6\u8d44\u6e90\uff09\uff0c\u4ece\u800c\u5b9e\u73b0 Compute-Compute Overlap \u6216 Copy-Compute Overlap\u3002"]}),"\n",(0,c.jsx)(n.mermaid,{value:"gantt\n    dateFormat  s\n    axisFormat  %S\n    title Multi-Stream Execution\n    \n    section Default Stream\n    Kernel A       :a1, 0, 3\n    Kernel B       :a2, 3, 5\n    \n    section Stream 1\n    Data Transfer  :b1, 0, 2\n    Kernel C       :b2, 2, 4"}),"\n",(0,c.jsx)(n.h3,{id:"32-events-\u4e8b\u4ef6",children:"3.2 Events (\u4e8b\u4ef6)"}),"\n",(0,c.jsx)(n.p,{children:"Event \u662f\u7528\u4e8e Stream \u95f4\u540c\u6b65\u7684\u8f7b\u91cf\u7ea7\u6807\u8bb0\u3002"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Record"}),": \u5728 Stream \u4e2d\u8bb0\u5f55\u4e00\u4e2a\u65f6\u95f4\u70b9\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Wait"}),": \u8ba9\u53e6\u4e00\u4e2a Stream \u7b49\u5f85\u8be5 Event \u5b8c\u6210\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"Synchronize"}),": \u963b\u585e CPU \u76f4\u5230 Event \u5b8c\u6210\u3002"]}),"\n"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-python",children:"s1 = torch.cuda.Stream()\ns2 = torch.cuda.Stream()\n\n# \u5728 s1 \u4e0a\u6267\u884c\u64cd\u4f5c\nwith torch.cuda.stream(s1):\n    A = torch.matmul(X, W)\n\n# \u540c\u6b65\u673a\u5236\uff1a\u786e\u4fdd s2 \u4f7f\u7528 A \u4e4b\u524d\uff0cs1 \u5df2\u7ecf\u8ba1\u7b97\u5b8c\u6bd5\nevent = torch.cuda.Event()\ns1.record_event(event)\ns2.wait_event(event)  # s2 \u5c06\u963b\u585e\u76f4\u5230 event \u88ab\u8bb0\u5f55\n\nwith torch.cuda.stream(s2):\n    B = A + 1\n"})}),"\n",(0,c.jsx)(n.h2,{id:"4-\u9ad8\u7ea7\u6027\u80fd\u4f18\u5316-advanced-optimization",children:"4. \u9ad8\u7ea7\u6027\u80fd\u4f18\u5316 (Advanced Optimization)"}),"\n",(0,c.jsx)(n.h3,{id:"41-pinned-memory-\u9875\u9501\u5b9a\u5185\u5b58",children:"4.1 Pinned Memory (\u9875\u9501\u5b9a\u5185\u5b58)"}),"\n",(0,c.jsx)(n.p,{children:"\u4e3b\u673a\uff08CPU\uff09\u5185\u5b58\u9ed8\u8ba4\u662f\u5206\u9875\u7684\uff08Pageable\uff09\u3002GPU \u65e0\u6cd5\u76f4\u63a5\u901a\u8fc7 DMA \u8bbf\u95ee\u5206\u9875\u5185\u5b58\u3002"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"\u673a\u5236"}),"\uff1a",(0,c.jsx)(n.code,{children:"pin_memory()"})," \u5c06 Tensor \u9501\u5b9a\u5728\u7269\u7406\u5185\u5b58\u4e2d\uff0c\u9632\u6b62\u88ab\u6362\u51fa\uff08Swap out\uff09\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"\u4f18\u52bf"}),"\uff1a\u542f\u7528 ",(0,c.jsx)(n.code,{children:"pin_memory=True"})," \u548c ",(0,c.jsx)(n.code,{children:"non_blocking=True"})," \u53ef\u4ee5\u5b9e\u73b0 ",(0,c.jsx)(n.strong,{children:"Host-to-Device \u4f20\u8f93\u4e0e GPU \u8ba1\u7b97\u7684\u91cd\u53e0"}),"\u3002"]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"42-cuda-graphs",children:"4.2 CUDA Graphs"}),"\n",(0,c.jsx)(n.p,{children:"\u9488\u5bf9 CPU-Bound \u573a\u666f\uff08\u5982\u5c0f Batch Size \u6216\u5927\u91cf\u5fae\u5c0f\u7b97\u5b50\uff09\uff0c\u542f\u52a8 Kernel \u7684 CPU \u5f00\u9500\uff08Launch Overhead\uff09\u53ef\u80fd\u8d85\u8fc7 Kernel \u6267\u884c\u65f6\u95f4\u3002"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"\u673a\u5236"}),"\uff1a",(0,c.jsx)(n.strong,{children:"CUDA Graphs"})," \u5c06\u4e00\u7cfb\u5217 Kernel Capture \u6210\u4e00\u4e2a\u9759\u6001\u56fe\uff0c\u901a\u8fc7\u5355\u6b21 API \u8c03\u7528\u53d1\u5c04\u6574\u4e2a\u56fe\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"\u9650\u5236"}),"\uff1a\u4e0d\u652f\u6301\u52a8\u6001\u63a7\u5236\u6d41\uff08Dynamic Control Flow\uff09\u548c\u52a8\u6001\u5f62\u72b6\uff08Dynamic Shapes\uff09\u3002"]}),"\n"]}),"\n",(0,c.jsx)(n.pre,{children:(0,c.jsx)(n.code,{className:"language-python",children:"# CUDA Graph \u793a\u4f8b\ng = torch.cuda.CUDAGraph()\n# Warmup\nstatic_input = torch.randn(10, device='cuda')\ns = torch.cuda.Stream()\ns.wait_stream(torch.cuda.current_stream())\nwith torch.cuda.stream(s):\n    for _ in range(3):\n        static_output = static_input * 2\ntorch.cuda.current_stream().wait_stream(s)\n\n# Capture\nwith torch.cuda.graph(g):\n    static_output = static_input * 2\n\n# Replay\nstatic_input.copy_(real_input)\ng.replay()\n"})}),"\n",(0,c.jsx)(n.h2,{id:"5-\u8c03\u8bd5\u4e0e\u73af\u5883\u53d8\u91cf-debugging",children:"5. \u8c03\u8bd5\u4e0e\u73af\u5883\u53d8\u91cf (Debugging)"}),"\n",(0,c.jsx)(n.p,{children:"PyTorch \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u73af\u5883\u53d8\u91cf\u7528\u4e8e\u8c03\u8bd5 CUDA \u884c\u4e3a\uff1a"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"CUDA_LAUNCH_BLOCKING=1"}),": \u5f3a\u5236\u540c\u6b65\u6267\u884c\uff0c\u4f7f\u62a5\u9519\u5806\u6808\u6307\u5411\u89e6\u53d1\u9519\u8bef\u7684\u5177\u4f53\u4ee3\u7801\u884c\uff08\u751f\u4ea7\u73af\u5883\u7981\u7528\uff09\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"PYTORCH_CUDA_ALLOC_CONF"}),": \u8c03\u6574\u5206\u914d\u5668\u884c\u4e3a\u3002","\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"max_split_size_mb"}),": \u9650\u5236\u6700\u5927\u5207\u5206\u5757\u5927\u5c0f\uff0c\u51cf\u5c11\u788e\u7247\u3002"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"garbage_collection_threshold"}),": \u8bbe\u7f6e\u5783\u573e\u56de\u6536\u9608\u503c\u3002"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,c.jsx)(n.h2,{id:"6-\u53c2\u8003\u8d44\u6599-references",children:"6. \u53c2\u8003\u8d44\u6599 (References)"}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"PyTorch Documentation: CUDA Semantics"}),". ",(0,c.jsx)(n.a,{href:"https://pytorch.org/docs/stable/notes/cuda.html",children:"https://pytorch.org/docs/stable/notes/cuda.html"})]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"A Guide to PyTorch\u2019s CUDA Caching Allocator"}),". ",(0,c.jsx)(n.a,{href:"https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html",children:"https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html"})]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.strong,{children:"NVIDIA Developer Blog: CUDA Graphs"}),". ",(0,c.jsx)(n.a,{href:"https://developer.nvidia.com/blog/cuda-graphs/",children:"https://developer.nvidia.com/blog/cuda-graphs/"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,c.jsx)(n,{...e,children:(0,c.jsx)(d,{...e})}):d(e)}},54213:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>o});var s=r(36672);const c={},t=s.createContext(c);function l(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(c):e.components||c:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);