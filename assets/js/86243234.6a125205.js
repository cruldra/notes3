"use strict";(self.webpackChunknotes_3=self.webpackChunknotes_3||[]).push([[28629],{54213:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>d});var r=n(36672);const o={},i=r.createContext(o);function s(e){const t=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),r.createElement(i.Provider,{value:t},e.children)}},91378:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>d,default:()=>u,frontMatter:()=>s,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"AI/\u63d0\u793a\u8bcd\u5de5\u7a0b/DSPy/API/\u4f18\u5316\u5668/BootstrapFinetune","title":"BootstrapFinetune","description":"dspy.BootstrapFinetune(metric bool = True, trainkwargs Adapter | dict[LM, Adapter] | None = None, excludedemos int | None = None) [\xb6","source":"@site/docs/AI/\u63d0\u793a\u8bcd\u5de5\u7a0b/DSPy/API/\u4f18\u5316\u5668/BootstrapFinetune.md","sourceDirName":"AI/\u63d0\u793a\u8bcd\u5de5\u7a0b/DSPy/API/\u4f18\u5316\u5668","slug":"/AI/\u63d0\u793a\u8bcd\u5de5\u7a0b/DSPy/API/\u4f18\u5316\u5668/BootstrapFinetune","permalink":"/notes3/docs/AI/\u63d0\u793a\u8bcd\u5de5\u7a0b/DSPy/API/\u4f18\u5316\u5668/BootstrapFinetune","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/\u63d0\u793a\u8bcd\u5de5\u7a0b/DSPy/API/\u4f18\u5316\u5668/BootstrapFinetune.md","tags":[],"version":"current","frontMatter":{},"sidebar":"ai","previous":{"title":"BootstrapFewShot","permalink":"/notes3/docs/AI/\u63d0\u793a\u8bcd\u5de5\u7a0b/DSPy/API/\u4f18\u5316\u5668/BootstrapFewShot"},"next":{"title":"GEPA","permalink":"/notes3/docs/AI/\u63d0\u793a\u8bcd\u5de5\u7a0b/DSPy/API/\u4f18\u5316\u5668/GEPA"}}');var o=n(23420),i=n(54213);const s={},d=void 0,a={},l=[{value:"<code>dspy.BootstrapFinetune(metric: Callable | None = None, multitask: bool = True, train_kwargs: dict[str, Any] | dict[LM, dict[str, Any]] | None = None, adapter: Adapter | dict[LM, Adapter] | None = None, exclude_demos: bool = False, num_threads: int | None = None)</code> \xb6",id:"dspybootstrapfinetunemetric-callable--none--none-multitask-bool--true-train_kwargs-dictstr-any--dictlm-dictstr-any--none--none-adapter-adapter--dictlm-adapter--none--none-exclude_demos-bool--false-num_threads-int--none--none-",level:2},{value:"Functions\xb6",id:"functions",level:3},{value:"<code>compile(student: Module, trainset: list[Example], teacher: Module | list[Module] | None = None) -&gt; Module</code> \xb6",id:"compilestudent-module-trainset-listexample-teacher-module--listmodule--none--none---module-",level:4},{value:"<code>convert_to_lm_dict(arg) -&gt; dict[LM, Any]</code> <code>staticmethod</code> \xb6",id:"convert_to_lm_dictarg---dictlm-any-staticmethod-",level:4},{value:"<code>finetune_lms(finetune_dict) -&gt; dict[Any, LM]</code> <code>staticmethod</code> \xb6",id:"finetune_lmsfinetune_dict---dictany-lm-staticmethod-",level:4},{value:"<code>get_params() -&gt; dict[str, Any]</code> \xb6",id:"get_params---dictstr-any-",level:4}];function c(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(t.h2,{id:"dspybootstrapfinetunemetric-callable--none--none-multitask-bool--true-train_kwargs-dictstr-any--dictlm-dictstr-any--none--none-adapter-adapter--dictlm-adapter--none--none-exclude_demos-bool--false-num_threads-int--none--none-",children:[(0,o.jsx)(t.code,{children:"dspy.BootstrapFinetune(metric: Callable | None = None, multitask: bool = True, train_kwargs: dict[str, Any] | dict[LM, dict[str, Any]] | None = None, adapter: Adapter | dict[LM, Adapter] | None = None, exclude_demos: bool = False, num_threads: int | None = None)"})," ",(0,o.jsx)(t.a,{href:"#dspy.BootstrapFinetune",title:"Permanent link",children:"\xb6"})]}),"\n",(0,o.jsxs)(t.p,{children:["Bases: ",(0,o.jsx)(t.code,{children:"FinetuneTeleprompter"})]}),"\n",(0,o.jsxs)(t.p,{children:["Source code in ",(0,o.jsx)(t.code,{children:"dspy/teleprompt/bootstrap_finetune.py"})]}),"\n",(0,o.jsxs)(t.table,{children:[(0,o.jsx)(t.thead,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.th,{}),(0,o.jsx)(t.th,{})]})}),(0,o.jsx)(t.tbody,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58"})}),(0,o.jsxs)(t.td,{children:["``` def ",(0,o.jsx)(t.strong,{children:"init"}),"(     self,     metric: Callable"]})]})})]}),"\n",(0,o.jsxs)(t.h3,{id:"functions",children:["Functions",(0,o.jsx)(t.a,{href:"#dspy.BootstrapFinetune-functions",title:"Permanent link",children:"\xb6"})]}),"\n",(0,o.jsxs)(t.h4,{id:"compilestudent-module-trainset-listexample-teacher-module--listmodule--none--none---module-",children:[(0,o.jsx)(t.code,{children:"compile(student: Module, trainset: list[Example], teacher: Module | list[Module] | None = None) -> Module"})," ",(0,o.jsx)(t.a,{href:"#dspy.BootstrapFinetune.compile",title:"Permanent link",children:"\xb6"})]}),"\n",(0,o.jsxs)(t.p,{children:["Source code in ",(0,o.jsx)(t.code,{children:"dspy/teleprompt/bootstrap_finetune.py"})]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'def compile(\r\n    self, student: Module, trainset: list[Example], teacher: Module | list[Module] | None = None\r\n) -> Module:\r\n    # TODO: Print statements can be converted to logger.info if we ensure\r\n    # that the default DSPy logger logs info level messages in notebook\r\n    # environments.\r\n    logger.info("Preparing the student and teacher programs...")\r\n    all_predictors_have_lms(student)\r\n\r\n    logger.info("Bootstrapping data...")\r\n    trace_data = []\r\n\r\n    teachers = teacher if isinstance(teacher, list) else [teacher]\r\n    teachers = [prepare_teacher(student, t) for t in teachers]\r\n    num_threads = self.num_threads or dspy.settings.num_threads\r\n    for t in teachers:\r\n        trace_data += bootstrap_trace_data(program=t, dataset=trainset, metric=self.metric, num_threads=num_threads)\r\n\r\n    logger.info("Preparing the train data...")\r\n    key_to_data = {}\r\n    for pred_ind, pred in enumerate(student.predictors()):\r\n        data_pred_ind = None if self.multitask else pred_ind\r\n        if pred.lm is None:\r\n            raise ValueError(\r\n                f"Predictor {pred_ind} does not have an LM assigned. "\r\n                f"Please ensure the module\'s predictors have their LM set before fine-tuning. "\r\n                f"You can set it using: your_module.set_lm(your_lm)"\r\n            )\r\n        training_key = (pred.lm, data_pred_ind)\r\n\r\n        if training_key not in key_to_data:\r\n            train_data, data_format = self._prepare_finetune_data(\r\n                trace_data=trace_data, lm=pred.lm, pred_ind=data_pred_ind\r\n            )\r\n            logger.info(f"Using {len(train_data)} data points for fine-tuning the model: {pred.lm.model}")\r\n            finetune_kwargs = {\r\n                "lm": pred.lm,\r\n                "train_data": train_data,\r\n                "train_data_format": data_format,\r\n                "train_kwargs": self.train_kwargs[pred.lm],\r\n            }\r\n            key_to_data[training_key] = finetune_kwargs\r\n\r\n    logger.info("Starting LM fine-tuning...")\r\n    # TODO(feature): We could run batches of fine-tuning jobs in sequence\r\n    # to avoid exceeding the number of threads.\r\n    if len(key_to_data) > num_threads:\r\n        raise ValueError(\r\n            "BootstrapFinetune requires `num_threads` to be bigger than or equal to the number of fine-tuning "\r\n            f"jobs. There are {len(key_to_data)} fine-tuning jobs to start, but the number of threads is: "\r\n            f"{num_threads}! If the `multitask` flag is set to False, the number of fine-tuning jobs will "\r\n            "be equal to the number of predictors in the student program. If the `multitask` flag is set to True, "\r\n            "the number of fine-tuning jobs will be equal to: 1 if there is only a context LM, or the number of "\r\n            "unique LMs attached to the predictors in the student program. In any case, the number of fine-tuning "\r\n            "jobs will be less than or equal to the number of predictors."\r\n        )\r\n    logger.info(f"{len(key_to_data)} fine-tuning job(s) to start")\r\n    key_to_lm = self.finetune_lms(key_to_data)\r\n\r\n    logger.info("Updating the student program with the fine-tuned LMs...")\r\n    for pred_ind, pred in enumerate(student.predictors()):\r\n        data_pred_ind = None if self.multitask else pred_ind\r\n        training_key = (pred.lm, data_pred_ind)\r\n        finetuned_lm = key_to_lm[training_key]\r\n        if isinstance(finetuned_lm, Exception):\r\n            raise RuntimeError(f"Finetuned LM for predictor {pred_ind} failed.") from finetuned_lm\r\n        pred.lm = finetuned_lm\r\n        # TODO: What should the correct behavior be here? Should\r\n        # BootstrapFinetune modify the prompt demos according to the\r\n        # train data?\r\n        pred.demos = [] if self.exclude_demos else pred.demos\r\n\r\n    logger.info("BootstrapFinetune has finished compiling the student program")\r\n    student._compiled = True\r\n    return student\n'})}),"\n",(0,o.jsxs)(t.h4,{id:"convert_to_lm_dictarg---dictlm-any-staticmethod-",children:[(0,o.jsx)(t.code,{children:"convert_to_lm_dict(arg) -> dict[LM, Any]"})," ",(0,o.jsx)(t.code,{children:"staticmethod"})," ",(0,o.jsx)(t.a,{href:"#dspy.BootstrapFinetune.convert_to_lm_dict",title:"Permanent link",children:"\xb6"})]}),"\n",(0,o.jsxs)(t.p,{children:["Source code in ",(0,o.jsx)(t.code,{children:"dspy/teleprompt/bootstrap_finetune.py"})]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:"@staticmethod\r\ndef convert_to_lm_dict(arg) -> dict[LM, Any]:\r\n    non_empty_dict = arg and isinstance(arg, dict)\r\n    if non_empty_dict and all(isinstance(k, LM) for k in arg.keys()):\r\n        return arg\r\n    # Default to using the same value for all LMs\r\n    return defaultdict(lambda: arg)\n"})}),"\n",(0,o.jsxs)(t.h4,{id:"finetune_lmsfinetune_dict---dictany-lm-staticmethod-",children:[(0,o.jsx)(t.code,{children:"finetune_lms(finetune_dict) -> dict[Any, LM]"})," ",(0,o.jsx)(t.code,{children:"staticmethod"})," ",(0,o.jsx)(t.a,{href:"#dspy.BootstrapFinetune.finetune_lms",title:"Permanent link",children:"\xb6"})]}),"\n",(0,o.jsxs)(t.p,{children:["Source code in ",(0,o.jsx)(t.code,{children:"dspy/teleprompt/bootstrap_finetune.py"})]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'@staticmethod\r\ndef finetune_lms(finetune_dict) -> dict[Any, LM]:\r\n    num_jobs = len(finetune_dict)\r\n    logger.info(f"Starting {num_jobs} fine-tuning job(s)...")\r\n    # TODO(nit) Pass an identifier to the job so that we can tell the logs\r\n    # coming from different fine-tune threads.\r\n\r\n    key_to_job = {}\r\n    for key, finetune_kwargs in finetune_dict.items():\r\n        lm: LM = finetune_kwargs.pop("lm")\r\n        # TODO: The following line is a hack. We should re-think how to free\r\n        # up resources for fine-tuning. This might mean introducing a new\r\n        # provider method (e.g. prepare_for_finetune) that can be called\r\n        # before fine-tuning is started.\r\n        logger.info(\r\n            "Calling lm.kill() on the LM to be fine-tuned to free up resources. This won\'t have any effect if the "\r\n            "LM is not running."\r\n        )\r\n        lm.kill()\r\n        key_to_job[key] = lm.finetune(**finetune_kwargs)\r\n\r\n    key_to_lm = {}\r\n    for ind, (key, job) in enumerate(key_to_job.items()):\r\n        result = job.result()\r\n        if isinstance(result, Exception):\r\n            raise result\r\n        key_to_lm[key] = result\r\n        job.thread.join()\r\n        logger.info(f"Job {ind + 1}/{num_jobs} is done")\r\n\r\n    return key_to_lm\n'})}),"\n",(0,o.jsxs)(t.h4,{id:"get_params---dictstr-any-",children:[(0,o.jsx)(t.code,{children:"get_params() -> dict[str, Any]"})," ",(0,o.jsx)(t.a,{href:"#dspy.BootstrapFinetune.get_params",title:"Permanent link",children:"\xb6"})]}),"\n",(0,o.jsx)(t.p,{children:"Get the parameters of the teleprompter."}),"\n",(0,o.jsx)(t.p,{children:"Returns:"}),"\n",(0,o.jsxs)(t.table,{children:[(0,o.jsx)(t.thead,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.th,{children:"Type"}),(0,o.jsx)(t.th,{children:"Description"})]})}),(0,o.jsx)(t.tbody,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"dict[str, Any]"})}),(0,o.jsx)(t.td,{children:"The parameters of the teleprompter."})]})})]}),"\n",(0,o.jsxs)(t.p,{children:["Source code in ",(0,o.jsx)(t.code,{children:"dspy/teleprompt/teleprompt.py"})]}),"\n",(0,o.jsxs)(t.table,{children:[(0,o.jsx)(t.thead,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.th,{}),(0,o.jsx)(t.th,{})]})}),(0,o.jsx)(t.tbody,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"25 26 27 28 29 30 31 32"})}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:'def get_params(self) -> dict[str, Any]:     """     Get the parameters of the teleprompter.      Returns:         The parameters of the teleprompter.     """     return self.__dict__ '})})]})})]})]})}function u(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);