数据湖位于**L4 数据服务层**，是整个云端平台（L3）的基石，负责汇聚从边缘端（L2）上传的海量异构数据，并为上层的数智主管（推理）、组织记忆（知识库）和业务应用（报表）提供数据支撑。

---

### 一、 数据湖分层架构设计
为应对非结构化视频数据与结构化传感数据的混合存储需求，采用**ODS-DWD-DWS-ADS**四层架构设计。

| 层级 | 名称 | 核心职责 | 数据类型 | 存储周期 | 技术载体 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **ODS** | **原始数据层** | 接收边缘端上传的原始数据，不做处理 | H.264/H.265视频流、原始JPEG截图、传感器原始JSON、系统日志 | 7天 (热数据) | MinIO (SSD)<br />Kafka |
| **DWD** | **明细数据层** | 数据清洗、去重、格式转换、结构化 | 清洗后的图像、结构化的传感器数值、标准化的告警事件记录 | 90天 (温数据) | MinIO (HDD)<br />PostgreSQL |
| **DWS** | **汇总数据层** | 按主题进行聚合、统计、特征提取 | 小时级告警统计、设备健康度日报、风险分析周报 | 1年 (冷数据) | PostgreSQL<br />InfluxDB |
| **ADS** | **应用数据层** | 面向业务应用的数据组织，提供API查询 | 大屏展示数据、报表数据、API接口缓存 | 永久 (归档) | Redis<br />PostgreSQL |

---

### 二、 核心技术选型
数据湖采用**混合存储技术栈**以平衡性能与成本,。

#### 1. 存储组件
*   **对象存储 (Object Storage): MinIO**
    *   **用途**：存储非结构化数据，包括告警视频切片（前后30秒）、关键帧截图、完整的“证据包”文件。
    *   **选型理由**：兼容S3协议，高性能，适合海量小文件存储。
*   **关系型数据库 (RDBMS): PostgreSQL 15**
    *   **用途**：存储告警元数据（时间、地点、类型）、设备台账、工单记录、用户信息。
    *   **选型理由**：支持复杂查询，插件丰富（如PostGIS处理空间数据）。
*   **时序数据库 (TSDB): InfluxDB**
    *   **用途**：存储高频传感器数据（温度曲线、燃气浓度趋势）。
    *   **选型理由**：高写入吞吐量，擅长处理时间序列数据查询。
*   **向量数据库 (Vector DB): Milvus 2.3**
    *   **用途**：存储非结构化数据的特征向量（如历史火灾案例的Embedding），用于RAG（检索增强生成）知识检索。
*   **图数据库 (Graph DB): Neo4j 5.0**
    *   **用途**：构建厨房-设备-隐患-预案的知识图谱，支持因果推理。

#### 2. 数据管道组件
*   **消息队列: Kafka**
    *   **用途**：作为边缘端数据的统一接入入口，削峰填谷，解耦边缘与云端。
*   **流式计算: Flink**
    *   **用途**：实时处理ODS层数据流，进行清洗和实时聚合，写入DWD/DWS层。

---

### 三、 存储策略与成本优化
数据湖最大的挑战是存储成本，需采用**分级存储**与**按需落盘**策略。

#### 1. 冷热分离策略
*   **热数据 (0-7天)**：存放在高性能SSD（MinIO）和Redis中，供实时大屏和数智主管快速研判。
*   **温数据 (7-90天)**：存放在低成本HDD（MinIO）和PostgreSQL中，供短期回溯和工单处理。
*   **冷数据 (>90天)**：转存至云端低频对象存储（OSS/S3 Archive），用于合规审计和长期趋势分析。
*   **归档数据 (>1年)**：核心告警记录永久保存，普通日志删除。

#### 2. 按需落盘机制 (Save-on-Event)
*   **视频数据**：**不进行7×24小时全量录像上传**。
*   **边缘自治**：仅当边缘AI推理置信度>0.8或触发告警时，才上传前后30秒视频切片和关键帧。
*   **效果**：相比全量上传，带宽和存储需求降低 **90%** 以上。

---

### 四、 容量规划与预算估计
基于**100个标准厨房**的规模进行估算。

#### 1. 容量预估 (日增量)
*   **视频流 (H.265)**：仅上传告警片段，约 50GB/天。
*   **图像 (告警抓拍)**：约 2GB/天。
*   **传感器数据**：100个厨房 × 25个传感器/厨房，约 100MB/天。
*   **总量**：约 **53GB/天** (压缩去重后)。
*   **年增量**：约 **19TB/年**。

#### 2. 预算估计 (公有云模式参考)
如果采用公有云（如阿里云/腾讯云）构建数据湖，月度费用估算如下：

| 资源类型 | 配置说明 | 预估费用 (CNY/月) | 备注 |
| :--- | :--- | :--- | :--- |
| **云盘 (ESSD)** | 10TB (用于数据库、热数据) | 10,000 | 高IO性能 |
| **对象存储 (OSS)** | 50TB (用于视频归档、冷数据) | 6,000 | 低频存储单价低 |
| **数据库实例** | RDS PostgreSQL (主备) | 2,500 | 16核 128GB |
| **中间件** | Redis + Kafka | 5,000 | 集群版 |
| **数据湖总计** | | **~23,500 元/月** | 摊销到100个厨房约235元/店/月 |

*注：若采用私有云自建，需采购约2台组织记忆服务器（配置大容量HDD），硬件成本约11万元。*

---

### 五、 开发实施周期
数据湖的搭建通常包含在云端平台建设中，预计周期为 **2周**。

1.  **环境准备 (Day 1-3)**：
    *   部署Kubernetes集群，安装MinIO、PostgreSQL、Milvus等基础组件（Helm Chart部署）。
2.  **数据模型设计 (Day 4-6)**：
    *   设计PostgreSQL表结构（告警表、设备表）。
    *   设计MinIO存储桶结构（Bucket策略）。
    *   定义Milvus向量索引结构。
3.  **管道开发 (Day 7-10)**：
    *   开发数据接入服务（Data Ingestion Service），对接边缘MQTT数据。
    *   开发ETL任务，实现ODS到DWD/DWS的数据清洗与聚合。
4.  **联调测试 (Day 11-14)**：
    *   模拟边缘端发送数据，验证数据写入、分层流转和查询性能。
    *   验证数据过期自动清理（TTL）策略。

### 总结
EMP-01的数据湖设计核心在于**“厚边缘、轻云端”**。通过在边缘端完成初步的数据清洗和推理，仅将高价值的**“证据包”**上传至云端数据湖。这不仅大幅降低了传输和存储成本（90%以上），还保证了核心告警数据的完整性（有图有真相）。技术上采用开源的 **MinIO + PostgreSQL + Milvus** 组合，既满足了多模态数据存储需求，又保证了架构的开放性和可扩展性。