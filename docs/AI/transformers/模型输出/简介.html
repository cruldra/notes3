<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AI/transformers/模型输出/简介" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">简介 | Cruldra</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/notes3/docs/AI/transformers/模型输出/简介"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="简介 | Cruldra"><meta data-rh="true" name="description" content="transformers.modeling_outputs 模块定义了 Hugging Face Transformers 库中所有模型的标准输出数据结构。这些类不仅仅是简单的数据容器，它们提供了统一的接口，使得模型输出既可以像 Python 对象一样访问属性，也可以像字典或元组一样进行解包和索引。"><meta data-rh="true" property="og:description" content="transformers.modeling_outputs 模块定义了 Hugging Face Transformers 库中所有模型的标准输出数据结构。这些类不仅仅是简单的数据容器，它们提供了统一的接口，使得模型输出既可以像 Python 对象一样访问属性，也可以像字典或元组一样进行解包和索引。"><link data-rh="true" rel="icon" href="/notes3/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/notes3/docs/AI/transformers/模型输出/简介"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/transformers/模型输出/简介" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/transformers/模型输出/简介" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"简介","item":"https://your-docusaurus-site.example.com/notes3/docs/AI/transformers/模型输出/简介"}]}</script><link rel="alternate" type="application/rss+xml" href="/notes3/blog/rss.xml" title="Cruldra RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/notes3/blog/atom.xml" title="Cruldra Atom Feed"><link rel="stylesheet" href="/notes3/assets/css/styles.371c6534.css">
<script src="/notes3/assets/js/runtime~main.c039e8de.js" defer="defer"></script>
<script src="/notes3/assets/js/main.f9912a11.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme",window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-theme-choice","system"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes3/img/logo.svg"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><div role="region" aria-label="Skip to main content"><a class="skipToContent_aA1M" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes3/"><div class="navbar__logo"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E3Xm themedComponent--light_DVqC"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E3Xm themedComponent--dark_B_L3"></div><b class="navbar__title text--truncate">Cruldra</b></a><a class="navbar__item navbar__link" href="/notes3/docs/category/设计模式">JVM</a><a class="navbar__item navbar__link" href="/notes3/docs/category/css">前端</a><a class="navbar__item navbar__link" href="/notes3/docs/category/astrbot">工具</a><a class="navbar__item navbar__link" href="/notes3/docs/category/ai电竞酒店">个人</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/notes3/docs/AI/ACP/架构">AI</a><a class="navbar__item navbar__link" href="/notes3/docs/category/内置模块">Python</a><a class="navbar__item navbar__link" href="/notes3/docs/category/actix-web">Rust</a><a class="navbar__item navbar__link" href="/notes3/docs/category/数据库系统">软件工程</a><a class="navbar__item navbar__link" href="/notes3/docs/category/上古卷轴5">游戏</a><a class="navbar__item navbar__link" href="/notes3/docs/Go/Go-Python-Java三语言全方位对比">Go</a><a class="navbar__item navbar__link" href="/notes3/docs/Hardware/GPU工作原理">硬件</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_PufJ"><div class="navbar__search searchBarContainer_r6C1" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_G4_y" value=""><div class="loadingRing__Zfe searchBarLoadingRing_f0pn"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_ctfR"><div class="docsWrapper_ByIB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_KwvU" type="button"></button><div class="docRoot_hD6z"><aside class="theme-doc-sidebar-container docSidebarContainer_KuHC"><div class="sidebarViewport_LCjr"><div class="sidebar_L77d"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_VYAF"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/ACP/架构"><span title="ACP" class="categoryLinkLabel_FHN4">ACP</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agent Skills/什么是Skills"><span title="Agent Skills" class="categoryLinkLabel_FHN4">Agent Skills</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agno/介绍"><span title="Agno" class="categoryLinkLabel_FHN4">Agno</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/CrewAI/CLI"><span title="CrewAI" class="categoryLinkLabel_FHN4">CrewAI</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/DALLE成本计算"><span title="DALL-E 画图成本计算" class="linkLabel__RqX">DALL-E 画图成本计算</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/LLamaIndex/CitationQueryEngine"><span title="LLamaIndex" class="categoryLinkLabel_FHN4">LLamaIndex</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/MCP/MCP-Python-SDK"><span title="MCP" class="categoryLinkLabel_FHN4">MCP</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Pytorch/介绍"><span title="Pytorch" class="categoryLinkLabel_FHN4">Pytorch</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/SentencePiece/简介"><span title="SentencePiece" class="categoryLinkLabel_FHN4">SentencePiece</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/Transformer"><span title="Transformer" class="linkLabel__RqX">Transformer</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/cv_graph"><span title="计算机视觉 (CV) 知识图谱" class="linkLabel__RqX">计算机视觉 (CV) 知识图谱</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/datasets/demo"><span title="datasets" class="categoryLinkLabel_FHN4">datasets</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/huggingface_hub/简介"><span title="huggingface_hub" class="categoryLinkLabel_FHN4">huggingface_hub</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/llm_graph"><span title="LLM 知识图谱" class="linkLabel__RqX">LLM 知识图谱</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/tiktoken/简介"><span title="tiktoken" class="categoryLinkLabel_FHN4">tiktoken</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/tokenizers/和tiktoken的区别"><span title="tokenizers" class="categoryLinkLabel_FHN4">tokenizers</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/notes3/docs/AI/transformers/分词器/PreTrainedTokenizer"><span title="transformers" class="categoryLinkLabel_FHN4">transformers</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/transformers/分词器/PreTrainedTokenizer"><span title="分词器" class="categoryLinkLabel_FHN4">分词器</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/transformers/模型/GenerationMixin"><span title="模型" class="categoryLinkLabel_FHN4">模型</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/notes3/docs/AI/transformers/模型输出/简介"><span title="模型输出" class="categoryLinkLabel_FHN4">模型输出</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes3/docs/AI/transformers/模型输出/简介"><span title="简介" class="linkLabel__RqX">简介</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/transformers/激活函数/简介"><span title="激活函数" class="categoryLinkLabel_FHN4">激活函数</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/transformers/简介"><span title="简介" class="linkLabel__RqX">简介</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/transformers/配置/PretrainedConfig"><span title="配置" class="categoryLinkLabel_FHN4">配置</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist" href="/notes3/docs/AI/vllm"><span title="vLLM 学习资料" class="categoryLinkLabel_FHN4">vLLM 学习资料</span></a><button aria-label="Expand sidebar category &#x27;vLLM 学习资料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/wandb/简介"><span title="wandb" class="categoryLinkLabel_FHN4">wandb</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念1"><span title="一些概念1" class="linkLabel__RqX">一些概念1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念2"><span title="一些概念2" class="linkLabel__RqX">一些概念2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念3"><span title="一些概念3" class="linkLabel__RqX">一些概念3</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念4"><span title="一些概念4" class="linkLabel__RqX">一些概念4</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念5"><span title="一些概念5" class="linkLabel__RqX">一些概念5</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/候选模型"><span title="候选模型" class="linkLabel__RqX">候选模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/变分自编码器详解"><span title="变分自编码器（VAE）详解" class="linkLabel__RqX">变分自编码器（VAE）详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型核心概念通俗解释"><span title="大模型核心概念通俗解释" class="linkLabel__RqX">大模型核心概念通俗解释</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型训练中的随机种子：为什么需要它？"><span title="大模型训练中的随机种子：为什么需要它？" class="linkLabel__RqX">大模型训练中的随机种子：为什么需要它？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/如何看懂数学公式"><span title="如何看懂数学公式" class="linkLabel__RqX">如何看懂数学公式</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/嵌入和向量/Chroma与PGVector对比"><span title="嵌入和向量" class="categoryLinkLabel_FHN4">嵌入和向量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/感知机"><span title="感知机" class="linkLabel__RqX">感知机</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/提示词工程/DSPy/API/优化器/BetterTogether"><span title="提示词工程" class="categoryLinkLabel_FHN4">提示词工程</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/智能体"><span title="智能体(Agent)" class="linkLabel__RqX">智能体(Agent)</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/深度学习/入门"><span title="深度学习" class="categoryLinkLabel_FHN4">深度学习</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/理解大模型：从函数视角看AI的本质"><span title="理解大模型：从函数视角看AI的本质" class="linkLabel__RqX">理解大模型：从函数视角看AI的本质</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/相关概念/Gradient"><span title="相关概念" class="categoryLinkLabel_FHN4">相关概念</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/联邦学习概念"><span title="联邦学习概念" class="linkLabel__RqX">联邦学习概念</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/通义千问/阿里云百炼"><span title="通义千问" class="categoryLinkLabel_FHN4">通义千问</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/金丝雀发布和AB测试"><span title="金丝雀发布和AB测试" class="linkLabel__RqX">金丝雀发布和AB测试</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_WxcZ"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_Zd2x"><div class="docItemContainer_EEW4"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_xL_w" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes3/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_zA1U"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">transformers</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">模型输出</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">简介</span></li></ul></nav><div class="tocCollapsible_aZGz theme-doc-toc-mobile tocMobile_ShCt"><button type="button" class="clean-btn tocCollapsibleButton_fxzH">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>简介</h1></header><p><code>transformers.modeling_outputs</code> 模块定义了 Hugging Face Transformers 库中所有模型的标准输出数据结构。这些类不仅仅是简单的数据容器，它们提供了统一的接口，使得模型输出既可以像 Python 对象一样访问属性，也可以像字典或元组一样进行解包和索引。</p>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="1-核心设计哲学modeloutput-基类">1. 核心设计哲学：<code>ModelOutput</code> 基类<a href="#1-核心设计哲学modeloutput-基类" class="hash-link" aria-label="Direct link to 1-核心设计哲学modeloutput-基类" title="Direct link to 1-核心设计哲学modeloutput-基类" translate="no">​</a></h2>
<p>所有模型输出类都继承自 <code>transformers.utils.ModelOutput</code>。这个基类使用了 Python 的 <code>@dataclass</code> 装饰器，并实现了特殊的方法以提供灵活的访问方式。</p>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="11-三种访问模式">1.1 三种访问模式<a href="#11-三种访问模式" class="hash-link" aria-label="Direct link to 1.1 三种访问模式" title="Direct link to 1.1 三种访问模式" translate="no">​</a></h3>
<p><code>ModelOutput</code> 的实例支持三种访问模式，这通过覆写 <code>__getitem__</code>、<code>__iter__</code> 等魔法方法实现：</p>
<ol>
<li class=""><strong>属性访问 (Attribute Access)</strong>: 推荐方式，代码可读性最强。<!-- -->
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token plain">outputs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">logits</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">outputs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">loss</span><br></span></code></pre></div></div>
</li>
<li class=""><strong>字典访问 (Dictionary Access)</strong>: 兼容字典操作。<!-- -->
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token plain">outputs</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;logits&quot;</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre></div></div>
</li>
<li class=""><strong>元组解包 (Tuple Unpacking)</strong>: 用于兼容旧代码或简单的解包赋值。注意：解包顺序是固定的，且只包含非 <code>None</code> 的元素。<!-- -->
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token plain">loss</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> logits </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> outputs  </span><span class="token comment" style="color:#999988;font-style:italic"># 仅当 loss 存在时</span><br></span></code></pre></div></div>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="12-数据结构特性">1.2 数据结构特性<a href="#12-数据结构特性" class="hash-link" aria-label="Direct link to 1.2 数据结构特性" title="Direct link to 1.2 数据结构特性" translate="no">​</a></h3>
<ul>
<li class=""><strong>可选字段</strong>: 大多数 output 类的字段都是 <code>Optional</code> 的。如果模型在前向传播时未计算某个值（例如未传入 <code>labels</code> 计算 <code>loss</code>，或未设置 <code>output_attentions=True</code>），则对应属性为 <code>None</code>。</li>
<li class=""><strong>Tensor 类型</strong>: 所有数值数据通常为 <code>torch.FloatTensor</code>。</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="2-核心输出类架构">2. 核心输出类架构<a href="#2-核心输出类架构" class="hash-link" aria-label="Direct link to 2. 核心输出类架构" title="Direct link to 2. 核心输出类架构" translate="no">​</a></h2>
<p>Transformers 库根据任务类型和模型架构定义了一系列输出类。以下是继承关系的简化视图：</p>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="3-通用输出类详解">3. 通用输出类详解<a href="#3-通用输出类详解" class="hash-link" aria-label="Direct link to 3. 通用输出类详解" title="Direct link to 3. 通用输出类详解" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="31-basemodeloutput">3.1 <code>BaseModelOutput</code><a href="#31-basemodeloutput" class="hash-link" aria-label="Direct link to 31-basemodeloutput" title="Direct link to 31-basemodeloutput" translate="no">​</a></h3>
<p>这是最基础的 Transformer 编码器输出，包含隐藏层状态和注意力权重。</p>
<table><thead><tr><th style="text-align:left">字段</th><th style="text-align:left">类型</th><th style="text-align:left">形状 (Shape)</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><strong><code>last_hidden_state</code></strong></td><td style="text-align:left"><code>torch.FloatTensor</code></td><td style="text-align:left"><code>(batch, seq_len, hidden)</code></td><td style="text-align:left">模型最后一层的输出序列。通常用于后续的 Token 级任务或通过池化用于序列任务。</td></tr><tr><td style="text-align:left"><strong><code>hidden_states</code></strong></td><td style="text-align:left"><code>Tuple[torch.FloatTensor]</code></td><td style="text-align:left"><code>n_layers + 1</code> 个张量</td><td style="text-align:left"><strong>可选</strong>。包含 embedding 层的输出加上每一层的输出。形状同上。需要设置 <code>output_hidden_states=True</code>。</td></tr><tr><td style="text-align:left"><strong><code>attentions</code></strong></td><td style="text-align:left"><code>Tuple[torch.FloatTensor]</code></td><td style="text-align:left"><code>n_layers</code> 个张量</td><td style="text-align:left"><strong>可选</strong>。每一层的注意力权重矩阵。形状为 <code>(batch, num_heads, seq_len, seq_len)</code>。需要设置 <code>output_attentions=True</code>。</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="32-basemodeloutputwithpooling-如-bert">3.2 <code>BaseModelOutputWithPooling</code> (如 BERT)<a href="#32-basemodeloutputwithpooling-如-bert" class="hash-link" aria-label="Direct link to 32-basemodeloutputwithpooling-如-bert" title="Direct link to 32-basemodeloutputwithpooling-如-bert" translate="no">​</a></h3>
<p>在 <code>BaseModelOutput</code> 基础上增加了池化输出。</p>
<table><thead><tr><th style="text-align:left">字段</th><th style="text-align:left">类型</th><th style="text-align:left">形状</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><strong><code>pooler_output</code></strong></td><td style="text-align:left"><code>torch.FloatTensor</code></td><td style="text-align:left"><code>(batch, hidden)</code></td><td style="text-align:left">序列的聚合表示。对于 BERT，这是 <code>[CLS]</code> token 经过全连接层和 Tanh 激活后的结果。常用于分类任务。</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="33-causallmoutputwithpast-如-gpt-2-llama">3.3 <code>CausalLMOutputWithPast</code> (如 GPT-2, Llama)<a href="#33-causallmoutputwithpast-如-gpt-2-llama" class="hash-link" aria-label="Direct link to 33-causallmoutputwithpast-如-gpt-2-llama" title="Direct link to 33-causallmoutputwithpast-如-gpt-2-llama" translate="no">​</a></h3>
<p>用于自回归（Autoregressive）文本生成任务。</p>
<table><thead><tr><th style="text-align:left">字段</th><th style="text-align:left">类型</th><th style="text-align:left">形状</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><strong><code>loss</code></strong></td><td style="text-align:left"><code>torch.FloatTensor</code></td><td style="text-align:left"><code>(1,)</code></td><td style="text-align:left"><strong>可选</strong>。语言建模损失（CrossEntropy）。仅当提供了 <code>labels</code> 时返回。</td></tr><tr><td style="text-align:left"><strong><code>logits</code></strong></td><td style="text-align:left"><code>torch.FloatTensor</code></td><td style="text-align:left"><code>(batch, seq_len, vocab_size)</code></td><td style="text-align:left">预测分数（未经过 Softmax）。</td></tr><tr><td style="text-align:left"><strong><code>past_key_values</code></strong></td><td style="text-align:left"><code>Tuple[Tuple[torch.FloatTensor]]</code></td><td style="text-align:left">详见下文</td><td style="text-align:left"><strong>关键字段</strong>。预计算的 Key 和 Value 矩阵，用于加速解码。</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_aDle" id="深入解析-past_key_values">深入解析 <code>past_key_values</code><a href="#深入解析-past_key_values" class="hash-link" aria-label="Direct link to 深入解析-past_key_values" title="Direct link to 深入解析-past_key_values" translate="no">​</a></h4>
<p>这是 KV Cache 的核心实现。</p>
<ul>
<li class=""><strong>结构</strong>: 一个元组，包含 <code>n_layers</code> 个元素。每个元素又是一个元组 <code>(key_tensor, value_tensor)</code>。</li>
<li class=""><strong>形状</strong>: <code>(batch, num_heads, past_seq_len, head_dim)</code>。</li>
<li class=""><strong>作用</strong>: 在生成第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span> 个 token 时，我们只需要关注第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span> 个 token 的 Query，但需要所有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0...</mn><mi>t</mi></mrow><annotation encoding="application/x-tex">0...t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0...</span><span class="mord mathnormal">t</span></span></span></span> 时刻的 Key 和 Value。通过传入 <code>past_key_values</code>，模型只需计算当前的 Attention，而无需重新计算之前所有 token 的 KV 矩阵。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="34-seq2seqlmoutput-如-t5-bart">3.4 <code>Seq2SeqLMOutput</code> (如 T5, BART)<a href="#34-seq2seqlmoutput-如-t5-bart" class="hash-link" aria-label="Direct link to 34-seq2seqlmoutput-如-t5-bart" title="Direct link to 34-seq2seqlmoutput-如-t5-bart" translate="no">​</a></h3>
<p>用于序列到序列任务（翻译、摘要）。这是一个复杂的复合对象，包含 Encoder 和 Decoder 的信息。</p>
<ul>
<li class=""><strong><code>loss</code></strong>: 生成任务的损失。</li>
<li class=""><strong><code>logits</code></strong>: Decoder 生成的词汇表预测分数。</li>
<li class=""><strong><code>past_key_values</code></strong>: Decoder 的 KV Cache。</li>
<li class=""><strong><code>encoder_last_hidden_state</code></strong>: Encoder 最后一层的输出。</li>
<li class=""><strong><code>encoder_hidden_states</code></strong>: Encoder 所有层的隐藏状态（可选）。</li>
<li class=""><strong><code>decoder_hidden_states</code></strong>: Decoder 所有层的隐藏状态（可选）。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="35-sequenceclassifieroutput-如-bert-for-classification">3.5 <code>SequenceClassifierOutput</code> (如 BERT For Classification)<a href="#35-sequenceclassifieroutput-如-bert-for-classification" class="hash-link" aria-label="Direct link to 35-sequenceclassifieroutput-如-bert-for-classification" title="Direct link to 35-sequenceclassifieroutput-如-bert-for-classification" translate="no">​</a></h3>
<p>用于文本分类任务。</p>
<table><thead><tr><th style="text-align:left">字段</th><th style="text-align:left">类型</th><th style="text-align:left">形状</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left"><strong><code>loss</code></strong></td><td style="text-align:left"><code>torch.FloatTensor</code></td><td style="text-align:left"><code>(1,)</code></td><td style="text-align:left">分类损失（CrossEntropy）或回归损失（MSE）。</td></tr><tr><td style="text-align:left"><strong><code>logits</code></strong></td><td style="text-align:left"><code>torch.FloatTensor</code></td><td style="text-align:left"><code>(batch, num_labels)</code></td><td style="text-align:left">分类得分。分类任务通常需要接 <code>softmax</code> 或 <code>argmax</code>。</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="4-代码示例">4. 代码示例<a href="#4-代码示例" class="hash-link" aria-label="Direct link to 4. 代码示例" title="Direct link to 4. 代码示例" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="41-获取隐藏状态和注意力">4.1 获取隐藏状态和注意力<a href="#41-获取隐藏状态和注意力" class="hash-link" aria-label="Direct link to 4.1 获取隐藏状态和注意力" title="Direct link to 4.1 获取隐藏状态和注意力" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoModel</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> AutoTokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_name </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;bert-base-uncased&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_name</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModel</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_name</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">inputs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Hello, world!&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> return_tensors</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;pt&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 显式要求返回 hidden_states 和 attentions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">outputs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">**</span><span class="token plain">inputs</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> output_hidden_states</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> output_attentions</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 1. 属性访问 (推荐)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">last_hidden </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> outputs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">last_hidden_state</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">all_layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> outputs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">hidden_states</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">all_attentions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> outputs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">attentions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 2. 验证形状</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Last Hidden Shape: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">last_hidden</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">shape</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># torch.Size([1, 5, 768]) -&gt; (batch, seq_len, hidden)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Number of layers (including embedding): </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation builtin">len</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">(</span><span class="token string-interpolation interpolation">all_layers</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">)</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 13 (12 layers + 1 embedding)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="42-处理生成模型的-kv-cache">4.2 处理生成模型的 KV Cache<a href="#42-处理生成模型的-kv-cache" class="hash-link" aria-label="Direct link to 4.2 处理生成模型的 KV Cache" title="Direct link to 4.2 处理生成模型的 KV Cache" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> AutoTokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;gpt2&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;gpt2&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_ids </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;AI is&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> return_tensors</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;pt&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">input_ids</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 第一步：初始推理</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">outputs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">input_ids</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pkvs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> outputs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">past_key_values  </span><span class="token comment" style="color:#999988;font-style:italic"># 获取 KV Cache</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 第二步：生成下一个 token，传入 past_key_values</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">next_token_input </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> outputs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">logits</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">argmax</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dim</span><span class="token operator" style="color:#393A34">=</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">unsqueeze</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">outputs_next </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">next_token_input</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> past_key_values</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">pkvs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># 极大加速</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># outputs_next.past_key_values 包含了更新后的 Cache</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="5-参考资料">5. 参考资料<a href="#5-参考资料" class="hash-link" aria-label="Direct link to 5. 参考资料" title="Direct link to 5. 参考资料" translate="no">​</a></h2>
<ol>
<li class=""><strong>Hugging Face Official Docs</strong>: <a href="https://huggingface.co/docs/transformers/en/main_classes/output" target="_blank" rel="noopener noreferrer" class="">Model outputs</a></li>
<li class=""><strong>GitHub Source Code</strong>: <a href="https://github.com/huggingface/transformers/blob/main/src/transformers/modeling_outputs.py" target="_blank" rel="noopener noreferrer" class="">modeling_outputs.py</a></li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_iDCr"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/transformers/模型输出/简介.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_c0mv" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_mxtt"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes3/docs/AI/transformers/模型/PreTrainedModel"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">PreTrainedModel</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes3/docs/AI/transformers/激活函数/简介"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">简介</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_r83r thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-核心设计哲学modeloutput-基类" class="table-of-contents__link toc-highlight">1. 核心设计哲学：<code>ModelOutput</code> 基类</a><ul><li><a href="#11-三种访问模式" class="table-of-contents__link toc-highlight">1.1 三种访问模式</a></li><li><a href="#12-数据结构特性" class="table-of-contents__link toc-highlight">1.2 数据结构特性</a></li></ul></li><li><a href="#2-核心输出类架构" class="table-of-contents__link toc-highlight">2. 核心输出类架构</a></li><li><a href="#3-通用输出类详解" class="table-of-contents__link toc-highlight">3. 通用输出类详解</a><ul><li><a href="#31-basemodeloutput" class="table-of-contents__link toc-highlight">3.1 <code>BaseModelOutput</code></a></li><li><a href="#32-basemodeloutputwithpooling-如-bert" class="table-of-contents__link toc-highlight">3.2 <code>BaseModelOutputWithPooling</code> (如 BERT)</a></li><li><a href="#33-causallmoutputwithpast-如-gpt-2-llama" class="table-of-contents__link toc-highlight">3.3 <code>CausalLMOutputWithPast</code> (如 GPT-2, Llama)</a></li><li><a href="#34-seq2seqlmoutput-如-t5-bart" class="table-of-contents__link toc-highlight">3.4 <code>Seq2SeqLMOutput</code> (如 T5, BART)</a></li><li><a href="#35-sequenceclassifieroutput-如-bert-for-classification" class="table-of-contents__link toc-highlight">3.5 <code>SequenceClassifierOutput</code> (如 BERT For Classification)</a></li></ul></li><li><a href="#4-代码示例" class="table-of-contents__link toc-highlight">4. 代码示例</a><ul><li><a href="#41-获取隐藏状态和注意力" class="table-of-contents__link toc-highlight">4.1 获取隐藏状态和注意力</a></li><li><a href="#42-处理生成模型的-kv-cache" class="table-of-contents__link toc-highlight">4.2 处理生成模型的 KV Cache</a></li></ul></li><li><a href="#5-参考资料" class="table-of-contents__link toc-highlight">5. 参考资料</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>