<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AI/vllm/vLLM完整指南" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">vLLM 完整指南 | Cruldra</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/notes3/docs/AI/vllm/vLLM完整指南"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="vLLM 完整指南 | Cruldra"><meta data-rh="true" name="description" content="什么是 vLLM？"><meta data-rh="true" property="og:description" content="什么是 vLLM？"><link data-rh="true" rel="icon" href="/notes3/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/notes3/docs/AI/vllm/vLLM完整指南"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/vllm/vLLM完整指南" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/vllm/vLLM完整指南" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"vLLM 学习资料","item":"https://your-docusaurus-site.example.com/notes3/docs/AI/vllm/"},{"@type":"ListItem","position":2,"name":"vLLM 完整指南","item":"https://your-docusaurus-site.example.com/notes3/docs/AI/vllm/vLLM完整指南"}]}</script><link rel="alternate" type="application/rss+xml" href="/notes3/blog/rss.xml" title="Cruldra RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/notes3/blog/atom.xml" title="Cruldra Atom Feed"><link rel="stylesheet" href="/notes3/assets/css/styles.f3dc2d00.css">
<script src="/notes3/assets/js/runtime~main.bf1ebb8b.js" defer="defer"></script>
<script src="/notes3/assets/js/main.84cd95f1.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme",window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-theme-choice","system"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes3/img/logo.svg"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><div role="region" aria-label="Skip to main content"><a class="skipToContent_kJiJ" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes3/"><div class="navbar__logo"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_NrnZ themedComponent--light_kIco"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_NrnZ themedComponent--dark_HCTy"></div><b class="navbar__title text--truncate">Cruldra</b></a><a class="navbar__item navbar__link" href="/notes3/docs/category/设计模式">JVM</a><a class="navbar__item navbar__link" href="/notes3/docs/category/css">前端</a><a class="navbar__item navbar__link" href="/notes3/docs/category/astrbot">工具</a><a class="navbar__item navbar__link" href="/notes3/docs/category/ai电竞酒店">个人</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/notes3/docs/AI/Agno/介绍">AI</a><a class="navbar__item navbar__link" href="/notes3/docs/category/内置模块">Python</a><a class="navbar__item navbar__link" href="/notes3/docs/category/actix-web">Rust</a><a class="navbar__item navbar__link" href="/notes3/docs/category/数据库系统">软件工程</a><a class="navbar__item navbar__link" href="/notes3/docs/category/上古卷轴5">游戏</a><a class="navbar__item navbar__link" href="/notes3/docs/Go/Go-Python-Java三语言全方位对比">Go</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_V3q0"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_YMCn"><div class="docsWrapper_UDzO"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_OA9t" type="button"></button><div class="docRoot_zblS"><aside class="theme-doc-sidebar-container docSidebarContainer_utvl"><div class="sidebarViewport_uicj"><div class="sidebar_wSJP"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_xz03"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agno/介绍"><span title="Agno" class="categoryLinkLabel_5XjO">Agno</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/DALLE成本计算"><span title="DALL-E 画图成本计算" class="linkLabel_VeW_">DALL-E 画图成本计算</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/MCP/MCP-Python-SDK"><span title="MCP" class="categoryLinkLabel_5XjO">MCP</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/Transformer"><span title="Transformer" class="linkLabel_VeW_">Transformer</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--active" href="/notes3/docs/AI/vllm/"><span title="vLLM 学习资料" class="categoryLinkLabel_5XjO">vLLM 学习资料</span></a><button aria-label="Collapse sidebar category &#x27;vLLM 学习资料&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/vllm/PagedAttention技术详解"><span title="PagedAttention 技术详解" class="linkLabel_VeW_">PagedAttention 技术详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes3/docs/AI/vllm/vLLM完整指南"><span title="vLLM 完整指南" class="linkLabel_VeW_">vLLM 完整指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/vllm/vLLM实战部署指南"><span title="vLLM 实战部署指南" class="linkLabel_VeW_">vLLM 实战部署指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/vllm/vLLM性能调优指南"><span title="vLLM 性能调优指南" class="linkLabel_VeW_">vLLM 性能调优指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/vllm/vllm-fast-inference-and-cuda-graph"><span title="vLLM 快速推理与 CUDA Graph 详解" class="linkLabel_VeW_">vLLM 快速推理与 CUDA Graph 详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/vllm/安装常见错误及解决方案"><span title="安装常见错误及解决方案" class="linkLabel_VeW_">安装常见错误及解决方案</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念1"><span title="一些概念1" class="linkLabel_VeW_">一些概念1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念2"><span title="一些概念2" class="linkLabel_VeW_">一些概念2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念3"><span title="一些概念3" class="linkLabel_VeW_">一些概念3</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念4"><span title="一些概念4" class="linkLabel_VeW_">一些概念4</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念5"><span title="一些概念5" class="linkLabel_VeW_">一些概念5</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/候选模型"><span title="候选模型" class="linkLabel_VeW_">候选模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/变分自编码器详解"><span title="变分自编码器（VAE）详解" class="linkLabel_VeW_">变分自编码器（VAE）详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型核心概念通俗解释"><span title="大模型核心概念通俗解释" class="linkLabel_VeW_">大模型核心概念通俗解释</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型训练中的随机种子：为什么需要它？"><span title="大模型训练中的随机种子：为什么需要它？" class="linkLabel_VeW_">大模型训练中的随机种子：为什么需要它？</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/嵌入和向量/Chroma与PGVector对比"><span title="嵌入和向量" class="categoryLinkLabel_5XjO">嵌入和向量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/感知机"><span title="感知机" class="linkLabel_VeW_">感知机</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/智能体"><span title="智能体(Agent)" class="linkLabel_VeW_">智能体(Agent)</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/深度学习/入门"><span title="深度学习" class="categoryLinkLabel_5XjO">深度学习</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/理解大模型：从函数视角看AI的本质"><span title="理解大模型：从函数视角看AI的本质" class="linkLabel_VeW_">理解大模型：从函数视角看AI的本质</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/知识蒸馏"><span title="知识蒸馏" class="linkLabel_VeW_">知识蒸馏</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/联邦学习概念"><span title="联邦学习概念" class="linkLabel_VeW_">联邦学习概念</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/通义千问/阿里云百炼"><span title="通义千问" class="categoryLinkLabel_5XjO">通义千问</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/金丝雀发布和AB测试"><span title="金丝雀发布和AB测试" class="linkLabel_VeW_">金丝雀发布和AB测试</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_e2u6"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_y0g3"><div class="docItemContainer_PZbB"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_I1XV" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes3/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_ZIEp"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/notes3/docs/AI/vllm/"><span>vLLM 学习资料</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">vLLM 完整指南</span></li></ul></nav><div class="tocCollapsible_UUJj theme-doc-toc-mobile tocMobile_b9MH"><button type="button" class="clean-btn tocCollapsibleButton_zQap">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>vLLM 完整指南</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="什么是-vllm">什么是 vLLM？<a href="#什么是-vllm" class="hash-link" aria-label="Direct link to 什么是 vLLM？" title="Direct link to 什么是 vLLM？" translate="no">​</a></h2>
<p>vLLM（Vectorized Large Language Model Serving System）是由加州大学伯克利分校 LMSYS 团队开发的<strong>高性能大语言模型推理引擎</strong>。它专注于通过创新的内存管理和计算优化技术，实现高吞吐、低延迟、低成本的模型服务。</p>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="核心特点">核心特点<a href="#核心特点" class="hash-link" aria-label="Direct link to 核心特点" title="Direct link to 核心特点" translate="no">​</a></h3>
<ul>
<li class=""><strong>高性能推理</strong>：支持分布式推理，能高效利用多机多卡资源</li>
<li class=""><strong>显存优化</strong>：采用 PagedAttention 内存管理技术，显著提升 GPU 显存利用率</li>
<li class=""><strong>多场景适配</strong>：无论是低延迟的在线服务，还是资源受限的边缘部署，vLLM 都能提供卓越的性能表现</li>
<li class=""><strong>OpenAI 兼容</strong>：提供与 OpenAI API 兼容的接口，方便迁移和集成</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="官方资源">官方资源<a href="#官方资源" class="hash-link" aria-label="Direct link to 官方资源" title="Direct link to 官方资源" translate="no">​</a></h3>
<ul>
<li class=""><strong>中文站点</strong>：<a href="https://vllm.hyper.ai/docs/" target="_blank" rel="noopener noreferrer" class="">https://vllm.hyper.ai/docs/</a></li>
<li class=""><strong>英文站点</strong>：<a href="https://docs.vllm.ai/en/latest/index.html" target="_blank" rel="noopener noreferrer" class="">https://docs.vllm.ai/en/latest/index.html</a></li>
<li class=""><strong>GitHub</strong>：<a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer" class="">https://github.com/vllm-project/vllm</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="vllm-vs-ollama对比分析">vLLM vs Ollama：对比分析<a href="#vllm-vs-ollama对比分析" class="hash-link" aria-label="Direct link to vLLM vs Ollama：对比分析" title="Direct link to vLLM vs Ollama：对比分析" translate="no">​</a></h2>
<p>在 LLM 推理引擎的选择上，vLLM 和 Ollama 是两个常见的选项。</p>
<table><thead><tr><th>对比维度</th><th>Ollama</th><th>vLLM</th><th>备注</th></tr></thead><tbody><tr><td><strong>量化与压缩策略</strong></td><td>默认采用 4-bit/8-bit 量化，显存占用降至 25%-50%</td><td>默认使用 FP16/BF16 精度，保留完整参数精度</td><td>Ollama 牺牲精度换显存，vLLM 牺牲显存换计算效率</td></tr><tr><td><strong>优化目标</strong></td><td>轻量化和本地部署，动态加载模型分块，按需使用显存</td><td>高吞吐量、低延迟，预加载完整模型到显存，支持高并发</td><td>Ollama 适合单任务，vLLM 适合批量推理</td></tr><tr><td><strong>显存管理机制</strong></td><td>分块加载 + 动态缓存，仅保留必要参数和激活值</td><td>PagedAttention + 全量预加载，保留完整参数和中间激活值</td><td>vLLM 显存占用为 Ollama 的 2-5 倍</td></tr><tr><td><strong>硬件适配</strong></td><td>针对消费级 GPU（如 RTX 3060）优化，显存需求低</td><td>依赖专业级 GPU（如 A100/H100），需多卡并行或分布式部署</td><td>Ollama 可在 24GB 显存运行 32B 模型，vLLM 需至少 64GB</td></tr><tr><td><strong>性能与资源平衡</strong></td><td>显存占用低，但推理速度较慢（适合轻量级应用）</td><td>显存占用高，但吞吐量高（适合企业级服务）</td><td>量化后 Ollama 速度可提升，但仍低于 vLLM</td></tr><tr><td><strong>适用场景</strong></td><td>个人开发、本地测试、轻量级应用</td><td>企业级 API 服务、高并发推理、大规模部署</td><td>根据显存和性能需求选择框架</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="deepseek-r1-distill-qwen-32b-模型对比">DeepSeek-R1-Distill-Qwen-32B 模型对比<a href="#deepseek-r1-distill-qwen-32b-模型对比" class="hash-link" aria-label="Direct link to DeepSeek-R1-Distill-Qwen-32B 模型对比" title="Direct link to DeepSeek-R1-Distill-Qwen-32B 模型对比" translate="no">​</a></h3>
<table><thead><tr><th>指标</th><th>Ollama (4-bit)</th><th>vLLM (FP16)</th><th>说明</th></tr></thead><tbody><tr><td><strong>显存占用</strong></td><td>19-24 GB</td><td>64-96 GB</td><td>Ollama 通过 4-bit 量化压缩参数，vLLM 需保留完整 FP16 参数和激活值</td></tr><tr><td><strong>存储空间</strong></td><td>20 GB</td><td>64 GB</td><td>Ollama 存储量化后模型，vLLM 存储原始 FP16 精度模型</td></tr><tr><td><strong>推理速度</strong></td><td>较低（5-15 tokens/s）</td><td>中高（30-60 tokens/s）</td><td>Ollama 因量化计算效率降低，vLLM 通过批处理和并行优化提升吞吐量</td></tr><tr><td><strong>硬件门槛</strong></td><td>高端消费级 GPU（≥24GB）</td><td>多卡专业级 GPU（如 2×A100 80GB）</td><td>Ollama 勉强单卡运行，vLLM 需多卡并行或分布式部署</td></tr></tbody></table>
<p><strong>总结</strong>：Ollama 更适合个人开发和轻量级应用，而 vLLM 则更适合企业级服务和高并发场景。</p>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="核心技术pagedattention">核心技术：PagedAttention<a href="#核心技术pagedattention" class="hash-link" aria-label="Direct link to 核心技术：PagedAttention" title="Direct link to 核心技术：PagedAttention" translate="no">​</a></h2>
<p>PagedAttention 是 vLLM 最核心的技术创新，它解决了大型语言模型推理过程中的内存管理难题。</p>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="传统-kv-cache-的问题">传统 KV Cache 的问题<a href="#传统-kv-cache-的问题" class="hash-link" aria-label="Direct link to 传统 KV Cache 的问题" title="Direct link to 传统 KV Cache 的问题" translate="no">​</a></h3>
<p>在 LLM 推理时，KV Cache（存储注意力机制的 Key-Value 对）会占用大量显存，且由于请求长度不一，容易造成：</p>
<ol>
<li class=""><strong>显存占用增长快</strong>：KV Cache 占用迅速增长，极易耗尽 GPU 内存</li>
<li class=""><strong>内存碎片严重</strong>：不同长度的请求导致内存碎片化</li>
<li class=""><strong>缓存难以复用</strong>：无法有效复用已计算的 KV Cache</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="pagedattention-的解决方案">PagedAttention 的解决方案<a href="#pagedattention-的解决方案" class="hash-link" aria-label="Direct link to PagedAttention 的解决方案" title="Direct link to PagedAttention 的解决方案" translate="no">​</a></h3>
<p>PagedAttention 的设计灵感来自操作系统的虚拟内存分页管理技术：</p>
<ul>
<li class=""><strong>分页管理</strong>：将 KV Cache 分割成固定大小的块（pages），类似操作系统的内存页</li>
<li class=""><strong>按需分配</strong>：只在需要时分配内存页，避免预先分配大块连续内存</li>
<li class=""><strong>高效复用</strong>：不同请求可以共享相同的 KV Cache 页，提高内存利用率</li>
<li class=""><strong>减少碎片</strong>：通过页表管理，减少内存碎片</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="性能提升">性能提升<a href="#性能提升" class="hash-link" aria-label="Direct link to 性能提升" title="Direct link to 性能提升" translate="no">​</a></h3>
<ul>
<li class=""><strong>吞吐量提升</strong>：相比 HuggingFace Transformers 提升高达 24 倍</li>
<li class=""><strong>显存利用率</strong>：显著提高 GPU 显存利用率，可在相同硬件上处理更多并发请求</li>
<li class=""><strong>延迟降低</strong>：通过优化内存管理，降低推理延迟</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="安装部署">安装部署<a href="#安装部署" class="hash-link" aria-label="Direct link to 安装部署" title="Direct link to 安装部署" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="环境要求">环境要求<a href="#环境要求" class="hash-link" aria-label="Direct link to 环境要求" title="Direct link to 环境要求" translate="no">​</a></h3>
<ul>
<li class=""><strong>操作系统</strong>：Linux（推荐 Ubuntu 20.04+）</li>
<li class=""><strong>Python</strong>：3.8-3.11</li>
<li class=""><strong>GPU</strong>：NVIDIA GPU with CUDA 11.8+</li>
<li class=""><strong>显存</strong>：根据模型大小而定（建议 ≥24GB）</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="使用-pip-安装">使用 pip 安装<a href="#使用-pip-安装" class="hash-link" aria-label="Direct link to 使用 pip 安装" title="Direct link to 使用 pip 安装" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-bash codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain"># 安装 vLLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install vllm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 或者从源码安装最新版本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install git+https://github.com/vllm-project/vllm.git</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="使用-docker-部署">使用 Docker 部署<a href="#使用-docker-部署" class="hash-link" aria-label="Direct link to 使用 Docker 部署" title="Direct link to 使用 Docker 部署" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="1-安装-nvidia-container-toolkit">1. 安装 NVIDIA Container Toolkit<a href="#1-安装-nvidia-container-toolkit" class="hash-link" aria-label="Direct link to 1. 安装 NVIDIA Container Toolkit" title="Direct link to 1. 安装 NVIDIA Container Toolkit" translate="no">​</a></h4>
<div class="language-bash codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-bash codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain"># 更新软件包列表并安装 NVIDIA 容器工具包</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 配置 NVIDIA 容器运行时</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo nvidia-ctk runtime configure --runtime=docker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 重加载系统服务并重启 Docker</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo systemctl daemon-reload</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sudo systemctl restart docker</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="2-拉取-vllm-镜像">2. 拉取 vLLM 镜像<a href="#2-拉取-vllm-镜像" class="hash-link" aria-label="Direct link to 2. 拉取 vLLM 镜像" title="Direct link to 2. 拉取 vLLM 镜像" translate="no">​</a></h4>
<div class="language-bash codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-bash codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain">docker pull vllm/vllm-openai:latest</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="3-启动-vllm-容器">3. 启动 vLLM 容器<a href="#3-启动-vllm-容器" class="hash-link" aria-label="Direct link to 3. 启动 vLLM 容器" title="Direct link to 3. 启动 vLLM 容器" translate="no">​</a></h4>
<div class="language-bash codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-bash codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain">docker run -itd --restart=always --name vllm_service \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -v /path/to/models:/models \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -p 8000:8000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --gpus all \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --ipc=host \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  vllm/vllm-openai:latest \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --model /models/your-model \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --dtype bfloat16 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --gpu-memory-utilization 0.9 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --tensor-parallel-size 1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --max-model-len 4096 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --api-key your-api-key</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="参数说明">参数说明<a href="#参数说明" class="hash-link" aria-label="Direct link to 参数说明" title="Direct link to 参数说明" translate="no">​</a></h3>
<table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>--restart=always</code></td><td>容器退出后自动重启</td></tr><tr><td><code>-v /path/to/models:/models</code></td><td>挂载模型目录</td></tr><tr><td><code>-p 8000:8000</code></td><td>端口映射</td></tr><tr><td><code>--gpus all</code></td><td>使用所有 GPU</td></tr><tr><td><code>--ipc=host</code></td><td>共享主机 IPC，提升并行性能</td></tr><tr><td><code>--model</code></td><td>模型路径</td></tr><tr><td><code>--dtype</code></td><td>数据类型（auto, half, float16, bfloat16, float, float32）</td></tr><tr><td><code>--gpu-memory-utilization</code></td><td>GPU 内存使用率（0.7-0.95）</td></tr><tr><td><code>--tensor-parallel-size</code></td><td>张量并行大小（GPU 数量）</td></tr><tr><td><code>--max-model-len</code></td><td>最大上下文长度</td></tr><tr><td><code>--api-key</code></td><td>API 密钥</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="使用方法">使用方法<a href="#使用方法" class="hash-link" aria-label="Direct link to 使用方法" title="Direct link to 使用方法" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="python-api">Python API<a href="#python-api" class="hash-link" aria-label="Direct link to Python API" title="Direct link to Python API" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-python codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> vllm </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> LLM</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> SamplingParams</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 初始化模型</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> LLM</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;Qwen/Qwen2.5-7B-Instruct&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dtype</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;bfloat16&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    gpu_memory_utilization</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.9</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_model_len</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">4096</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 设置采样参数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sampling_params </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> SamplingParams</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.7</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_p</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.9</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_tokens</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 生成文本</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompts </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;北京的著名景点有哪些？&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">outputs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> llm</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generate</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">prompts</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> sampling_params</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> output </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> outputs</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">output</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">outputs</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="openai-兼容-api">OpenAI 兼容 API<a href="#openai-兼容-api" class="hash-link" aria-label="Direct link to OpenAI 兼容 API" title="Direct link to OpenAI 兼容 API" translate="no">​</a></h3>
<p>启动 OpenAI 兼容服务器：</p>
<div class="language-bash codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-bash codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain">vllm serve Qwen/Qwen2.5-7B-Instruct \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --dtype bfloat16 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --gpu-memory-utilization 0.9 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --api-key your-api-key</span><br></span></code></pre></div></div>
<p>使用 curl 调用：</p>
<div class="language-bash codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-bash codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain">curl http://localhost:8000/v1/completions \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H &quot;Content-Type: application/json&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H &quot;Authorization: Bearer your-api-key&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -d &#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;model&quot;: &quot;Qwen/Qwen2.5-7B-Instruct&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;prompt&quot;: &quot;北京的著名景点有哪些？&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;max_tokens&quot;: 1000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;temperature&quot;: 0.7</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }&#x27;</span><br></span></code></pre></div></div>
<p>使用 Python OpenAI 客户端：</p>
<div class="language-python codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-python codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> openai </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> OpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;http://localhost:8000/v1&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    api_key</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;your-api-key&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;Qwen/Qwen2.5-7B-Instruct&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    prompt</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;北京的著名景点有哪些？&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_tokens</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.7</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">choices</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="性能优化">性能优化<a href="#性能优化" class="hash-link" aria-label="Direct link to 性能优化" title="Direct link to 性能优化" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="关键参数调优">关键参数调优<a href="#关键参数调优" class="hash-link" aria-label="Direct link to 关键参数调优" title="Direct link to 关键参数调优" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="1-gpu-内存利用率---gpu-memory-utilization">1. GPU 内存利用率 (<code>--gpu-memory-utilization</code>)<a href="#1-gpu-内存利用率---gpu-memory-utilization" class="hash-link" aria-label="Direct link to 1-gpu-内存利用率---gpu-memory-utilization" title="Direct link to 1-gpu-内存利用率---gpu-memory-utilization" translate="no">​</a></h4>
<ul>
<li class=""><strong>范围</strong>：0.7-0.95</li>
<li class=""><strong>建议</strong>：从 0.95 开始降低，直到效果达到最佳</li>
<li class=""><strong>说明</strong>：限制模型使用的 GPU 内存占比，避免因内存不足导致服务崩溃</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="2-张量并行---tensor-parallel-size">2. 张量并行 (<code>--tensor-parallel-size</code>)<a href="#2-张量并行---tensor-parallel-size" class="hash-link" aria-label="Direct link to 2-张量并行---tensor-parallel-size" title="Direct link to 2-张量并行---tensor-parallel-size" translate="no">​</a></h4>
<ul>
<li class=""><strong>说明</strong>：将模型分割到多个 GPU 上进行并行计算</li>
<li class=""><strong>建议</strong>：设置为 GPU 数量</li>
<li class=""><strong>示例</strong>：8 卡 A100 设置为 8</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="3-数据类型---dtype">3. 数据类型 (<code>--dtype</code>)<a href="#3-数据类型---dtype" class="hash-link" aria-label="Direct link to 3-数据类型---dtype" title="Direct link to 3-数据类型---dtype" translate="no">​</a></h4>
<ul>
<li class=""><strong>auto</strong>：根据模型类型自动选择精度</li>
<li class=""><strong>bfloat16</strong>：推荐，平衡精度和性能</li>
<li class=""><strong>float16</strong>：半精度，节省显存</li>
<li class=""><strong>float32</strong>：全精度，占用显存大</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="4-最大上下文长度---max-model-len">4. 最大上下文长度 (<code>--max-model-len</code>)<a href="#4-最大上下文长度---max-model-len" class="hash-link" aria-label="Direct link to 4-最大上下文长度---max-model-len" title="Direct link to 4-最大上下文长度---max-model-len" translate="no">​</a></h4>
<ul>
<li class=""><strong>说明</strong>：限制模型在一次推理中能处理的最大输入长度</li>
<li class=""><strong>建议</strong>：根据实际需求设置，避免过长输入导致性能问题</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="5-采样参数">5. 采样参数<a href="#5-采样参数" class="hash-link" aria-label="Direct link to 5. 采样参数" title="Direct link to 5. 采样参数" translate="no">​</a></h4>
<div class="language-python codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-python codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain">sampling_params </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> SamplingParams</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.7</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># 控制随机性，0-1 之间</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_p</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.9</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">           </span><span class="token comment" style="color:#999988;font-style:italic"># 核采样，优先调节此参数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_k</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">50</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic"># Top-K 采样</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    repetition_penalty</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1.1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 重复惩罚，大于 1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_tokens</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># 最大生成 token 数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="最佳实践">最佳实践<a href="#最佳实践" class="hash-link" aria-label="Direct link to 最佳实践" title="Direct link to 最佳实践" translate="no">​</a></h3>
<ol>
<li class=""><strong>先测试后部署</strong>：在实际部署前进行充分测试，确定最佳配置</li>
<li class=""><strong>监控资源使用</strong>：使用 Prometheus + Grafana 监控 GPU 使用率、吞吐量等指标</li>
<li class=""><strong>分块预填充</strong>：启用 Chunked Prefill，将大型预填充操作拆分成更小的块</li>
<li class=""><strong>批处理优化</strong>：通过 <code>max_num_batched_tokens</code> 参数优化批处理性能</li>
<li class=""><strong>长文本优化</strong>：对于长文本场景，使用 YaRN 等长度外推技术</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="常见模型显存占用参考">常见模型显存占用参考<a href="#常见模型显存占用参考" class="hash-link" aria-label="Direct link to 常见模型显存占用参考" title="Direct link to 常见模型显存占用参考" translate="no">​</a></h2>
<table><thead><tr><th>模型</th><th>Base Model</th><th>Ollama</th><th>vLLM</th></tr></thead><tbody><tr><td>DeepSeek-R1-Distill-Qwen-1.5B</td><td>Qwen2.5-Math-1.5B</td><td>1.1GB</td><td>3-6 GB</td></tr><tr><td>DeepSeek-R1-Distill-Qwen-7B</td><td>Qwen2.5-Math-7B</td><td>4.7GB</td><td>14-21 GB</td></tr><tr><td>DeepSeek-R1-Distill-Llama-8B</td><td>Llama-3.1-8B</td><td>4.9GB</td><td>16-24 GB</td></tr><tr><td>DeepSeek-R1-Distill-Qwen-14B</td><td>Qwen2.5-14B</td><td>9.0GB</td><td>28-42 GB</td></tr><tr><td>DeepSeek-R1-Distill-Qwen-32B</td><td>Qwen2.5-32B</td><td>20GB</td><td>64-96 GB</td></tr><tr><td>DeepSeek-R1-Distill-Llama-70B</td><td>Llama-3.3-70B-Instruct</td><td>43GB</td><td>140-210 GB</td></tr><tr><td>DeepSeek-R1-671B</td><td>DeepSeek-R1-671B</td><td>404GB</td><td>1342-2013 GB</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="技术栈关系">技术栈关系<a href="#技术栈关系" class="hash-link" aria-label="Direct link to 技术栈关系" title="Direct link to 技术栈关系" translate="no">​</a></h2>
<p>vLLM 的运行依赖于以下技术栈：</p>
<div class="language-text codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-text codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain">应用层：vLLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">加速库层：cuDNN（深度学习加速库）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">计算平台层：CUDA（GPU 计算平台）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">驱动层：NVIDIA 驱动</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">硬件层：NVIDIA GPU</span><br></span></code></pre></div></div>
<ul>
<li class=""><strong>vLLM</strong>：应用层，调用 cuDNN 和 CUDA 提供的接口来加速计算</li>
<li class=""><strong>cuDNN</strong>：加速库层，依赖于 CUDA 提供的 GPU 计算能力，优化了深度学习任务</li>
<li class=""><strong>CUDA</strong>：计算平台层，依赖于 NVIDIA 驱动与 GPU 硬件通信，提供了通用的 GPU 计算接口</li>
<li class=""><strong>NVIDIA 驱动</strong>：驱动层，管理着 NVIDIA GPU 的硬件资源，允许上层软件与 GPU 进行交互</li>
<li class=""><strong>NVIDIA GPU</strong>：硬件层，执行实际的计算任务，提供了强大的并行计算能力</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_FzkC" id="总结">总结<a href="#总结" class="hash-link" aria-label="Direct link to 总结" title="Direct link to 总结" translate="no">​</a></h2>
<p>vLLM 是一个强大的大语言模型推理引擎，通过 PagedAttention 等创新技术，显著提升了推理性能和显存利用率。它适合企业级服务和高并发场景，是构建生产级 LLM 应用的理想选择。</p>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="何时选择-vllm">何时选择 vLLM？<a href="#何时选择-vllm" class="hash-link" aria-label="Direct link to 何时选择 vLLM？" title="Direct link to 何时选择 vLLM？" translate="no">​</a></h3>
<ul>
<li class="">✅ 需要高吞吐量和低延迟</li>
<li class="">✅ 有充足的 GPU 资源（专业级 GPU）</li>
<li class="">✅ 需要处理高并发请求</li>
<li class="">✅ 需要 OpenAI 兼容的 API 接口</li>
<li class="">✅ 企业级生产环境</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="何时选择-ollama">何时选择 Ollama？<a href="#何时选择-ollama" class="hash-link" aria-label="Direct link to 何时选择 Ollama？" title="Direct link to 何时选择 Ollama？" translate="no">​</a></h3>
<ul>
<li class="">✅ 个人开发和测试</li>
<li class="">✅ 消费级 GPU（显存有限）</li>
<li class="">✅ 单用户或低并发场景</li>
<li class="">✅ 快速原型开发</li>
<li class="">✅ 本地部署和轻量级应用</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_RM2i"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/vllm/vLLM完整指南.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_NBA7" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_Ng_4"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes3/docs/AI/vllm/PagedAttention技术详解"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">PagedAttention 技术详解</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes3/docs/AI/vllm/vLLM实战部署指南"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">vLLM 实战部署指南</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_qSfz thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#什么是-vllm" class="table-of-contents__link toc-highlight">什么是 vLLM？</a><ul><li><a href="#核心特点" class="table-of-contents__link toc-highlight">核心特点</a></li><li><a href="#官方资源" class="table-of-contents__link toc-highlight">官方资源</a></li></ul></li><li><a href="#vllm-vs-ollama对比分析" class="table-of-contents__link toc-highlight">vLLM vs Ollama：对比分析</a><ul><li><a href="#deepseek-r1-distill-qwen-32b-模型对比" class="table-of-contents__link toc-highlight">DeepSeek-R1-Distill-Qwen-32B 模型对比</a></li></ul></li><li><a href="#核心技术pagedattention" class="table-of-contents__link toc-highlight">核心技术：PagedAttention</a><ul><li><a href="#传统-kv-cache-的问题" class="table-of-contents__link toc-highlight">传统 KV Cache 的问题</a></li><li><a href="#pagedattention-的解决方案" class="table-of-contents__link toc-highlight">PagedAttention 的解决方案</a></li><li><a href="#性能提升" class="table-of-contents__link toc-highlight">性能提升</a></li></ul></li><li><a href="#安装部署" class="table-of-contents__link toc-highlight">安装部署</a><ul><li><a href="#环境要求" class="table-of-contents__link toc-highlight">环境要求</a></li><li><a href="#使用-pip-安装" class="table-of-contents__link toc-highlight">使用 pip 安装</a></li><li><a href="#使用-docker-部署" class="table-of-contents__link toc-highlight">使用 Docker 部署</a></li><li><a href="#参数说明" class="table-of-contents__link toc-highlight">参数说明</a></li></ul></li><li><a href="#使用方法" class="table-of-contents__link toc-highlight">使用方法</a><ul><li><a href="#python-api" class="table-of-contents__link toc-highlight">Python API</a></li><li><a href="#openai-兼容-api" class="table-of-contents__link toc-highlight">OpenAI 兼容 API</a></li></ul></li><li><a href="#性能优化" class="table-of-contents__link toc-highlight">性能优化</a><ul><li><a href="#关键参数调优" class="table-of-contents__link toc-highlight">关键参数调优</a></li><li><a href="#最佳实践" class="table-of-contents__link toc-highlight">最佳实践</a></li></ul></li><li><a href="#常见模型显存占用参考" class="table-of-contents__link toc-highlight">常见模型显存占用参考</a></li><li><a href="#技术栈关系" class="table-of-contents__link toc-highlight">技术栈关系</a></li><li><a href="#总结" class="table-of-contents__link toc-highlight">总结</a><ul><li><a href="#何时选择-vllm" class="table-of-contents__link toc-highlight">何时选择 vLLM？</a></li><li><a href="#何时选择-ollama" class="table-of-contents__link toc-highlight">何时选择 Ollama？</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_EO6u"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_EO6u"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_EO6u"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes3/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_EO6u"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>