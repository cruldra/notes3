<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AI/深度学习/Tokenization和Embedding" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Tokenization和Embedding | Cruldra</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/Tokenization和Embedding"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Tokenization和Embedding | Cruldra"><meta data-rh="true" name="description" content="在深度学习中，Tokenization（标记化）和Embedding（嵌入） 是处理文本数据的关键步骤，分别解决不同的问题，共同将人类可读的文本转化为模型可理解的数值形式。以下是它们的核心作用及区别："><meta data-rh="true" property="og:description" content="在深度学习中，Tokenization（标记化）和Embedding（嵌入） 是处理文本数据的关键步骤，分别解决不同的问题，共同将人类可读的文本转化为模型可理解的数值形式。以下是它们的核心作用及区别："><link data-rh="true" rel="icon" href="/notes3/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/Tokenization和Embedding"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/Tokenization和Embedding" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/Tokenization和Embedding" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Tokenization和Embedding","item":"https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/Tokenization和Embedding"}]}</script><link rel="alternate" type="application/rss+xml" href="/notes3/blog/rss.xml" title="Cruldra RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/notes3/blog/atom.xml" title="Cruldra Atom Feed"><link rel="stylesheet" href="/notes3/assets/css/styles.f3dc2d00.css">
<script src="/notes3/assets/js/runtime~main.a656ceba.js" defer="defer"></script>
<script src="/notes3/assets/js/main.ed3b81bb.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme",window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-theme-choice","system"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes3/img/logo.svg"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><div role="region" aria-label="Skip to main content"><a class="skipToContent_kJiJ" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes3/"><div class="navbar__logo"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_NrnZ themedComponent--light_kIco"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_NrnZ themedComponent--dark_HCTy"></div><b class="navbar__title text--truncate">Cruldra</b></a><a class="navbar__item navbar__link" href="/notes3/docs/category/设计模式">JVM</a><a class="navbar__item navbar__link" href="/notes3/docs/category/css">前端</a><a class="navbar__item navbar__link" href="/notes3/docs/category/astrbot">工具</a><a class="navbar__item navbar__link" href="/notes3/docs/category/ai电竞酒店">个人</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/notes3/docs/AI/Agno/介绍">AI</a><a class="navbar__item navbar__link" href="/notes3/docs/category/内置模块">Python</a><a class="navbar__item navbar__link" href="/notes3/docs/category/actix-web">Rust</a><a class="navbar__item navbar__link" href="/notes3/docs/category/数据库系统">软件工程</a><a class="navbar__item navbar__link" href="/notes3/docs/category/上古卷轴5">游戏</a><a class="navbar__item navbar__link" href="/notes3/docs/Go/Go-Python-Java三语言全方位对比">Go</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_V3q0"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_YMCn"><div class="docsWrapper_UDzO"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_OA9t" type="button"></button><div class="docRoot_zblS"><aside class="theme-doc-sidebar-container docSidebarContainer_utvl"><div class="sidebarViewport_uicj"><div class="sidebar_wSJP"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_xz03"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agno/介绍"><span title="Agno" class="categoryLinkLabel_5XjO">Agno</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/DALLE成本计算"><span title="DALL-E 画图成本计算" class="linkLabel_VeW_">DALL-E 画图成本计算</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/MCP/MCP-Python-SDK"><span title="MCP" class="categoryLinkLabel_5XjO">MCP</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/Transformer"><span title="Transformer" class="linkLabel_VeW_">Transformer</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist" href="/notes3/docs/AI/vllm/"><span title="vLLM 学习资料" class="categoryLinkLabel_5XjO">vLLM 学习资料</span></a><button aria-label="Expand sidebar category &#x27;vLLM 学习资料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念1"><span title="一些概念1" class="linkLabel_VeW_">一些概念1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念2"><span title="一些概念2" class="linkLabel_VeW_">一些概念2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念3"><span title="一些概念3" class="linkLabel_VeW_">一些概念3</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念4"><span title="一些概念4" class="linkLabel_VeW_">一些概念4</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念5"><span title="一些概念5" class="linkLabel_VeW_">一些概念5</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/候选模型"><span title="候选模型" class="linkLabel_VeW_">候选模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/变分自编码器详解"><span title="变分自编码器（VAE）详解" class="linkLabel_VeW_">变分自编码器（VAE）详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型核心概念通俗解释"><span title="大模型核心概念通俗解释" class="linkLabel_VeW_">大模型核心概念通俗解释</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型训练中的随机种子：为什么需要它？"><span title="大模型训练中的随机种子：为什么需要它？" class="linkLabel_VeW_">大模型训练中的随机种子：为什么需要它？</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/嵌入和向量/Chroma与PGVector对比"><span title="嵌入和向量" class="categoryLinkLabel_5XjO">嵌入和向量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/感知机"><span title="感知机" class="linkLabel_VeW_">感知机</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/智能体"><span title="智能体(Agent)" class="linkLabel_VeW_">智能体(Agent)</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/notes3/docs/AI/深度学习/入门"><span title="深度学习" class="categoryLinkLabel_5XjO">深度学习</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/入门"><span title="入门" class="linkLabel_VeW_">入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes3/docs/AI/深度学习/Tokenization和Embedding"><span title="Tokenization和Embedding" class="linkLabel_VeW_">Tokenization和Embedding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/用低维向量来保留语义"><span title="用低维向量来保留语义" class="linkLabel_VeW_">用低维向量来保留语义</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/什么是低维向量"><span title="什么是低维向量" class="linkLabel_VeW_">什么是低维向量</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/为什么抛弃了OneHot编码"><span title="为什么抛弃了OneHot编码" class="linkLabel_VeW_">为什么抛弃了OneHot编码</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/CUDA"><span title="CUDA" class="linkLabel_VeW_">CUDA</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/理解大模型：从函数视角看AI的本质"><span title="理解大模型：从函数视角看AI的本质" class="linkLabel_VeW_">理解大模型：从函数视角看AI的本质</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/知识蒸馏"><span title="知识蒸馏" class="linkLabel_VeW_">知识蒸馏</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/联邦学习概念"><span title="联邦学习概念" class="linkLabel_VeW_">联邦学习概念</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_OIbK menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/通义千问/阿里云百炼"><span title="通义千问" class="categoryLinkLabel_5XjO">通义千问</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/金丝雀发布和AB测试"><span title="金丝雀发布和AB测试" class="linkLabel_VeW_">金丝雀发布和AB测试</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_e2u6"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_y0g3"><div class="docItemContainer_PZbB"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_I1XV" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes3/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_ZIEp"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">深度学习</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Tokenization和Embedding</span></li></ul></nav><div class="tocCollapsible_UUJj theme-doc-toc-mobile tocMobile_b9MH"><button type="button" class="clean-btn tocCollapsibleButton_zQap">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Tokenization和Embedding</h1></header><p>在深度学习中，<strong>Tokenization（标记化）<strong>和</strong>Embedding（嵌入）</strong> 是处理文本数据的关键步骤，分别解决不同的问题，共同将人类可读的文本转化为模型可理解的数值形式。以下是它们的核心作用及区别：</p>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="一tokenization标记化解决文本的结构化分解问题">一、<strong>Tokenization（标记化）：解决文本的结构化分解问题</strong><a href="#一tokenization标记化解决文本的结构化分解问题" class="hash-link" aria-label="Direct link to 一tokenization标记化解决文本的结构化分解问题" title="Direct link to 一tokenization标记化解决文本的结构化分解问题" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="1-是什么"><strong>1. 是什么？</strong><a href="#1-是什么" class="hash-link" aria-label="Direct link to 1-是什么" title="Direct link to 1-是什么" translate="no">​</a></h4>
<p>将原始文本（如句子、段落）分割成更小的单元（称为 <strong>token</strong>），例如：</p>
<ul>
<li class=""><strong>单词</strong>：<code>&quot;I love machine learning&quot;</code> → <code>[&quot;I&quot;, &quot;love&quot;, &quot;machine&quot;, &quot;learning&quot;]</code></li>
<li class=""><strong>子词</strong>（Subword）：<code>&quot;unhappy&quot;</code> → <code>[&quot;un&quot;, &quot;happy&quot;]</code>（解决未登录词问题）</li>
<li class=""><strong>字符</strong>：<code>&quot;cat&quot;</code> → <code>[&quot;c&quot;, &quot;a&quot;, &quot;t&quot;]</code></li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="2-为什么要做"><strong>2. 为什么要做？</strong><a href="#2-为什么要做" class="hash-link" aria-label="Direct link to 2-为什么要做" title="Direct link to 2-为什么要做" translate="no">​</a></h4>
<ul>
<li class=""><strong>计算机无法直接处理文本</strong>：模型需要数值输入，而文本是符号化的。</li>
<li class=""><strong>统一文本表示</strong>：处理大小写、标点、缩写（如<code>&quot;don&#x27;t&quot;</code>→<code>[&quot;do&quot;, &quot;n&#x27;t&quot;]</code>）。</li>
<li class=""><strong>应对语言复杂性</strong>：<!-- -->
<ul>
<li class="">中文无空格：<code>&quot;我爱机器学习&quot;</code>→<code>[&quot;我&quot;, &quot;爱&quot;, &quot;机器学习&quot;]</code>。</li>
<li class="">处理罕见词：通过子词（如<code>BPE</code>、<code>WordPiece</code>）拆分，避免模型遇到未见过词汇（OOV）。</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="3-常见方法"><strong>3. 常见方法</strong><a href="#3-常见方法" class="hash-link" aria-label="Direct link to 3-常见方法" title="Direct link to 3-常见方法" translate="no">​</a></h4>
<ul>
<li class=""><strong>空格分词</strong>：简单但无法处理复合词（如德语<code>&quot;Lebensversicherungsgesellschaft&quot;</code>）。</li>
<li class=""><strong>子词分词</strong>：<!-- -->
<ul>
<li class=""><strong>BPE（Byte-Pair Encoding）</strong>：合并高频字符对（如将<code>&quot;low&quot;</code>和<code>&quot;lower&quot;</code>拆分为<code>[&quot;low&quot;, &quot;er&quot;]</code>）。</li>
<li class=""><strong>WordPiece</strong>（被BERT采用）：基于概率合并子词。</li>
</ul>
</li>
<li class=""><strong>SentencePiece</strong>：支持多语言，直接处理原始文本（包括空格）。</li>
</ul>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="二embedding嵌入解决语义的数值化表示问题">二、<strong>Embedding（嵌入）：解决语义的数值化表示问题</strong><a href="#二embedding嵌入解决语义的数值化表示问题" class="hash-link" aria-label="Direct link to 二embedding嵌入解决语义的数值化表示问题" title="Direct link to 二embedding嵌入解决语义的数值化表示问题" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="1-是什么-1"><strong>1. 是什么？</strong><a href="#1-是什么-1" class="hash-link" aria-label="Direct link to 1-是什么-1" title="Direct link to 1-是什么-1" translate="no">​</a></h4>
<p>将每个 <strong>token</strong> 映射为一个低维稠密向量（例如300维），捕捉其语义信息。<br>
<!-- -->例如：<code>&quot;cat&quot;</code> → <code>[0.2, -0.5, 1.3, ...]</code>，<code>&quot;dog&quot;</code> → <code>[0.3, -0.4, 1.2, ...]</code>（两者向量接近）。</p>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="2-为什么要做-1"><strong>2. 为什么要做？</strong><a href="#2-为什么要做-1" class="hash-link" aria-label="Direct link to 2-为什么要做-1" title="Direct link to 2-为什么要做-1" translate="no">​</a></h4>
<ul>
<li class=""><strong>符号→数值转换</strong>：模型只能处理数值，但简单的One-Hot编码（如<code>[0,0,1,0]</code>）维度高且无法表达语义。</li>
<li class=""><strong>捕捉语义关系</strong>：<!-- -->
<ul>
<li class="">相似词距离近：<code>&quot;king&quot;</code>和<code>&quot;queen&quot;</code>的向量接近。</li>
<li class="">类比关系：<code>&quot;king&quot; - &quot;man&quot; + &quot;woman&quot; ≈ &quot;queen&quot;</code>。</li>
</ul>
</li>
<li class=""><strong>降维与泛化</strong>：低维向量（如300维）比One-Hot（数万维）更高效，且能泛化到未见的用法。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="3-常见方法-1"><strong>3. 常见方法</strong><a href="#3-常见方法-1" class="hash-link" aria-label="Direct link to 3-常见方法-1" title="Direct link to 3-常见方法-1" translate="no">​</a></h4>
<ul>
<li class=""><strong>静态嵌入</strong>（预训练）：<!-- -->
<ul>
<li class=""><strong>Word2Vec</strong>：基于上下文预测（Skip-Gram/CBOW）。</li>
<li class=""><strong>GloVe</strong>：基于全局词共现矩阵。</li>
</ul>
</li>
<li class=""><strong>动态嵌入</strong>（上下文相关）：<!-- -->
<ul>
<li class=""><strong>Transformer模型</strong>（如BERT、GPT）：同一词在不同上下文的向量不同。<br>
<!-- -->例如，<code>&quot;bank&quot;</code>在<code>&quot;river bank&quot;</code>和<code>&quot;bank account&quot;</code>中的向量不同。</li>
</ul>
</li>
</ul>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="三两者的关系与协作">三、两者的关系与协作<a href="#三两者的关系与协作" class="hash-link" aria-label="Direct link to 三、两者的关系与协作" title="Direct link to 三、两者的关系与协作" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="1-处理流程"><strong>1. 处理流程</strong><a href="#1-处理流程" class="hash-link" aria-label="Direct link to 1-处理流程" title="Direct link to 1-处理流程" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_iV14 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_jh8H"><pre tabindex="0" class="prism-code language-text codeBlock_E9uv thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_Kv4h"><span class="token-line" style="color:#393A34"><span class="token plain">原始文本 → Tokenization → Tokens → Embedding → 向量序列 → 输入模型</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="2-协作示例"><strong>2. 协作示例</strong><a href="#2-协作示例" class="hash-link" aria-label="Direct link to 2-协作示例" title="Direct link to 2-协作示例" translate="no">​</a></h4>
<p>假设输入句子：<code>&quot;The cat sat on the mat.&quot;</code></p>
<ol>
<li class=""><strong>Tokenization</strong>：分割为 <code>[&quot;The&quot;, &quot;cat&quot;, &quot;sat&quot;, &quot;on&quot;, &quot;the&quot;, &quot;mat&quot;, &quot;.&quot;]</code>。</li>
<li class=""><strong>Embedding</strong>：每个token转换为向量，形成矩阵（形状：<code>7 tokens × 300 dim</code>）。</li>
</ol>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="3-关键区别"><strong>3. 关键区别</strong><a href="#3-关键区别" class="hash-link" aria-label="Direct link to 3-关键区别" title="Direct link to 3-关键区别" translate="no">​</a></h4>
<table><thead><tr><th></th><th>Tokenization</th><th>Embedding</th></tr></thead><tbody><tr><td><strong>目标</strong></td><td>结构化分解文本</td><td>语义的数值化表示</td></tr><tr><td><strong>输入/输出</strong></td><td>文本 → Tokens</td><td>Tokens → 向量</td></tr><tr><td><strong>核心问题</strong></td><td>如何处理复杂语言结构？</td><td>如何让向量保留语义信息？</td></tr></tbody></table>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="四实际应用中的挑战">四、实际应用中的挑战<a href="#四实际应用中的挑战" class="hash-link" aria-label="Direct link to 四、实际应用中的挑战" title="Direct link to 四、实际应用中的挑战" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="1-tokenization的挑战"><strong>1. Tokenization的挑战</strong><a href="#1-tokenization的挑战" class="hash-link" aria-label="Direct link to 1-tokenization的挑战" title="Direct link to 1-tokenization的挑战" translate="no">​</a></h4>
<ul>
<li class=""><strong>语言差异</strong>：中文分词 vs. 英文空格分词。</li>
<li class=""><strong>未登录词（OOV）</strong>：子词分词（如<code>BPE</code>）通过拆分解决。</li>
<li class=""><strong>歧义</strong>：例如<code>&quot;苹果&quot;</code>（水果 vs. 公司）需要上下文区分（动态Embedding解决）。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_FzkC" id="2-embedding的挑战"><strong>2. Embedding的挑战</strong><a href="#2-embedding的挑战" class="hash-link" aria-label="Direct link to 2-embedding的挑战" title="Direct link to 2-embedding的挑战" translate="no">​</a></h4>
<ul>
<li class=""><strong>一词多义</strong>：静态嵌入（如Word2Vec）无法处理，需动态嵌入（如BERT）。</li>
<li class=""><strong>计算效率</strong>：大词表的嵌入层可能占用大量内存（可通过参数共享或压缩优化）。</li>
</ul>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_FzkC" id="五总结">五、总结<a href="#五总结" class="hash-link" aria-label="Direct link to 五、总结" title="Direct link to 五、总结" translate="no">​</a></h3>
<ul>
<li class=""><strong>Tokenization</strong>：将文本分解为模型可处理的基本单元（token），解决<strong>结构化分解</strong>问题。</li>
<li class=""><strong>Embedding</strong>：将token映射为富含语义的向量，解决<strong>语义表示</strong>问题。</li>
</ul>
<p>二者共同构建了文本到数值的桥梁，是深度学习模型（如BERT、GPT）处理语言任务的基础。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_RM2i"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/深度学习/Tokenization和Embedding.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_NBA7" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_Ng_4"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes3/docs/AI/深度学习/入门"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">入门</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes3/docs/AI/深度学习/用低维向量来保留语义"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">用低维向量来保留语义</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_qSfz thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#一tokenization标记化解决文本的结构化分解问题" class="table-of-contents__link toc-highlight">一、<strong>Tokenization（标记化）：解决文本的结构化分解问题</strong></a></li><li><a href="#二embedding嵌入解决语义的数值化表示问题" class="table-of-contents__link toc-highlight">二、<strong>Embedding（嵌入）：解决语义的数值化表示问题</strong></a></li><li><a href="#三两者的关系与协作" class="table-of-contents__link toc-highlight">三、两者的关系与协作</a></li><li><a href="#四实际应用中的挑战" class="table-of-contents__link toc-highlight">四、实际应用中的挑战</a></li><li><a href="#五总结" class="table-of-contents__link toc-highlight">五、总结</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_EO6u"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_EO6u"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_EO6u"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes3/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_EO6u"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>