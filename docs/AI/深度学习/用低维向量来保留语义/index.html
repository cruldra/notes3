<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AI/深度学习/用低维向量来保留语义" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.1">
<title data-rh="true">用低维向量来保留语义 | Cruldra</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/用低维向量来保留语义"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="用低维向量来保留语义 | Cruldra"><meta data-rh="true" name="description" content="在深度学习中，使用低维向量表示语义的核心思想是通过稠密、连续的数值空间捕捉词语或概念的内在关系。这种表示方式并非直接“解释”语义，而是通过数据驱动的方式，让模型在训练过程中自动学习语义的数学表达。以下从几个关键角度解释为什么低维向量能有效表示语义："><meta data-rh="true" property="og:description" content="在深度学习中，使用低维向量表示语义的核心思想是通过稠密、连续的数值空间捕捉词语或概念的内在关系。这种表示方式并非直接“解释”语义，而是通过数据驱动的方式，让模型在训练过程中自动学习语义的数学表达。以下从几个关键角度解释为什么低维向量能有效表示语义："><link data-rh="true" rel="icon" href="/notes3/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/用低维向量来保留语义"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/用低维向量来保留语义" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/用低维向量来保留语义" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"用低维向量来保留语义","item":"https://your-docusaurus-site.example.com/notes3/docs/AI/深度学习/用低维向量来保留语义"}]}</script><link rel="alternate" type="application/rss+xml" href="/notes3/blog/rss.xml" title="Cruldra RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/notes3/blog/atom.xml" title="Cruldra Atom Feed"><link rel="stylesheet" href="/notes3/assets/css/styles.da241bce.css">
<script src="/notes3/assets/js/runtime~main.f2a2e49e.js" defer="defer"></script>
<script src="/notes3/assets/js/main.05821ba9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme",window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-theme-choice","system"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes3/img/logo.svg"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><div role="region" aria-label="Skip to main content"><a class="skipToContent_HuOE" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes3/"><div class="navbar__logo"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E0TY themedComponent--light_oQTo"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E0TY themedComponent--dark_xnBK"></div><b class="navbar__title text--truncate">Cruldra</b></a><a class="navbar__item navbar__link" href="/notes3/docs/category/设计模式">JVM</a><a class="navbar__item navbar__link" href="/notes3/docs/category/css">前端</a><a class="navbar__item navbar__link" href="/notes3/docs/category/astrbot">工具</a><a class="navbar__item navbar__link" href="/notes3/docs/category/ai电竞酒店">个人</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/notes3/docs/AI/Agno/介绍">AI</a><a class="navbar__item navbar__link" href="/notes3/docs/category/内置模块">Python</a><a class="navbar__item navbar__link" href="/notes3/docs/category/actix-web">Rust</a><a class="navbar__item navbar__link" href="/notes3/docs/category/数据库系统">软件工程</a><a class="navbar__item navbar__link" href="/notes3/docs/category/上古卷轴5">游戏</a><a class="navbar__item navbar__link" href="/notes3/docs/Go/Go语言常用语法">Go</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_lmNG"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_ec9K"><div class="docsWrapper_T_Kj"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_U0vv" type="button"></button><div class="docRoot_n2jZ"><aside class="theme-doc-sidebar-container docSidebarContainer_BcoR"><div class="sidebarViewport_Cc21"><div class="sidebar_OHx_"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_n4En"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_smok menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agno/介绍"><span title="Agno" class="categoryLinkLabel_X2zX">Agno</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/DALLE成本计算"><span title="DALL-E 画图成本计算" class="linkLabel_j3lx">DALL-E 画图成本计算</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_smok menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/MCP/MCP-Python-SDK"><span title="MCP" class="categoryLinkLabel_X2zX">MCP</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/Transformer"><span title="Transformer" class="linkLabel_j3lx">Transformer</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_smok menu__link menu__link--sublist" href="/notes3/docs/AI/vllm/"><span title="vLLM 学习资料" class="categoryLinkLabel_X2zX">vLLM 学习资料</span></a><button aria-label="Expand sidebar category &#x27;vLLM 学习资料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念1"><span title="一些概念1" class="linkLabel_j3lx">一些概念1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念2"><span title="一些概念2" class="linkLabel_j3lx">一些概念2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念3"><span title="一些概念3" class="linkLabel_j3lx">一些概念3</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念4"><span title="一些概念4" class="linkLabel_j3lx">一些概念4</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念5"><span title="一些概念5" class="linkLabel_j3lx">一些概念5</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/候选模型"><span title="候选模型" class="linkLabel_j3lx">候选模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/变分自编码器详解"><span title="变分自编码器（VAE）详解" class="linkLabel_j3lx">变分自编码器（VAE）详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型核心概念通俗解释"><span title="大模型核心概念通俗解释" class="linkLabel_j3lx">大模型核心概念通俗解释</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型训练中的随机种子：为什么需要它？"><span title="大模型训练中的随机种子：为什么需要它？" class="linkLabel_j3lx">大模型训练中的随机种子：为什么需要它？</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_smok menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/嵌入和向量/Chroma与PGVector对比"><span title="嵌入和向量" class="categoryLinkLabel_X2zX">嵌入和向量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/感知机"><span title="感知机" class="linkLabel_j3lx">感知机</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/智能体"><span title="智能体(Agent)" class="linkLabel_j3lx">智能体(Agent)</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_smok menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/notes3/docs/AI/深度学习/入门"><span title="深度学习" class="categoryLinkLabel_X2zX">深度学习</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/入门"><span title="入门" class="linkLabel_j3lx">入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/Tokenization和Embedding"><span title="Tokenization和Embedding" class="linkLabel_j3lx">Tokenization和Embedding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes3/docs/AI/深度学习/用低维向量来保留语义"><span title="用低维向量来保留语义" class="linkLabel_j3lx">用低维向量来保留语义</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/什么是低维向量"><span title="什么是低维向量" class="linkLabel_j3lx">什么是低维向量</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/为什么抛弃了OneHot编码"><span title="为什么抛弃了OneHot编码" class="linkLabel_j3lx">为什么抛弃了OneHot编码</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/深度学习/CUDA"><span title="CUDA" class="linkLabel_j3lx">CUDA</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/理解大模型：从函数视角看AI的本质"><span title="理解大模型：从函数视角看AI的本质" class="linkLabel_j3lx">理解大模型：从函数视角看AI的本质</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/知识蒸馏"><span title="知识蒸馏" class="linkLabel_j3lx">知识蒸馏</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/联邦学习概念"><span title="联邦学习概念" class="linkLabel_j3lx">联邦学习概念</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_smok menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/通义千问/阿里云百炼"><span title="通义千问" class="categoryLinkLabel_X2zX">通义千问</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/金丝雀发布和AB测试"><span title="金丝雀发布和AB测试" class="linkLabel_j3lx">金丝雀发布和AB测试</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_vrpX"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_WIWH"><div class="docItemContainer_zhTd"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_kL0w" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes3/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_y6sH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">深度学习</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">用低维向量来保留语义</span></li></ul></nav><div class="tocCollapsible_sNig theme-doc-toc-mobile tocMobile_AD9K"><button type="button" class="clean-btn tocCollapsibleButton_dkdr">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>用低维向量来保留语义</h1></header><p>在深度学习中，使用低维向量表示语义的核心思想是通过<strong>稠密、连续的数值空间</strong>捕捉词语或概念的<strong>内在关系</strong>。这种表示方式并非直接“解释”语义，而是通过数据驱动的方式，让模型在训练过程中<strong>自动学习语义的数学表达</strong>。以下从几个关键角度解释为什么低维向量能有效表示语义：</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_qHQm" id="一从符号到语义传统方法的局限性">一、<strong>从符号到语义：传统方法的局限性</strong><a href="#一从符号到语义传统方法的局限性" class="hash-link" aria-label="Direct link to 一从符号到语义传统方法的局限性" title="Direct link to 一从符号到语义传统方法的局限性" translate="no">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="1-one-hot-编码的缺陷">1. <strong>One-Hot 编码的缺陷</strong><a href="#1-one-hot-编码的缺陷" class="hash-link" aria-label="Direct link to 1-one-hot-编码的缺陷" title="Direct link to 1-one-hot-编码的缺陷" translate="no">​</a></h4>
<ul>
<li><strong>问题</strong>：传统方法（如One-Hot编码）将每个词表示为高维稀疏向量（例如词典大小为10万，则每个词是10万维的向量，其中仅一个位置为1，其余为0）。</li>
<li><strong>局限性</strong>：<!-- -->
<ul>
<li><strong>无法表达语义相似性</strong>：所有词向量彼此正交，例如“猫”和“狗”的向量距离与“猫”和“飞机”的距离相同。</li>
<li><strong>维度灾难</strong>：高维向量导致计算和存储效率极低。</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="2-低维稠密向量的优势">2. <strong>低维稠密向量的优势</strong><a href="#2-低维稠密向量的优势" class="hash-link" aria-label="Direct link to 2-低维稠密向量的优势" title="Direct link to 2-低维稠密向量的优势" translate="no">​</a></h4>
<ul>
<li><strong>核心思想</strong>：将词映射到低维连续空间（如300维），向量中的每个维度不再对应某个具体符号，而是隐含的<strong>语义特征</strong>。</li>
<li><strong>直观理解</strong>：<!-- -->
<ul>
<li>向量空间中的“方向”和“距离”反映语义关系。</li>
<li>例如：<!-- -->
<ul>
<li>“猫”的向量 ≈ [0.3, -0.2, 1.5, ...]</li>
<li>“狗”的向量 ≈ [0.4, -0.1, 1.6, ...]</li>
<li>“飞机”的向量 ≈ [-0.8, 1.0, 0.2, ...]</li>
</ul>
</li>
<li>计算余弦相似度时，“猫”和“狗”的向量更接近，而“猫”与“飞机”差异较大。</li>
</ul>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_qHQm" id="二为什么低维向量能捕捉语义">二、<strong>为什么低维向量能捕捉语义？</strong><a href="#二为什么低维向量能捕捉语义" class="hash-link" aria-label="Direct link to 二为什么低维向量能捕捉语义" title="Direct link to 二为什么低维向量能捕捉语义" translate="no">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="1-分布式假设distributional-hypothesis">1. <strong>分布式假设（Distributional Hypothesis）</strong><a href="#1-分布式假设distributional-hypothesis" class="hash-link" aria-label="Direct link to 1-分布式假设distributional-hypothesis" title="Direct link to 1-分布式假设distributional-hypothesis" translate="no">​</a></h4>
<ul>
<li><strong>核心理论</strong>：<br>
<!-- -->“一个词的语义由其上下文决定”（You shall know a word by the company it keeps）。<br>
<!-- -->例如，“猫”和“狗”经常出现在相似的上下文（如“宠物”“喂食”），因此它们的向量会趋近。</li>
<li><strong>实现方式</strong>：<br>
<!-- -->模型通过大量文本数据，学习预测词的上下文（如Word2Vec），或直接建模词与上下文的共现关系（如GloVe）。在此过程中，语义相似的词被迫在向量空间中靠近。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="2-低维空间的数学性质">2. <strong>低维空间的数学性质</strong><a href="#2-低维空间的数学性质" class="hash-link" aria-label="Direct link to 2-低维空间的数学性质" title="Direct link to 2-低维空间的数学性质" translate="no">​</a></h4>
<ul>
<li><strong>稠密性</strong>：低维向量中的每个维度都是稠密浮点数（非0/1），允许通过<strong>数值运算</strong>表达复杂关系。<!-- -->
<ul>
<li>例如：<!-- -->
<ul>
<li>向量加减法可表达语义类比：<br>
<code>“国王” - “男性” + “女性” ≈ “女王”</code></li>
<li>向量方向可表示抽象属性（如“性别”“类别”）。</li>
</ul>
</li>
</ul>
</li>
<li><strong>降维与泛化</strong>：低维空间过滤了噪声，保留了最重要的语义特征，使模型更易泛化到新任务。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="3-动态嵌入的进一步突破">3. <strong>动态嵌入的进一步突破</strong><a href="#3-动态嵌入的进一步突破" class="hash-link" aria-label="Direct link to 3-动态嵌入的进一步突破" title="Direct link to 3-动态嵌入的进一步突破" translate="no">​</a></h4>
<ul>
<li><strong>上下文相关</strong>：传统静态嵌入（如Word2Vec）为每个词赋予固定向量，无法处理多义词。<!-- -->
<ul>
<li><strong>动态嵌入模型（如BERT）</strong>：根据上下文动态调整词向量。<br>
<!-- -->例如，“苹果”在句子中的不同含义：<!-- -->
<ul>
<li><code>“我吃了一个苹果”</code> → 向量靠近“水果”。</li>
<li><code>“苹果发布了新手机”</code> → 向量靠近“公司”。</li>
</ul>
</li>
</ul>
</li>
<li><strong>多层级抽象</strong>：通过Transformer等模型，向量能捕捉词、短语、句子的多粒度语义。</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_qHQm" id="三低维向量的训练过程">三、<strong>低维向量的训练过程</strong><a href="#三低维向量的训练过程" class="hash-link" aria-label="Direct link to 三低维向量的训练过程" title="Direct link to 三低维向量的训练过程" translate="no">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="1-训练目标驱动语义学习">1. <strong>训练目标驱动语义学习</strong><a href="#1-训练目标驱动语义学习" class="hash-link" aria-label="Direct link to 1-训练目标驱动语义学习" title="Direct link to 1-训练目标驱动语义学习" translate="no">​</a></h4>
<ul>
<li><strong>任务设计</strong>：模型通过预测目标（如预测上下文词、分类任务）间接学习语义。<!-- -->
<ul>
<li><strong>Word2Vec</strong>：通过Skip-Gram/CBOW预测邻近词。</li>
<li><strong>BERT</strong>：通过掩码语言模型（Masked Language Model）预测被遮盖的词。</li>
</ul>
</li>
<li><strong>反向传播优化</strong>：模型调整向量，使得语义相似的词在任务中表现更好。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="2-可视化理解以word2vec为例">2. <strong>可视化理解（以Word2Vec为例）</strong><a href="#2-可视化理解以word2vec为例" class="hash-link" aria-label="Direct link to 2-可视化理解以word2vec为例" title="Direct link to 2-可视化理解以word2vec为例" translate="no">​</a></h4>
<ul>
<li><strong>步骤</strong>：<!-- -->
<ol>
<li>初始化随机向量（如300维）。</li>
<li>输入句子“The cat sits on the mat”。</li>
<li>模型尝试用“cat”的向量预测“sits”。</li>
<li>若预测错误，则通过梯度下降调整“cat”和“sits”的向量，使它们更接近。</li>
</ol>
</li>
<li><strong>结果</strong>：频繁共现的词（如“cat”和“mat”）向量逐渐靠近。</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_qHQm" id="四为什么低维足够">四、<strong>为什么“低维”足够？</strong><a href="#四为什么低维足够" class="hash-link" aria-label="Direct link to 四为什么低维足够" title="Direct link to 四为什么低维足够" translate="no">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="1-维度选择的平衡">1. <strong>维度选择的平衡</strong><a href="#1-维度选择的平衡" class="hash-link" aria-label="Direct link to 1-维度选择的平衡" title="Direct link to 1-维度选择的平衡" translate="no">​</a></h4>
<ul>
<li><strong>经验值</strong>：常用嵌入维度为256~1024维。<!-- -->
<ul>
<li>维度太低：无法捕捉复杂语义（如无法区分近义词）。</li>
<li>维度太高：增加计算成本，可能引入噪声（过拟合）。</li>
</ul>
</li>
<li><strong>实验验证</strong>：实践中通过任务性能选择最优维度（如NLP任务中300维是常用基准）。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="2-压缩与信息保留">2. <strong>压缩与信息保留</strong><a href="#2-压缩与信息保留" class="hash-link" aria-label="Direct link to 2-压缩与信息保留" title="Direct link to 2-压缩与信息保留" translate="no">​</a></h4>
<ul>
<li><strong>奇异值分解（SVD）</strong>：数学上证明，低维空间可以保留高维数据的主要信息（类似PCA降维）。</li>
<li><strong>深度学习优势</strong>：神经网络能自动学习如何压缩信息，保留对任务有用的特征。</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_qHQm" id="五实际应用中的语义表达">五、<strong>实际应用中的语义表达</strong><a href="#五实际应用中的语义表达" class="hash-link" aria-label="Direct link to 五实际应用中的语义表达" title="Direct link to 五实际应用中的语义表达" translate="no">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="1-语义相似度计算">1. <strong>语义相似度计算</strong><a href="#1-语义相似度计算" class="hash-link" aria-label="Direct link to 1-语义相似度计算" title="Direct link to 1-语义相似度计算" translate="no">​</a></h4>
<ul>
<li><strong>代码示例（余弦相似度）</strong>：<!-- -->
<div class="language-python codeBlockContainer_El0U theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_AwBu"><pre tabindex="0" class="prism-code language-python codeBlock_D9uD thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_hMzE"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">metrics</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pairwise </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> cosine_similarity</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 词向量示例（实际中从预训练模型加载）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vector_cat </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">array</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0.3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.5</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vector_dog </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">array</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0.4</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.6</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vector_plane </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">array</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">0.8</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 计算相似度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">cosine_similarity</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">vector_cat</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">vector_dog</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 输出接近1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">cosine_similarity</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">vector_cat</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">vector_plane</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 输出接近0</span><br></span></code></pre></div></div>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_qHQm" id="2-多语言与跨模态语义">2. <strong>多语言与跨模态语义</strong><a href="#2-多语言与跨模态语义" class="hash-link" aria-label="Direct link to 2-多语言与跨模态语义" title="Direct link to 2-多语言与跨模态语义" translate="no">​</a></h4>
<ul>
<li><strong>跨语言嵌入</strong>：将不同语言的词映射到同一空间（如“猫”的中文向量和“cat”的英文向量接近）。</li>
<li><strong>图像-文本对齐</strong>：CLIP等模型将图片和文本映射到同一空间，实现跨模态检索。</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_qHQm" id="六总结">六、<strong>总结</strong><a href="#六总结" class="hash-link" aria-label="Direct link to 六总结" title="Direct link to 六总结" translate="no">​</a></h3>
<p>低维向量能表示语义，本质是通过<strong>数据驱动的压缩与抽象</strong>：</p>
<ol>
<li><strong>分布式假设</strong>：利用上下文信息建模语义关系。</li>
<li><strong>稠密向量空间</strong>：通过连续数值运算表达复杂语义。</li>
<li><strong>任务驱动训练</strong>：模型在优化目标中间接学习语义表示。</li>
</ol>
<p>这种表示方式并非完美（如无法完全解决歧义），但已成为深度学习处理语义的基石，支撑了BERT、GPT等模型的强大能力。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/深度学习/用低维向量来保留语义.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_HnUL" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_DcQK"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes3/docs/AI/深度学习/Tokenization和Embedding"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Tokenization和Embedding</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes3/docs/AI/深度学习/什么是低维向量"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">什么是低维向量</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_AvJD thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#一从符号到语义传统方法的局限性" class="table-of-contents__link toc-highlight">一、<strong>从符号到语义：传统方法的局限性</strong></a></li><li><a href="#二为什么低维向量能捕捉语义" class="table-of-contents__link toc-highlight">二、<strong>为什么低维向量能捕捉语义？</strong></a></li><li><a href="#三低维向量的训练过程" class="table-of-contents__link toc-highlight">三、<strong>低维向量的训练过程</strong></a></li><li><a href="#四为什么低维足够" class="table-of-contents__link toc-highlight">四、<strong>为什么“低维”足够？</strong></a></li><li><a href="#五实际应用中的语义表达" class="table-of-contents__link toc-highlight">五、<strong>实际应用中的语义表达</strong></a></li><li><a href="#六总结" class="table-of-contents__link toc-highlight">六、<strong>总结</strong></a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_YFPC"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_YFPC"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_YFPC"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes3/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_YFPC"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>