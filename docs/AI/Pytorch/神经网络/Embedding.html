<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AI/Pytorch/神经网络/Embedding" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Embedding | Cruldra</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/神经网络/Embedding"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Embedding | Cruldra"><meta data-rh="true" name="description" content="torch.nn.Embedding 是 PyTorch 中用于处理离散分类数据（Categorical Data）的核心模块，本质上是一个可学习的查找表（Lookup Table）。它将高维稀疏的索引（Indices）映射为低维稠密的连续向量（Dense Vectors）。"><meta data-rh="true" property="og:description" content="torch.nn.Embedding 是 PyTorch 中用于处理离散分类数据（Categorical Data）的核心模块，本质上是一个可学习的查找表（Lookup Table）。它将高维稀疏的索引（Indices）映射为低维稠密的连续向量（Dense Vectors）。"><link data-rh="true" rel="icon" href="/notes3/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/神经网络/Embedding"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/神经网络/Embedding" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/神经网络/Embedding" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Embedding","item":"https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/神经网络/Embedding"}]}</script><link rel="alternate" type="application/rss+xml" href="/notes3/blog/rss.xml" title="Cruldra RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/notes3/blog/atom.xml" title="Cruldra Atom Feed"><link rel="stylesheet" href="/notes3/assets/css/styles.371c6534.css">
<script src="/notes3/assets/js/runtime~main.c039e8de.js" defer="defer"></script>
<script src="/notes3/assets/js/main.f9912a11.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme",window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-theme-choice","system"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes3/img/logo.svg"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><div role="region" aria-label="Skip to main content"><a class="skipToContent_aA1M" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes3/"><div class="navbar__logo"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E3Xm themedComponent--light_DVqC"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E3Xm themedComponent--dark_B_L3"></div><b class="navbar__title text--truncate">Cruldra</b></a><a class="navbar__item navbar__link" href="/notes3/docs/category/设计模式">JVM</a><a class="navbar__item navbar__link" href="/notes3/docs/category/css">前端</a><a class="navbar__item navbar__link" href="/notes3/docs/category/astrbot">工具</a><a class="navbar__item navbar__link" href="/notes3/docs/category/ai电竞酒店">个人</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/notes3/docs/AI/ACP/架构">AI</a><a class="navbar__item navbar__link" href="/notes3/docs/category/内置模块">Python</a><a class="navbar__item navbar__link" href="/notes3/docs/category/actix-web">Rust</a><a class="navbar__item navbar__link" href="/notes3/docs/category/数据库系统">软件工程</a><a class="navbar__item navbar__link" href="/notes3/docs/category/上古卷轴5">游戏</a><a class="navbar__item navbar__link" href="/notes3/docs/Go/Go-Python-Java三语言全方位对比">Go</a><a class="navbar__item navbar__link" href="/notes3/docs/Hardware/GPU工作原理">硬件</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_PufJ"><div class="navbar__search searchBarContainer_r6C1" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_G4_y" value=""><div class="loadingRing__Zfe searchBarLoadingRing_f0pn"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_ctfR"><div class="docsWrapper_ByIB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_KwvU" type="button"></button><div class="docRoot_hD6z"><aside class="theme-doc-sidebar-container docSidebarContainer_KuHC"><div class="sidebarViewport_LCjr"><div class="sidebar_L77d"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_VYAF"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/ACP/架构"><span title="ACP" class="categoryLinkLabel_FHN4">ACP</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agent Skills/什么是Skills"><span title="Agent Skills" class="categoryLinkLabel_FHN4">Agent Skills</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agno/介绍"><span title="Agno" class="categoryLinkLabel_FHN4">Agno</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/CrewAI/CLI"><span title="CrewAI" class="categoryLinkLabel_FHN4">CrewAI</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/DALLE成本计算"><span title="DALL-E 画图成本计算" class="linkLabel__RqX">DALL-E 画图成本计算</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/LLamaIndex/CitationQueryEngine"><span title="LLamaIndex" class="categoryLinkLabel_FHN4">LLamaIndex</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/MCP/MCP-Python-SDK"><span title="MCP" class="categoryLinkLabel_FHN4">MCP</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/notes3/docs/AI/Pytorch/介绍"><span title="Pytorch" class="categoryLinkLabel_FHN4">Pytorch</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/介绍"><span title="介绍" class="linkLabel__RqX">介绍</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/简介"><span title="神经网络" class="categoryLinkLabel_FHN4">神经网络</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/简介"><span title="简介" class="linkLabel__RqX">简介</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/CrossEntropyLoss"><span title="CrossEntropyLoss" class="linkLabel__RqX">CrossEntropyLoss</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/Dropout"><span title="Dropout" class="linkLabel__RqX">Dropout</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/Embedding"><span title="Embedding" class="linkLabel__RqX">Embedding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/F"><span title="F" class="linkLabel__RqX">F</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/Linear"><span title="Linear" class="linkLabel__RqX">Linear</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/ModuleList"><span title="ModuleList" class="linkLabel__RqX">ModuleList</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/init"><span title="init" class="linkLabel__RqX">init</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/示例/linear_semantic_distance"><span title="示例" class="categoryLinkLabel_FHN4">示例</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/grad_scaler"><span title="CUDA" class="categoryLinkLabel_FHN4">CUDA</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/arange"><span title="arange" class="linkLabel__RqX">arange</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/cat"><span title="cat" class="linkLabel__RqX">cat</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/outer"><span title="outer" class="linkLabel__RqX">outer</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/从头开始训练自己的大模型"><span title="从头开始训练自己的大模型 - 流程图" class="linkLabel__RqX">从头开始训练自己的大模型 - 流程图</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/优化/简介"><span title="优化" class="categoryLinkLabel_FHN4">优化</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/分布式训练/DistributedDataParallel"><span title="分布式训练" class="categoryLinkLabel_FHN4">分布式训练</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/分词器与词嵌入完整流程演示"><span title="分词器与词嵌入完整流程演示" class="linkLabel__RqX">分词器与词嵌入完整流程演示</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/参考/1"><span title="参考" class="categoryLinkLabel_FHN4">参考</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/工具/简介"><span title="工具" class="categoryLinkLabel_FHN4">工具</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/张量/如何看懂张量形状"><span title="张量" class="categoryLinkLabel_FHN4">张量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/混合精度浮点数"><span title="混合精度浮点数" class="linkLabel__RqX">混合精度浮点数</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/SentencePiece/简介"><span title="SentencePiece" class="categoryLinkLabel_FHN4">SentencePiece</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/Transformer"><span title="Transformer" class="linkLabel__RqX">Transformer</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/cv_graph"><span title="计算机视觉 (CV) 知识图谱" class="linkLabel__RqX">计算机视觉 (CV) 知识图谱</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/datasets/demo"><span title="datasets" class="categoryLinkLabel_FHN4">datasets</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/huggingface_hub/简介"><span title="huggingface_hub" class="categoryLinkLabel_FHN4">huggingface_hub</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/llm_graph"><span title="LLM 知识图谱" class="linkLabel__RqX">LLM 知识图谱</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/tiktoken/简介"><span title="tiktoken" class="categoryLinkLabel_FHN4">tiktoken</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/tokenizers/和tiktoken的区别"><span title="tokenizers" class="categoryLinkLabel_FHN4">tokenizers</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/transformers/分词器/PreTrainedTokenizer"><span title="transformers" class="categoryLinkLabel_FHN4">transformers</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist" href="/notes3/docs/AI/vllm"><span title="vLLM 学习资料" class="categoryLinkLabel_FHN4">vLLM 学习资料</span></a><button aria-label="Expand sidebar category &#x27;vLLM 学习资料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/wandb/简介"><span title="wandb" class="categoryLinkLabel_FHN4">wandb</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念1"><span title="一些概念1" class="linkLabel__RqX">一些概念1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念2"><span title="一些概念2" class="linkLabel__RqX">一些概念2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念3"><span title="一些概念3" class="linkLabel__RqX">一些概念3</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念4"><span title="一些概念4" class="linkLabel__RqX">一些概念4</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念5"><span title="一些概念5" class="linkLabel__RqX">一些概念5</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/候选模型"><span title="候选模型" class="linkLabel__RqX">候选模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/变分自编码器详解"><span title="变分自编码器（VAE）详解" class="linkLabel__RqX">变分自编码器（VAE）详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型核心概念通俗解释"><span title="大模型核心概念通俗解释" class="linkLabel__RqX">大模型核心概念通俗解释</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型训练中的随机种子：为什么需要它？"><span title="大模型训练中的随机种子：为什么需要它？" class="linkLabel__RqX">大模型训练中的随机种子：为什么需要它？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/如何看懂数学公式"><span title="如何看懂数学公式" class="linkLabel__RqX">如何看懂数学公式</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/嵌入和向量/Chroma与PGVector对比"><span title="嵌入和向量" class="categoryLinkLabel_FHN4">嵌入和向量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/感知机"><span title="感知机" class="linkLabel__RqX">感知机</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/提示词工程/DSPy/API/优化器/BetterTogether"><span title="提示词工程" class="categoryLinkLabel_FHN4">提示词工程</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/智能体"><span title="智能体(Agent)" class="linkLabel__RqX">智能体(Agent)</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/深度学习/入门"><span title="深度学习" class="categoryLinkLabel_FHN4">深度学习</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/理解大模型：从函数视角看AI的本质"><span title="理解大模型：从函数视角看AI的本质" class="linkLabel__RqX">理解大模型：从函数视角看AI的本质</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/相关概念/Gradient"><span title="相关概念" class="categoryLinkLabel_FHN4">相关概念</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/联邦学习概念"><span title="联邦学习概念" class="linkLabel__RqX">联邦学习概念</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/通义千问/阿里云百炼"><span title="通义千问" class="categoryLinkLabel_FHN4">通义千问</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/金丝雀发布和AB测试"><span title="金丝雀发布和AB测试" class="linkLabel__RqX">金丝雀发布和AB测试</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_WxcZ"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_Zd2x"><div class="docItemContainer_EEW4"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_xL_w" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes3/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_zA1U"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Pytorch</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">神经网络</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Embedding</span></li></ul></nav><div class="tocCollapsible_aZGz theme-doc-toc-mobile tocMobile_ShCt"><button type="button" class="clean-btn tocCollapsibleButton_fxzH">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Embedding</h1></header><p><code>torch.nn.Embedding</code> 是 PyTorch 中用于处理离散分类数据（Categorical Data）的核心模块，本质上是一个<strong>可学习的查找表（Lookup Table）</strong>。它将高维稀疏的索引（Indices）映射为低维稠密的连续向量（Dense Vectors）。</p>
<p>在数学上，<code>nn.Embedding</code> 等价于输入为 <strong>One-Hot 编码</strong> 的无偏置全连接层（Linear Layer without bias），但在实现上通过直接内存寻址（Direct Memory Access）替代了矩阵乘法，显著降低了计算复杂度和内存开销。</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Output</mtext><mo>=</mo><mtext>Embedding</mtext><mo stretchy="false">(</mo><mtext>Index</mtext><mo stretchy="false">)</mo><mo>≡</mo><mtext>Linear</mtext><mo stretchy="false">(</mo><mtext>OneHot</mtext><mo stretchy="false">(</mo><mtext>Index</mtext><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Output} = \text{Embedding}(\text{Index}) \equiv \text{Linear}(\text{OneHot}(\text{Index}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Embedding</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">Index</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≡</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Linear</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">OneHot</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">Index</span></span><span class="mclose">))</span></span></span></span></span>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="2-架构与原理-architecture--mechanism">2. 架构与原理 (Architecture &amp; Mechanism)<a href="#2-架构与原理-architecture--mechanism" class="hash-link" aria-label="Direct link to 2. 架构与原理 (Architecture &amp; Mechanism)" title="Direct link to 2. 架构与原理 (Architecture &amp; Mechanism)" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="21-查找表机制">2.1 查找表机制<a href="#21-查找表机制" class="hash-link" aria-label="Direct link to 2.1 查找表机制" title="Direct link to 2.1 查找表机制" translate="no">​</a></h3>
<p><code>nn.Embedding</code> 维护一个形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span> 的权重矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span>，其中：</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span> (<code>num_embeddings</code>)：词表大小（Vocabulary Size）。</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span> (<code>embedding_dim</code>)：嵌入向量的维度。</li>
</ul>
<p>当输入一个索引 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span> 时，模块直接返回 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span> 的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span> 行 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">W[i]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span></span></span></span>。</p>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="22-架构图解">2.2 架构图解<a href="#22-架构图解" class="hash-link" aria-label="Direct link to 2.2 架构图解" title="Direct link to 2.2 架构图解" translate="no">​</a></h3>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="23-与-linear-层的对比">2.3 与 Linear 层的对比<a href="#23-与-linear-层的对比" class="hash-link" aria-label="Direct link to 2.3 与 Linear 层的对比" title="Direct link to 2.3 与 Linear 层的对比" translate="no">​</a></h3>
<p>假设词表大小 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mn>10000</mn></mrow><annotation encoding="application/x-tex">V=10000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">10000</span></span></span></span>，嵌入维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mn>300</mn></mrow><annotation encoding="application/x-tex">D=300</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">300</span></span></span></span>。</p>
<table><thead><tr><th style="text-align:left">特性</th><th style="text-align:left">nn.Embedding</th><th style="text-align:left">nn.Linear (w/ One-Hot)</th></tr></thead><tbody><tr><td style="text-align:left"><strong>操作方式</strong></td><td style="text-align:left">索引查找 (Slicing)</td><td style="text-align:left">矩阵乘法 (MatMul)</td></tr><tr><td style="text-align:left"><strong>计算复杂度</strong></td><td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span> (per token)</td><td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>V</mi><mo>×</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(V \times D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></td></tr><tr><td style="text-align:left"><strong>空间复杂度</strong></td><td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>V</mi><mo>×</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(V \times D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></td><td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>V</mi><mo>×</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(V \times D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></td></tr><tr><td style="text-align:left"><strong>输入格式</strong></td><td style="text-align:left">LongTensor (Indices)</td><td style="text-align:left">FloatTensor (One-Hot)</td></tr><tr><td style="text-align:left"><strong>适用场景</strong></td><td style="text-align:left">NLP 词嵌入、推荐系统 ID 嵌入</td><td style="text-align:left">一般特征变换</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="3-api-详解-api-specification">3. API 详解 (API Specification)<a href="#3-api-详解-api-specification" class="hash-link" aria-label="Direct link to 3. API 详解 (API Specification)" title="Direct link to 3. API 详解 (API Specification)" translate="no">​</a></h2>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_embeddings</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    embedding_dim</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">int</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    padding_idx</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">int</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_norm</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">float</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    norm_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">float</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    scale_grad_by_freq</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">bool</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sparse</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">bool</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    _weight</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">Tensor</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="关键参数说明">关键参数说明<a href="#关键参数说明" class="hash-link" aria-label="Direct link to 关键参数说明" title="Direct link to 关键参数说明" translate="no">​</a></h3>
<ol>
<li class="">
<p><strong><code>num_embeddings</code> (int)</strong>:</p>
<ul>
<li class="">嵌入字典的大小。即索引的最大值必须小于此值。</li>
</ul>
</li>
<li class="">
<p><strong><code>embedding_dim</code> (int)</strong>:</p>
<ul>
<li class="">每个嵌入向量的大小。</li>
</ul>
</li>
<li class="">
<p><strong><code>padding_idx</code> (int, optional)</strong>:</p>
<ul>
<li class=""><strong>重要</strong>：指定该索引为填充（Padding）索引。</li>
<li class=""><strong>特性</strong>：初始化时，该位置的向量全为 0；在反向传播中，<strong>该位置的梯度始终为 0</strong>，即权重不更新。</li>
<li class="">用途：处理变长序列时用于填充占位。</li>
</ul>
</li>
<li class="">
<p><strong><code>max_norm</code> (float, optional)</strong>:</p>
<ul>
<li class="">如果设置，前向传播时会将范数超过该值的向量重新归一化（Renormalize），使其范数等于 <code>max_norm</code>。</li>
</ul>
</li>
<li class="">
<p><strong><code>scale_grad_by_freq</code> (bool)</strong>:</p>
<ul>
<li class="">如果为 <code>True</code>，则根据单词在 mini-batch 中出现的频率缩放梯度。词频越高，梯度越小。</li>
<li class="">公式：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>grad</mtext><mo>=</mo><mfrac><mtext>grad</mtext><mtext>frequency</mtext></mfrac></mrow><annotation encoding="application/x-tex">\text{grad} = \frac{\text{grad}}{\text{frequency}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord text"><span class="mord">grad</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.4133em;vertical-align:-0.4811em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">frequency</span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.4461em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">grad</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4811em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
</ul>
</li>
<li class="">
<p><strong><code>sparse</code> (bool)</strong>:</p>
<ul>
<li class="">如果为 <code>True</code>，权重的梯度将是稀疏张量（Sparse Tensor）。</li>
<li class=""><strong>注意</strong>：目前仅部分优化器支持稀疏梯度（如 <code>optim.SGD</code>, <code>optim.SparseAdam</code>, <code>optim.Adagrad</code>）。</li>
</ul>
</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="4-梯度与反向传播-backpropagation">4. 梯度与反向传播 (Backpropagation)<a href="#4-梯度与反向传播-backpropagation" class="hash-link" aria-label="Direct link to 4. 梯度与反向传播 (Backpropagation)" title="Direct link to 4. 梯度与反向传播 (Backpropagation)" translate="no">​</a></h2>
<p>在训练过程中，<code>nn.Embedding</code> 的权重矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span> 是模型参数的一部分。</p>
<ul>
<li class=""><strong>前向传播</strong>：选择特定的行。</li>
<li class=""><strong>反向传播</strong>：梯度仅回传到<strong>被选中的行</strong>。<!-- -->
<ul>
<li class="">这意味着对于一个 Batch 中未出现的词，其对应的嵌入向量梯度为 0，权重不会更新。</li>
<li class="">这种稀疏更新特性使得 <code>nn.Embedding</code> 在处理超大规模词表时非常高效。</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="代码验证梯度更新">代码验证梯度更新<a href="#代码验证梯度更新" class="hash-link" aria-label="Direct link to 代码验证梯度更新" title="Direct link to 代码验证梯度更新" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 定义 Embedding</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">emb </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_embeddings</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> embedding_dim</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">optimizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">optim</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">SGD</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">emb</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">parameters</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> lr</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 输入索引 [1, 5]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_indices </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tensor</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 前向传播</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> emb</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">input_indices</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> output</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># 模拟 Loss</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 反向传播</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">optimizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zero_grad</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loss</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 检查梯度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Gradient for index 1:&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> emb</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">grad</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># 有梯度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Gradient for index 2:&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> emb</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">grad</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># 全为 0 (未被选中)</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="5-高级用法-advanced-usage">5. 高级用法 (Advanced Usage)<a href="#5-高级用法-advanced-usage" class="hash-link" aria-label="Direct link to 5. 高级用法 (Advanced Usage)" title="Direct link to 5. 高级用法 (Advanced Usage)" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="51-加载预训练向量-loading-pre-trained-embeddings">5.1 加载预训练向量 (Loading Pre-trained Embeddings)<a href="#51-加载预训练向量-loading-pre-trained-embeddings" class="hash-link" aria-label="Direct link to 5.1 加载预训练向量 (Loading Pre-trained Embeddings)" title="Direct link to 5.1 加载预训练向量 (Loading Pre-trained Embeddings)" translate="no">​</a></h3>
<p>使用 <code>from_pretrained</code> 类方法可以加载 GloVe 或 Word2Vec 等预训练向量。</p>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 假设 pretrained_weights 是一个 Numpy 数组或 Tensor</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pretrained_weights </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">300</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 方法 1: 使用 from_pretrained (推荐)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># freeze=True 表示冻结参数，不参与训练（Fine-tuning 时可设为 False）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding_layer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">pretrained_weights</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> freeze</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 方法 2: 手动赋值</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding_layer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">300</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding_layer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copy_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_numpy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">pretrained_weights</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="52-处理变长序列-padding">5.2 处理变长序列 (Padding)<a href="#52-处理变长序列-padding" class="hash-link" aria-label="Direct link to 5.2 处理变长序列 (Padding)" title="Direct link to 5.2 处理变长序列 (Padding)" translate="no">​</a></h3>
<p>结合 <code>padding_idx</code> 和 <code>nn.utils.rnn.pad_sequence</code> 使用。</p>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 指定 0 为 padding_idx</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">emb </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding_idx</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 输入包含 padding 索引 0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tensor</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">out </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> emb</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 索引 0 对应的向量始终为 0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">out</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># tensor([0., 0., 0., 0., 0.], grad_fn=&lt;SelectBackward&gt;)</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="6-参考资料-references">6. 参考资料 (References)<a href="#6-参考资料-references" class="hash-link" aria-label="Direct link to 6. 参考资料 (References)" title="Direct link to 6. 参考资料 (References)" translate="no">​</a></h2>
<ol>
<li class=""><strong>PyTorch Official Documentation</strong>: <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html" target="_blank" rel="noopener noreferrer" class="">torch.nn.Embedding</a></li>
<li class=""><strong>PyTorch Forums</strong>: <a href="https://discuss.pytorch.org/t/how-does-nn-embedding-work/88518" target="_blank" rel="noopener noreferrer" class="">How does nn.Embedding work?</a></li>
<li class=""><strong>Stack Overflow</strong>: <a href="https://stackoverflow.com/questions/58718612/what-exactly-happens-inside-embedding-layer-in-pytorch" target="_blank" rel="noopener noreferrer" class="">What exactly happens inside embedding layer in pytorch?</a></li>
<li class=""><strong>Medium</strong>: <a href="https://medium.com/@gautam.e/what-is-nn-embedding-really-de038baadd24" target="_blank" rel="noopener noreferrer" class="">What is nn.Embedding really?</a></li>
<li class=""><strong>Towards Data Science</strong>: <a href="https://towardsdatascience.com/the-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16" target="_blank" rel="noopener noreferrer" class="">The Secret to Improved NLP: An In-Depth Look at the nn.Embedding Layer</a></li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_iDCr"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/Pytorch/神经网络/Embedding.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_c0mv" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_mxtt"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes3/docs/AI/Pytorch/神经网络/Dropout"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Dropout</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes3/docs/AI/Pytorch/神经网络/F"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">F</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_r83r thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2-架构与原理-architecture--mechanism" class="table-of-contents__link toc-highlight">2. 架构与原理 (Architecture &amp; Mechanism)</a><ul><li><a href="#21-查找表机制" class="table-of-contents__link toc-highlight">2.1 查找表机制</a></li><li><a href="#22-架构图解" class="table-of-contents__link toc-highlight">2.2 架构图解</a></li><li><a href="#23-与-linear-层的对比" class="table-of-contents__link toc-highlight">2.3 与 Linear 层的对比</a></li></ul></li><li><a href="#3-api-详解-api-specification" class="table-of-contents__link toc-highlight">3. API 详解 (API Specification)</a><ul><li><a href="#关键参数说明" class="table-of-contents__link toc-highlight">关键参数说明</a></li></ul></li><li><a href="#4-梯度与反向传播-backpropagation" class="table-of-contents__link toc-highlight">4. 梯度与反向传播 (Backpropagation)</a><ul><li><a href="#代码验证梯度更新" class="table-of-contents__link toc-highlight">代码验证梯度更新</a></li></ul></li><li><a href="#5-高级用法-advanced-usage" class="table-of-contents__link toc-highlight">5. 高级用法 (Advanced Usage)</a><ul><li><a href="#51-加载预训练向量-loading-pre-trained-embeddings" class="table-of-contents__link toc-highlight">5.1 加载预训练向量 (Loading Pre-trained Embeddings)</a></li><li><a href="#52-处理变长序列-padding" class="table-of-contents__link toc-highlight">5.2 处理变长序列 (Padding)</a></li></ul></li><li><a href="#6-参考资料-references" class="table-of-contents__link toc-highlight">6. 参考资料 (References)</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>