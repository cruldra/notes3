<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AI/Pytorch/CUDA/grad_scaler" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">grad_scaler | Cruldra</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/grad_scaler"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="grad_scaler | Cruldra"><meta data-rh="true" name="description" content="深入解析 GradScaler：自动混合精度的梯度缩放器"><meta data-rh="true" property="og:description" content="深入解析 GradScaler：自动混合精度的梯度缩放器"><link data-rh="true" rel="icon" href="/notes3/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/grad_scaler"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/grad_scaler" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/grad_scaler" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"grad_scaler","item":"https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/grad_scaler"}]}</script><link rel="alternate" type="application/rss+xml" href="/notes3/blog/rss.xml" title="Cruldra RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/notes3/blog/atom.xml" title="Cruldra Atom Feed"><link rel="stylesheet" href="/notes3/assets/css/styles.44875995.css">
<script src="/notes3/assets/js/runtime~main.e67d83d5.js" defer="defer"></script>
<script src="/notes3/assets/js/main.d5cfca97.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme",window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-theme-choice","system"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes3/img/logo.svg"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><div role="region" aria-label="Skip to main content"><a class="skipToContent_aA1M" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes3/"><div class="navbar__logo"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E3Xm themedComponent--light_DVqC"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E3Xm themedComponent--dark_B_L3"></div><b class="navbar__title text--truncate">Cruldra</b></a><a class="navbar__item navbar__link" href="/notes3/docs/category/设计模式">JVM</a><a class="navbar__item navbar__link" href="/notes3/docs/category/css">前端</a><a class="navbar__item navbar__link" href="/notes3/docs/category/astrbot">工具</a><a class="navbar__item navbar__link" href="/notes3/docs/category/ai电竞酒店">个人</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/notes3/docs/AI/ACP/架构">AI</a><a class="navbar__item navbar__link" href="/notes3/docs/category/内置模块">Python</a><a class="navbar__item navbar__link" href="/notes3/docs/category/actix-web">Rust</a><a class="navbar__item navbar__link" href="/notes3/docs/category/数据库系统">软件工程</a><a class="navbar__item navbar__link" href="/notes3/docs/category/上古卷轴5">游戏</a><a class="navbar__item navbar__link" href="/notes3/docs/Go/Go-Python-Java三语言全方位对比">Go</a><a class="navbar__item navbar__link" href="/notes3/docs/Hardware/GPU工作原理">硬件</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_PufJ"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_ctfR"><div class="docsWrapper_ByIB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_KwvU" type="button"></button><div class="docRoot_hD6z"><aside class="theme-doc-sidebar-container docSidebarContainer_KuHC"><div class="sidebarViewport_LCjr"><div class="sidebar_L77d"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_VYAF"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/ACP/架构"><span title="ACP" class="categoryLinkLabel_FHN4">ACP</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agent Skills/什么是Skills"><span title="Agent Skills" class="categoryLinkLabel_FHN4">Agent Skills</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agno/介绍"><span title="Agno" class="categoryLinkLabel_FHN4">Agno</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/CrewAI/CLI"><span title="CrewAI" class="categoryLinkLabel_FHN4">CrewAI</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/DALLE成本计算"><span title="DALL-E 画图成本计算" class="linkLabel__RqX">DALL-E 画图成本计算</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/LLamaIndex/CitationQueryEngine"><span title="LLamaIndex" class="categoryLinkLabel_FHN4">LLamaIndex</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/MCP/MCP-Python-SDK"><span title="MCP" class="categoryLinkLabel_FHN4">MCP</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/notes3/docs/AI/Pytorch/介绍"><span title="Pytorch" class="categoryLinkLabel_FHN4">Pytorch</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/介绍"><span title="介绍" class="linkLabel__RqX">介绍</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/简介"><span title="神经网络" class="categoryLinkLabel_FHN4">神经网络</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/grad_scaler"><span title="CUDA" class="categoryLinkLabel_FHN4">CUDA</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/grad_scaler"><span title="grad_scaler" class="linkLabel__RqX">grad_scaler</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/简介"><span title="简介" class="linkLabel__RqX">简介</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/自动混合精度"><span title="自动混合精度" class="linkLabel__RqX">自动混合精度</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/arange"><span title="arange" class="linkLabel__RqX">arange</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/cat"><span title="cat" class="linkLabel__RqX">cat</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/outer"><span title="outer" class="linkLabel__RqX">outer</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/从头开始训练自己的大模型"><span title="从头开始训练自己的大模型 - 流程图" class="linkLabel__RqX">从头开始训练自己的大模型 - 流程图</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/优化/简介"><span title="优化" class="categoryLinkLabel_FHN4">优化</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/分布式训练/DistributedDataParallel"><span title="分布式训练" class="categoryLinkLabel_FHN4">分布式训练</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/分词器与词嵌入完整流程演示"><span title="分词器与词嵌入完整流程演示" class="linkLabel__RqX">分词器与词嵌入完整流程演示</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/参考/1"><span title="参考" class="categoryLinkLabel_FHN4">参考</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/工具/简介"><span title="工具" class="categoryLinkLabel_FHN4">工具</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/张量/如何看懂张量形状"><span title="张量" class="categoryLinkLabel_FHN4">张量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/混合精度浮点数"><span title="混合精度浮点数" class="linkLabel__RqX">混合精度浮点数</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/SentencePiece/简介"><span title="SentencePiece" class="categoryLinkLabel_FHN4">SentencePiece</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/Transformer"><span title="Transformer" class="linkLabel__RqX">Transformer</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/cv_graph"><span title="计算机视觉 (CV) 知识图谱" class="linkLabel__RqX">计算机视觉 (CV) 知识图谱</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/datasets/demo"><span title="datasets" class="categoryLinkLabel_FHN4">datasets</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/huggingface_hub/简介"><span title="huggingface_hub" class="categoryLinkLabel_FHN4">huggingface_hub</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/llm_graph"><span title="LLM 知识图谱" class="linkLabel__RqX">LLM 知识图谱</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/tiktoken/简介"><span title="tiktoken" class="categoryLinkLabel_FHN4">tiktoken</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/tokenizers/和tiktoken的区别"><span title="tokenizers" class="categoryLinkLabel_FHN4">tokenizers</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/transformers/分词器/PreTrainedTokenizer"><span title="transformers" class="categoryLinkLabel_FHN4">transformers</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist" href="/notes3/docs/AI/vllm"><span title="vLLM 学习资料" class="categoryLinkLabel_FHN4">vLLM 学习资料</span></a><button aria-label="Expand sidebar category &#x27;vLLM 学习资料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/wandb/简介"><span title="wandb" class="categoryLinkLabel_FHN4">wandb</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念1"><span title="一些概念1" class="linkLabel__RqX">一些概念1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念2"><span title="一些概念2" class="linkLabel__RqX">一些概念2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念3"><span title="一些概念3" class="linkLabel__RqX">一些概念3</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念4"><span title="一些概念4" class="linkLabel__RqX">一些概念4</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念5"><span title="一些概念5" class="linkLabel__RqX">一些概念5</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/候选模型"><span title="候选模型" class="linkLabel__RqX">候选模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/变分自编码器详解"><span title="变分自编码器（VAE）详解" class="linkLabel__RqX">变分自编码器（VAE）详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型核心概念通俗解释"><span title="大模型核心概念通俗解释" class="linkLabel__RqX">大模型核心概念通俗解释</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型训练中的随机种子：为什么需要它？"><span title="大模型训练中的随机种子：为什么需要它？" class="linkLabel__RqX">大模型训练中的随机种子：为什么需要它？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/如何看懂数学公式"><span title="如何看懂数学公式" class="linkLabel__RqX">如何看懂数学公式</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/嵌入和向量/Chroma与PGVector对比"><span title="嵌入和向量" class="categoryLinkLabel_FHN4">嵌入和向量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/感知机"><span title="感知机" class="linkLabel__RqX">感知机</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/提示词工程/DSPy/API/优化器/BetterTogether"><span title="提示词工程" class="categoryLinkLabel_FHN4">提示词工程</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/智能体"><span title="智能体(Agent)" class="linkLabel__RqX">智能体(Agent)</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/深度学习/入门"><span title="深度学习" class="categoryLinkLabel_FHN4">深度学习</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/理解大模型：从函数视角看AI的本质"><span title="理解大模型：从函数视角看AI的本质" class="linkLabel__RqX">理解大模型：从函数视角看AI的本质</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/相关概念/Gradient"><span title="相关概念" class="categoryLinkLabel_FHN4">相关概念</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/联邦学习概念"><span title="联邦学习概念" class="linkLabel__RqX">联邦学习概念</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/通义千问/阿里云百炼"><span title="通义千问" class="categoryLinkLabel_FHN4">通义千问</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/金丝雀发布和AB测试"><span title="金丝雀发布和AB测试" class="linkLabel__RqX">金丝雀发布和AB测试</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_WxcZ"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_Zd2x"><div class="docItemContainer_EEW4"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_xL_w" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes3/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_zA1U"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Pytorch</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">CUDA</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">grad_scaler</span></li></ul></nav><div class="tocCollapsible_aZGz theme-doc-toc-mobile tocMobile_ShCt"><button type="button" class="clean-btn tocCollapsibleButton_fxzH">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>grad_scaler</h1></header><p>深入解析 GradScaler：自动混合精度的梯度缩放器</p>
<blockquote>
<p><strong>摘要</strong>：在混合精度训练（AMP）中，<code>float16</code> 的数值范围有限，容易导致梯度下溢（Underflow）。<code>torch.cuda.amp.GradScaler</code>（现更新为 <code>torch.amp.GradScaler</code>）是 PyTorch 提供的核心工具，通过动态缩放损失值来解决这一问题，确保模型在加速训练的同时不损失精度。</p>
</blockquote>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="1-核心问题梯度下溢-gradient-underflow">1. 核心问题：梯度下溢 (Gradient Underflow)<a href="#1-核心问题梯度下溢-gradient-underflow" class="hash-link" aria-label="Direct link to 1. 核心问题：梯度下溢 (Gradient Underflow)" title="Direct link to 1. 核心问题：梯度下溢 (Gradient Underflow)" translate="no">​</a></h2>
<p><code>float16</code>（半精度浮点数）的最小正规数约为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn><mo>×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">6 \times 10^{-8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span>。在深度神经网络的反向传播中，许多梯度的数值非常小（例如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mrow><mo>−</mo><mn>10</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-10}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">10</span></span></span></span></span></span></span></span></span></span></span></span> 甚至更小）。</p>
<ul>
<li class=""><strong>问题</strong>：如果直接使用 <code>float16</code> 存储这些微小的梯度，它们会因为精度不足变成 0。</li>
<li class=""><strong>后果</strong>：参数无法更新，模型无法收敛。</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="2-解决方案动态损失缩放-dynamic-loss-scaling">2. 解决方案：动态损失缩放 (Dynamic Loss Scaling)<a href="#2-解决方案动态损失缩放-dynamic-loss-scaling" class="hash-link" aria-label="Direct link to 2. 解决方案：动态损失缩放 (Dynamic Loss Scaling)" title="Direct link to 2. 解决方案：动态损失缩放 (Dynamic Loss Scaling)" translate="no">​</a></h2>
<p><code>GradScaler</code> 的工作原理非常巧妙且直观：</p>
<ol>
<li class=""><strong>放大 (Scale)</strong>：在反向传播（Backward）之前，将 Loss 乘以一个巨大的因子（Scale Factor，例如 65536）。<!-- -->
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Scaled Loss</mtext><mo>=</mo><mtext>Loss</mtext><mo>×</mo><mtext>Scale Factor</mtext></mrow><annotation encoding="application/x-tex">\text{Scaled Loss} = \text{Loss} \times \text{Scale Factor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text"><span class="mord">Scaled Loss</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord text"><span class="mord">Loss</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text"><span class="mord">Scale Factor</span></span></span></span></span></li>
<li class="">根据链式法则，计算出的梯度也会自动放大相同的倍数，从而“逃离”下溢区。</li>
</ul>
</li>
<li class=""><strong>缩小 (Unscale)</strong>：在参数更新（Optimizer Step）之前，将梯度除以同一个因子，恢复到真实的数值大小。<!-- -->
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Real Grad</mtext><mo>=</mo><mtext>Scaled Grad</mtext><mi mathvariant="normal">/</mi><mtext>Scale Factor</mtext></mrow><annotation encoding="application/x-tex">\text{Real Grad} = \text{Scaled Grad} / \text{Scale Factor}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord text"><span class="mord">Real Grad</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Scaled Grad</span></span><span class="mord">/</span><span class="mord text"><span class="mord">Scale Factor</span></span></span></span></span></li>
</ul>
</li>
<li class=""><strong>动态调整</strong>：<!-- -->
<ul>
<li class="">如果本轮迭代<strong>没有</strong>出现 <code>Inf</code> 或 <code>NaN</code>（溢出），说明缩放因子是安全的，甚至可以尝试增大一点。</li>
<li class="">如果本轮迭代<strong>出现</strong>了 <code>Inf</code> 或 <code>NaN</code>，说明缩放因子太大了，导致梯度溢出。此时应<strong>跳过</strong>参数更新，并将缩放因子减小（Backoff）。</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="21-流程图解">2.1 流程图解<a href="#21-流程图解" class="hash-link" aria-label="Direct link to 2.1 流程图解" title="Direct link to 2.1 流程图解" translate="no">​</a></h3>
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="3-核心-api-与参数">3. 核心 API 与参数<a href="#3-核心-api-与参数" class="hash-link" aria-label="Direct link to 3. 核心 API 与参数" title="Direct link to 3. 核心 API 与参数" translate="no">​</a></h2>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">amp</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">GradScaler</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    device</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;cuda&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    init_scale</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">65536.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    growth_factor</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2.0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    backoff_factor</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    growth_interval</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    enabled</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<table><thead><tr><th style="text-align:left">参数</th><th style="text-align:left">默认值</th><th style="text-align:left">含义</th></tr></thead><tbody><tr><td style="text-align:left"><code>init_scale</code></td><td style="text-align:left">65536.0</td><td style="text-align:left">初始缩放因子 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>16</mn></msup></mrow><annotation encoding="application/x-tex">2^{16}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">16</span></span></span></span></span></span></span></span></span></span></span></span>)。</td></tr><tr><td style="text-align:left"><code>growth_factor</code></td><td style="text-align:left">2.0</td><td style="text-align:left">当连续 N 次迭代未溢出时，缩放因子的倍增系数。</td></tr><tr><td style="text-align:left"><code>backoff_factor</code></td><td style="text-align:left">0.5</td><td style="text-align:left">当检测到溢出时，缩放因子的缩减系数。</td></tr><tr><td style="text-align:left"><code>growth_interval</code></td><td style="text-align:left">2000</td><td style="text-align:left">连续多少次未溢出后尝试增大缩放因子。</td></tr></tbody></table>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="4-工程实践标准代码范式">4. 工程实践：标准代码范式<a href="#4-工程实践标准代码范式" class="hash-link" aria-label="Direct link to 4. 工程实践：标准代码范式" title="Direct link to 4. 工程实践：标准代码范式" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="41-基本用法">4.1 基本用法<a href="#41-基本用法" class="hash-link" aria-label="Direct link to 4.1 基本用法" title="Direct link to 4.1 基本用法" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">amp </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> autocast</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> GradScaler</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> MyModel</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">optimizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">optim</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">SGD</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">parameters</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> lr</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.01</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scaler </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> GradScaler</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;cuda&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># 1. 初始化 Scaler</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> epoch </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">epochs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> </span><span class="token builtin">input</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> target </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> data_loader</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        optimizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zero_grad</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 2. 前向传播：开启 Autocast</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> autocast</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">device_type</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;cuda&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dtype</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">float16</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            output </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token builtin">input</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> loss_fn</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> target</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 3. 反向传播：Scale Loss</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        scaler</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">scale</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loss</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 4. 参数更新：Step Optimizer</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 内部逻辑：先 Unscale 梯度，如果无 Inf/NaN 则执行 optimizer.step()，否则跳过</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        scaler</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">step</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">optimizer</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 5. 更新缩放因子</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        scaler</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">update</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="42-梯度裁剪-gradient-clipping">4.2 梯度裁剪 (Gradient Clipping)<a href="#42-梯度裁剪-gradient-clipping" class="hash-link" aria-label="Direct link to 4.2 梯度裁剪 (Gradient Clipping)" title="Direct link to 4.2 梯度裁剪 (Gradient Clipping)" translate="no">​</a></h3>
<p>梯度裁剪必须在 <code>unscale_</code> 之后、<code>step</code> 之前进行，否则裁剪阈值会与缩放因子混淆。</p>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># ... backward ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scaler</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">scale</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loss</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 必须显式 Unscale</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scaler</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">unscale_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">optimizer</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 现在梯度是真实大小，可以安全裁剪</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">utils</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">clip_grad_norm_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">parameters</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> max_norm</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1.0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Step 时 Scaler 会知道已经 unscale 过了，不会重复操作</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scaler</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">step</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">optimizer</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scaler</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">update</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="43-多优化器--梯度累积">4.3 多优化器 / 梯度累积<a href="#43-多优化器--梯度累积" class="hash-link" aria-label="Direct link to 4.3 多优化器 / 梯度累积" title="Direct link to 4.3 多优化器 / 梯度累积" translate="no">​</a></h3>
<ul>
<li class=""><strong>多优化器</strong>：每个 Optimizer 都需要调用一次 <code>scaler.step(opt)</code>，但 <code>scaler.update()</code> 在一轮迭代中只能调用一次。</li>
<li class=""><strong>梯度累积</strong>：<code>scaler.step</code> 和 <code>scaler.update</code> 应该只在累积步数达到（即真正更新参数）时调用。</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="5-常见问题-faq">5. 常见问题 (FAQ)<a href="#5-常见问题-faq" class="hash-link" aria-label="Direct link to 5. 常见问题 (FAQ)" title="Direct link to 5. 常见问题 (FAQ)" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="q1-为什么我的-loss-变成了-nan">Q1: 为什么我的 Loss 变成了 NaN？<a href="#q1-为什么我的-loss-变成了-nan" class="hash-link" aria-label="Direct link to Q1: 为什么我的 Loss 变成了 NaN？" title="Direct link to Q1: 为什么我的 Loss 变成了 NaN？" translate="no">​</a></h3>
<p>如果是训练初期出现，可能是 <code>init_scale</code> 太大，Scaler 会自动减小它，通常几轮后会恢复正常。如果一直 NaN，需检查数据或模型结构。</p>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="q2-必须配合-autocast-使用吗">Q2: 必须配合 <code>autocast</code> 使用吗？<a href="#q2-必须配合-autocast-使用吗" class="hash-link" aria-label="Direct link to q2-必须配合-autocast-使用吗" title="Direct link to q2-必须配合-autocast-使用吗" translate="no">​</a></h3>
<p>是的。<code>GradScaler</code> 是为了解决 <code>float16</code> 梯度下溢问题的。如果全用 <code>float32</code> 训练，不需要 Scaler。</p>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="q3-torchcudaamp-和-torchamp-有什么区别">Q3: <code>torch.cuda.amp</code> 和 <code>torch.amp</code> 有什么区别？<a href="#q3-torchcudaamp-和-torchamp-有什么区别" class="hash-link" aria-label="Direct link to q3-torchcudaamp-和-torchamp-有什么区别" title="Direct link to q3-torchcudaamp-和-torchamp-有什么区别" translate="no">​</a></h3>
<p>从 PyTorch 1.10 开始，推荐使用 <code>torch.amp</code>（设备无关的新 API），<code>torch.cuda.amp</code> 是旧版 API，目前为了兼容性仍保留，但建议迁移。</p>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="6-参考资料">6. 参考资料<a href="#6-参考资料" class="hash-link" aria-label="Direct link to 6. 参考资料" title="Direct link to 6. 参考资料" translate="no">​</a></h2>
<ol>
<li class=""><a href="https://pytorch.org/docs/stable/amp.html" target="_blank" rel="noopener noreferrer" class="">PyTorch Docs - Automatic Mixed Precision</a></li>
<li class=""><a href="https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html" target="_blank" rel="noopener noreferrer" class="">PyTorch Tutorial - AMP Recipe</a></li>
<li class=""><a href="https://wandb.ai/wandb_fc/tips/reports/How-to-Use-GradScaler-in-PyTorch--VmlldzoyMTY5MDA5" target="_blank" rel="noopener noreferrer" class="">WandB - How to Use GradScaler</a></li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_iDCr"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/Pytorch/CUDA/grad_scaler.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_c0mv" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_mxtt"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes3/docs/AI/Pytorch/神经网络/示例/linear_semantic_distance"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Liner层的作用-语义距离调整演示</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes3/docs/AI/Pytorch/CUDA/简介"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">简介</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_r83r thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-核心问题梯度下溢-gradient-underflow" class="table-of-contents__link toc-highlight">1. 核心问题：梯度下溢 (Gradient Underflow)</a></li><li><a href="#2-解决方案动态损失缩放-dynamic-loss-scaling" class="table-of-contents__link toc-highlight">2. 解决方案：动态损失缩放 (Dynamic Loss Scaling)</a><ul><li><a href="#21-流程图解" class="table-of-contents__link toc-highlight">2.1 流程图解</a></li></ul></li><li><a href="#3-核心-api-与参数" class="table-of-contents__link toc-highlight">3. 核心 API 与参数</a></li><li><a href="#4-工程实践标准代码范式" class="table-of-contents__link toc-highlight">4. 工程实践：标准代码范式</a><ul><li><a href="#41-基本用法" class="table-of-contents__link toc-highlight">4.1 基本用法</a></li><li><a href="#42-梯度裁剪-gradient-clipping" class="table-of-contents__link toc-highlight">4.2 梯度裁剪 (Gradient Clipping)</a></li><li><a href="#43-多优化器--梯度累积" class="table-of-contents__link toc-highlight">4.3 多优化器 / 梯度累积</a></li></ul></li><li><a href="#5-常见问题-faq" class="table-of-contents__link toc-highlight">5. 常见问题 (FAQ)</a><ul><li><a href="#q1-为什么我的-loss-变成了-nan" class="table-of-contents__link toc-highlight">Q1: 为什么我的 Loss 变成了 NaN？</a></li><li><a href="#q2-必须配合-autocast-使用吗" class="table-of-contents__link toc-highlight">Q2: 必须配合 <code>autocast</code> 使用吗？</a></li><li><a href="#q3-torchcudaamp-和-torchamp-有什么区别" class="table-of-contents__link toc-highlight">Q3: <code>torch.cuda.amp</code> 和 <code>torch.amp</code> 有什么区别？</a></li></ul></li><li><a href="#6-参考资料" class="table-of-contents__link toc-highlight">6. 参考资料</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_rhIP"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_rhIP"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_rhIP"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes3/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_rhIP"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>