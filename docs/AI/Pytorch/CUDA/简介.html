<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AI/Pytorch/CUDA/简介" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">简介 | Cruldra</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/notes3/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/简介"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="简介 | Cruldra"><meta data-rh="true" name="description" content="torch.cuda 是 PyTorch 与 NVIDIA GPU 进行交互的核心接口包。它不仅封装了 CUDA Runtime API，还实现了一套复杂的内存管理机制 (Caching Allocator) 和异步执行模型 (Asynchronous Execution)，以最大化深度学习任务的吞吐量並降低 CPU 开销。"><meta data-rh="true" property="og:description" content="torch.cuda 是 PyTorch 与 NVIDIA GPU 进行交互的核心接口包。它不仅封装了 CUDA Runtime API，还实现了一套复杂的内存管理机制 (Caching Allocator) 和异步执行模型 (Asynchronous Execution)，以最大化深度学习任务的吞吐量並降低 CPU 开销。"><link data-rh="true" rel="icon" href="/notes3/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/简介"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/简介" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/简介" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"简介","item":"https://your-docusaurus-site.example.com/notes3/docs/AI/Pytorch/CUDA/简介"}]}</script><link rel="alternate" type="application/rss+xml" href="/notes3/blog/rss.xml" title="Cruldra RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/notes3/blog/atom.xml" title="Cruldra Atom Feed"><link rel="stylesheet" href="/notes3/assets/css/styles.48a6e6d2.css">
<script src="/notes3/assets/js/runtime~main.04368516.js" defer="defer"></script>
<script src="/notes3/assets/js/main.dcb0ce96.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme",window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"),document.documentElement.setAttribute("data-theme-choice","system"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes3/img/logo.svg"><style data-mantine-styles="classes">@media (max-width: 35.99375em) {.mantine-visible-from-xs {display: none !important;}}@media (min-width: 36em) {.mantine-hidden-from-xs {display: none !important;}}@media (max-width: 47.99375em) {.mantine-visible-from-sm {display: none !important;}}@media (min-width: 48em) {.mantine-hidden-from-sm {display: none !important;}}@media (max-width: 61.99375em) {.mantine-visible-from-md {display: none !important;}}@media (min-width: 62em) {.mantine-hidden-from-md {display: none !important;}}@media (max-width: 74.99375em) {.mantine-visible-from-lg {display: none !important;}}@media (min-width: 75em) {.mantine-hidden-from-lg {display: none !important;}}@media (max-width: 87.99375em) {.mantine-visible-from-xl {display: none !important;}}@media (min-width: 88em) {.mantine-hidden-from-xl {display: none !important;}}</style><div role="region" aria-label="Skip to main content"><a class="skipToContent_aA1M" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes3/"><div class="navbar__logo"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E3Xm themedComponent--light_DVqC"><img src="/notes3/img/logo.svg" alt="My Site Logo" class="themedComponent_E3Xm themedComponent--dark_B_L3"></div><b class="navbar__title text--truncate">Cruldra</b></a><a class="navbar__item navbar__link" href="/notes3/docs/category/设计模式">JVM</a><a class="navbar__item navbar__link" href="/notes3/docs/category/css">前端</a><a class="navbar__item navbar__link" href="/notes3/docs/category/astrbot">工具</a><a class="navbar__item navbar__link" href="/notes3/docs/category/ai电竞酒店">个人</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/notes3/docs/AI/ACP/架构">AI</a><a class="navbar__item navbar__link" href="/notes3/docs/category/内置模块">Python</a><a class="navbar__item navbar__link" href="/notes3/docs/category/actix-web">Rust</a><a class="navbar__item navbar__link" href="/notes3/docs/category/数据库系统">软件工程</a><a class="navbar__item navbar__link" href="/notes3/docs/category/上古卷轴5">游戏</a><a class="navbar__item navbar__link" href="/notes3/docs/Go/Go-Python-Java三语言全方位对比">Go</a><a class="navbar__item navbar__link" href="/notes3/docs/Hardware/GPU工作原理">硬件</a><a class="navbar__item navbar__link" href="/notes3/docs/Godot/功能列表">Godot</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_PufJ"><div class="navbar__search searchBarContainer_r6C1" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_G4_y" value=""><div class="loadingRing__Zfe searchBarLoadingRing_f0pn"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_ctfR"><div class="docsWrapper_ByIB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_KwvU" type="button"></button><div class="docRoot_hD6z"><aside class="theme-doc-sidebar-container docSidebarContainer_KuHC"><div class="sidebarViewport_LCjr"><div class="sidebar_L77d"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_VYAF"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/ACP/架构"><span title="ACP" class="categoryLinkLabel_FHN4">ACP</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agent Skills/什么是Skills"><span title="Agent Skills" class="categoryLinkLabel_FHN4">Agent Skills</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/Agno/介绍"><span title="Agno" class="categoryLinkLabel_FHN4">Agno</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/CrewAI/CLI"><span title="CrewAI" class="categoryLinkLabel_FHN4">CrewAI</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/DALLE成本计算"><span title="DALL-E 画图成本计算" class="linkLabel__RqX">DALL-E 画图成本计算</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/LLamaIndex/CitationQueryEngine"><span title="LLamaIndex" class="categoryLinkLabel_FHN4">LLamaIndex</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/MCP/MCP-Python-SDK"><span title="MCP" class="categoryLinkLabel_FHN4">MCP</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/notes3/docs/AI/Pytorch/介绍"><span title="Pytorch" class="categoryLinkLabel_FHN4">Pytorch</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/介绍"><span title="介绍" class="linkLabel__RqX">介绍</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/神经网络/简介"><span title="神经网络" class="categoryLinkLabel_FHN4">神经网络</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/grad_scaler"><span title="CUDA" class="categoryLinkLabel_FHN4">CUDA</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/grad_scaler"><span title="grad_scaler" class="linkLabel__RqX">grad_scaler</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/简介"><span title="简介" class="linkLabel__RqX">简介</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/CUDA/自动混合精度"><span title="自动混合精度" class="linkLabel__RqX">自动混合精度</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/arange"><span title="arange" class="linkLabel__RqX">arange</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/cat"><span title="cat" class="linkLabel__RqX">cat</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/outer"><span title="outer" class="linkLabel__RqX">outer</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/从头开始训练自己的大模型"><span title="从头开始训练自己的大模型 - 流程图" class="linkLabel__RqX">从头开始训练自己的大模型 - 流程图</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/优化/简介"><span title="优化" class="categoryLinkLabel_FHN4">优化</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/分布式训练/DistributedDataParallel"><span title="分布式训练" class="categoryLinkLabel_FHN4">分布式训练</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/分词器与词嵌入完整流程演示"><span title="分词器与词嵌入完整流程演示" class="linkLabel__RqX">分词器与词嵌入完整流程演示</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/参考/1"><span title="参考" class="categoryLinkLabel_FHN4">参考</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/工具/简介"><span title="工具" class="categoryLinkLabel_FHN4">工具</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/notes3/docs/AI/Pytorch/张量/如何看懂张量形状"><span title="张量" class="categoryLinkLabel_FHN4">张量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes3/docs/AI/Pytorch/混合精度浮点数"><span title="混合精度浮点数" class="linkLabel__RqX">混合精度浮点数</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/SentencePiece/简介"><span title="SentencePiece" class="categoryLinkLabel_FHN4">SentencePiece</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/Transformer"><span title="Transformer" class="linkLabel__RqX">Transformer</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/cv_graph"><span title="计算机视觉 (CV) 知识图谱" class="linkLabel__RqX">计算机视觉 (CV) 知识图谱</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/datasets/demo"><span title="datasets" class="categoryLinkLabel_FHN4">datasets</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/huggingface_hub/简介"><span title="huggingface_hub" class="categoryLinkLabel_FHN4">huggingface_hub</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/llm_graph"><span title="LLM 知识图谱" class="linkLabel__RqX">LLM 知识图谱</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/tiktoken/简介"><span title="tiktoken" class="categoryLinkLabel_FHN4">tiktoken</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/tokenizers/和tiktoken的区别"><span title="tokenizers" class="categoryLinkLabel_FHN4">tokenizers</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/transformers/分词器/PreTrainedTokenizer"><span title="transformers" class="categoryLinkLabel_FHN4">transformers</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist" href="/notes3/docs/AI/vllm"><span title="vLLM 学习资料" class="categoryLinkLabel_FHN4">vLLM 学习资料</span></a><button aria-label="Expand sidebar category &#x27;vLLM 学习资料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/wandb/简介"><span title="wandb" class="categoryLinkLabel_FHN4">wandb</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念1"><span title="一些概念1" class="linkLabel__RqX">一些概念1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念2"><span title="一些概念2" class="linkLabel__RqX">一些概念2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念3"><span title="一些概念3" class="linkLabel__RqX">一些概念3</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念4"><span title="一些概念4" class="linkLabel__RqX">一些概念4</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/一些概念5"><span title="一些概念5" class="linkLabel__RqX">一些概念5</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/候选模型"><span title="候选模型" class="linkLabel__RqX">候选模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/变分自编码器详解"><span title="变分自编码器（VAE）详解" class="linkLabel__RqX">变分自编码器（VAE）详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型核心概念通俗解释"><span title="大模型核心概念通俗解释" class="linkLabel__RqX">大模型核心概念通俗解释</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/大模型训练中的随机种子：为什么需要它？"><span title="大模型训练中的随机种子：为什么需要它？" class="linkLabel__RqX">大模型训练中的随机种子：为什么需要它？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/如何看懂数学公式"><span title="如何看懂数学公式" class="linkLabel__RqX">如何看懂数学公式</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/嵌入和向量/Chroma与PGVector对比"><span title="嵌入和向量" class="categoryLinkLabel_FHN4">嵌入和向量</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/感知机"><span title="感知机" class="linkLabel__RqX">感知机</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/提示词工程/DSPy/API/优化器/BetterTogether"><span title="提示词工程" class="categoryLinkLabel_FHN4">提示词工程</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/智能体"><span title="智能体(Agent)" class="linkLabel__RqX">智能体(Agent)</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/深度学习/入门"><span title="深度学习" class="categoryLinkLabel_FHN4">深度学习</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/理解大模型：从函数视角看AI的本质"><span title="理解大模型：从函数视角看AI的本质" class="linkLabel__RqX">理解大模型：从函数视角看AI的本质</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/相关概念/Gradient"><span title="相关概念" class="categoryLinkLabel_FHN4">相关概念</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/联邦学习概念"><span title="联邦学习概念" class="linkLabel__RqX">联邦学习概念</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_NhDl menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/notes3/docs/AI/通义千问/阿里云百炼"><span title="通义千问" class="categoryLinkLabel_FHN4">通义千问</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes3/docs/AI/金丝雀发布和AB测试"><span title="金丝雀发布和AB测试" class="linkLabel__RqX">金丝雀发布和AB测试</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_WxcZ"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_Zd2x"><div class="docItemContainer_EEW4"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_xL_w" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes3/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_zA1U"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Pytorch</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">CUDA</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">简介</span></li></ul></nav><div class="tocCollapsible_aZGz theme-doc-toc-mobile tocMobile_ShCt"><button type="button" class="clean-btn tocCollapsibleButton_fxzH">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>简介</h1></header><p><code>torch.cuda</code> 是 PyTorch 与 NVIDIA GPU 进行交互的核心接口包。它不仅封装了 CUDA Runtime API，还实现了一套复杂的<strong>内存管理机制 (Caching Allocator)</strong> 和<strong>异步执行模型 (Asynchronous Execution)</strong>，以最大化深度学习任务的吞吐量並降低 CPU 开销。</p>
<p>理解 <code>torch.cuda</code> 的底层原理对于解决 Out Of Memory (OOM) 错误、优化模型训练速度以及进行高性能算子开发至关重要。</p>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="2-内存管理机制-memory-management">2. 内存管理机制 (Memory Management)<a href="#2-内存管理机制-memory-management" class="hash-link" aria-label="Direct link to 2. 内存管理机制 (Memory Management)" title="Direct link to 2. 内存管理机制 (Memory Management)" translate="no">​</a></h2>
<p>PyTorch 并不直接对每一次 Tensor 分配都调用 CUDA 原生的 <code>cudaMalloc</code> 和 <code>cudaFree</code>，因为这些系统调用（System Calls）会导致设备同步（Device Synchronization），从而显著阻塞 CPU 线程，破坏流水线并行。</p>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="21-caching-allocator-架构">2.1 Caching Allocator 架构<a href="#21-caching-allocator-架构" class="hash-link" aria-label="Direct link to 2.1 Caching Allocator 架构" title="Direct link to 2.1 Caching Allocator 架构" translate="no">​</a></h3>
<p>PyTorch 实现了一个 <strong>Caching Allocator</strong>（缓存分配器），其核心策略是：<strong>向 CUDA 申请大块内存，然后在内部进行切分管理，释放时归还给缓存而非操作系统</strong>。</p>
<h4 class="anchor anchorTargetStickyNavbar_aDle" id="核心组件">核心组件<a href="#核心组件" class="hash-link" aria-label="Direct link to 核心组件" title="Direct link to 核心组件" translate="no">​</a></h4>
<ul>
<li class=""><strong>Block</strong>: 内存块的基本单位，包含元数据（大小、是否空闲、所属 Stream）。</li>
<li class=""><strong>Pools</strong>:<!-- -->
<ul>
<li class=""><strong>Small Pool</strong>: 管理小于 1MB 的 allocations。通常分配 2MB 的 Page。</li>
<li class=""><strong>Large Pool</strong>: 管理大于 1MB 的 allocations。通常分配 20MB 的 Page。</li>
</ul>
</li>
<li class=""><strong>Split &amp; Merge</strong>: 分配器会尝试将大 Block 切分为小 Block 以满足请求；释放时会尝试合并相邻的空闲 Block 以减少碎片。</li>
</ul>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="22-内存状态与监控">2.2 内存状态与监控<a href="#22-内存状态与监控" class="hash-link" aria-label="Direct link to 2.2 内存状态与监控" title="Direct link to 2.2 内存状态与监控" translate="no">​</a></h3>
<ul>
<li class=""><strong>Allocated Memory</strong>: 实际被 Tensor 占用的内存。</li>
<li class=""><strong>Reserved Memory</strong>: PyTorch 从 CUDA 申请并缓存的总内存（包含 Allocated 和未被使用的 Cached Memory）。</li>
<li class=""><strong>Fragmentation</strong>: 当 Reserved 远大于 Allocated 但仍发生 OOM 时，通常是因为内存碎片化（Memory Fragmentation）。</li>
</ul>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 打印内存统计摘要</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">memory_summary</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 释放未使用的缓存（不推荐频繁调用，会增加后续分配开销）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">empty_cache</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="3-异步执行模型-asynchronous-execution">3. 异步执行模型 (Asynchronous Execution)<a href="#3-异步执行模型-asynchronous-execution" class="hash-link" aria-label="Direct link to 3. 异步执行模型 (Asynchronous Execution)" title="Direct link to 3. 异步执行模型 (Asynchronous Execution)" translate="no">​</a></h2>
<p>默认情况下，PyTorch 的 CUDA 操作是异步的。当 CPU 发起一个 GPU Kernel 调用时，它只是将命令放入 <strong>Command Queue</strong>（命令队列）后立即返回，而不会等待 GPU 执行完毕。</p>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="31-streams-流">3.1 Streams (流)<a href="#31-streams-流" class="hash-link" aria-label="Direct link to 3.1 Streams (流)" title="Direct link to 3.1 Streams (流)" translate="no">​</a></h3>
<p>Stream 是 GPU 上执行序列的抽象。</p>
<ul>
<li class=""><strong>Default Stream (Stream 0)</strong>: 默认使用的流。</li>
<li class=""><strong>Non-default Streams</strong>: 用户创建的流，支持并发执行。</li>
</ul>
<p><strong>并发原理</strong>：不同 Stream 中的 Kernel 可以并行执行（受限于 GPU 硬件资源），从而实现 Compute-Compute Overlap 或 Copy-Compute Overlap。</p>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="32-events-事件">3.2 Events (事件)<a href="#32-events-事件" class="hash-link" aria-label="Direct link to 3.2 Events (事件)" title="Direct link to 3.2 Events (事件)" translate="no">​</a></h3>
<p>Event 是用于 Stream 间同步的轻量级标记。</p>
<ul>
<li class=""><strong>Record</strong>: 在 Stream 中记录一个时间点。</li>
<li class=""><strong>Wait</strong>: 让另一个 Stream 等待该 Event 完成。</li>
<li class=""><strong>Synchronize</strong>: 阻塞 CPU 直到 Event 完成。</li>
</ul>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token plain">s1 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">s2 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 在 s1 上执行操作</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">s1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    A </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">matmul</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">X</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> W</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 同步机制：确保 s2 使用 A 之前，s1 已经计算完毕</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">event </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Event</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">s1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">record_event</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">event</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">s2</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">wait_event</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">event</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># s2 将阻塞直到 event 被记录</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">s2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    B </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> A </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="4-高级性能优化-advanced-optimization">4. 高级性能优化 (Advanced Optimization)<a href="#4-高级性能优化-advanced-optimization" class="hash-link" aria-label="Direct link to 4. 高级性能优化 (Advanced Optimization)" title="Direct link to 4. 高级性能优化 (Advanced Optimization)" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="41-pinned-memory-页锁定内存">4.1 Pinned Memory (页锁定内存)<a href="#41-pinned-memory-页锁定内存" class="hash-link" aria-label="Direct link to 4.1 Pinned Memory (页锁定内存)" title="Direct link to 4.1 Pinned Memory (页锁定内存)" translate="no">​</a></h3>
<p>主机（CPU）内存默认是分页的（Pageable）。GPU 无法直接通过 DMA 访问分页内存。</p>
<ul>
<li class=""><strong>机制</strong>：<code>pin_memory()</code> 将 Tensor 锁定在物理内存中，防止被换出（Swap out）。</li>
<li class=""><strong>优势</strong>：启用 <code>pin_memory=True</code> 和 <code>non_blocking=True</code> 可以实现 <strong>Host-to-Device 传输与 GPU 计算的重叠</strong>。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_aDle" id="42-cuda-graphs">4.2 CUDA Graphs<a href="#42-cuda-graphs" class="hash-link" aria-label="Direct link to 4.2 CUDA Graphs" title="Direct link to 4.2 CUDA Graphs" translate="no">​</a></h3>
<p>针对 CPU-Bound 场景（如小 Batch Size 或大量微小算子），启动 Kernel 的 CPU 开销（Launch Overhead）可能超过 Kernel 执行时间。</p>
<ul>
<li class=""><strong>机制</strong>：<strong>CUDA Graphs</strong> 将一系列 Kernel Capture 成一个静态图，通过单次 API 调用发射整个图。</li>
<li class=""><strong>限制</strong>：不支持动态控制流（Dynamic Control Flow）和动态形状（Dynamic Shapes）。</li>
</ul>
<div class="language-python codeBlockContainer_FVab theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oMSL"><pre tabindex="0" class="prism-code language-python codeBlock_MTmK thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_KEkQ"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># CUDA Graph 示例</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">g </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">CUDAGraph</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Warmup</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">static_input </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> device</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;cuda&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">s </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">s</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">wait_stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">current_stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">s</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> _ </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        static_output </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> static_input </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">current_stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">wait_stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">s</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Capture</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">graph</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">g</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    static_output </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> static_input </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Replay</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">static_input</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copy_</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">real_input</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">g</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">replay</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="5-调试与环境变量-debugging">5. 调试与环境变量 (Debugging)<a href="#5-调试与环境变量-debugging" class="hash-link" aria-label="Direct link to 5. 调试与环境变量 (Debugging)" title="Direct link to 5. 调试与环境变量 (Debugging)" translate="no">​</a></h2>
<p>PyTorch 提供了一系列环境变量用于调试 CUDA 行为：</p>
<ul>
<li class=""><code>CUDA_LAUNCH_BLOCKING=1</code>: 强制同步执行，使报错堆栈指向触发错误的具体代码行（生产环境禁用）。</li>
<li class=""><code>PYTORCH_CUDA_ALLOC_CONF</code>: 调整分配器行为。<!-- -->
<ul>
<li class=""><code>max_split_size_mb</code>: 限制最大切分块大小，减少碎片。</li>
<li class=""><code>garbage_collection_threshold</code>: 设置垃圾回收阈值。</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_aDle" id="6-参考资料-references">6. 参考资料 (References)<a href="#6-参考资料-references" class="hash-link" aria-label="Direct link to 6. 参考资料 (References)" title="Direct link to 6. 参考资料 (References)" translate="no">​</a></h2>
<ol>
<li class=""><strong>PyTorch Documentation: CUDA Semantics</strong>. <a href="https://pytorch.org/docs/stable/notes/cuda.html" target="_blank" rel="noopener noreferrer" class="">https://pytorch.org/docs/stable/notes/cuda.html</a></li>
<li class=""><strong>A Guide to PyTorch’s CUDA Caching Allocator</strong>. <a href="https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html" target="_blank" rel="noopener noreferrer" class="">https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html</a></li>
<li class=""><strong>NVIDIA Developer Blog: CUDA Graphs</strong>. <a href="https://developer.nvidia.com/blog/cuda-graphs/" target="_blank" rel="noopener noreferrer" class="">https://developer.nvidia.com/blog/cuda-graphs/</a></li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_iDCr"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AI/Pytorch/CUDA/简介.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_c0mv" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_mxtt"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes3/docs/AI/Pytorch/CUDA/grad_scaler"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">grad_scaler</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes3/docs/AI/Pytorch/CUDA/自动混合精度"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">自动混合精度</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_r83r thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2-内存管理机制-memory-management" class="table-of-contents__link toc-highlight">2. 内存管理机制 (Memory Management)</a><ul><li><a href="#21-caching-allocator-架构" class="table-of-contents__link toc-highlight">2.1 Caching Allocator 架构</a></li><li><a href="#22-内存状态与监控" class="table-of-contents__link toc-highlight">2.2 内存状态与监控</a></li></ul></li><li><a href="#3-异步执行模型-asynchronous-execution" class="table-of-contents__link toc-highlight">3. 异步执行模型 (Asynchronous Execution)</a><ul><li><a href="#31-streams-流" class="table-of-contents__link toc-highlight">3.1 Streams (流)</a></li><li><a href="#32-events-事件" class="table-of-contents__link toc-highlight">3.2 Events (事件)</a></li></ul></li><li><a href="#4-高级性能优化-advanced-optimization" class="table-of-contents__link toc-highlight">4. 高级性能优化 (Advanced Optimization)</a><ul><li><a href="#41-pinned-memory-页锁定内存" class="table-of-contents__link toc-highlight">4.1 Pinned Memory (页锁定内存)</a></li><li><a href="#42-cuda-graphs" class="table-of-contents__link toc-highlight">4.2 CUDA Graphs</a></li></ul></li><li><a href="#5-调试与环境变量-debugging" class="table-of-contents__link toc-highlight">5. 调试与环境变量 (Debugging)</a></li><li><a href="#6-参考资料-references" class="table-of-contents__link toc-highlight">6. 参考资料 (References)</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>