import marimo

__generated_with = "0.19.2"
app = marimo.App(width="medium")


@app.cell(hide_code=True)
def _():
    import marimo as mo
    import torch
    return mo, torch


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    # æ ¸å¿ƒå‰æï¼šå…ƒç´ æ€»é‡å®ˆæ’

    æ— è®ºä½ æ€ä¹ˆå˜å½¢çŠ¶ï¼Œ**å…ƒç´ çš„æ€»ä¸ªæ•°å¿…é¡»ä¿æŒä¸å˜**ã€‚
    å¦‚æœä½ æœ‰ä¸€ä¸ªå½¢çŠ¶ä¸º$(2,3)$çš„å¼ é‡ï¼ˆæ€»å…± 6 ä¸ªå…ƒç´ ï¼‰ï¼Œä½ å¯ä»¥æŠŠå®ƒå˜æˆ $(1,6)$æˆ–$(6,1)$æˆ– ï¼Œä½†ç»å¯¹ä¸èƒ½å˜æˆ$(2,4)$ã€‚

    æ•°å­¦è¡¨è¾¾å¼ï¼š

    $A \times B = A' \times B'$

    # PyTorch å¼ é‡å˜å½¢æ“ä½œè¯¦è§£

    æœ¬ç¬”è®°æœ¬è¯¦ç»†ä»‹ç» PyTorch ä¸­äº”ä¸ªæ ¸å¿ƒçš„å¼ é‡å˜å½¢ APIï¼š

    | API | ä½œç”¨ | å…³é”®ç‰¹ç‚¹ |
    |-----|------|----------|
    | `.view()` | æ”¹å˜å¼ é‡å½¢çŠ¶ | è¦æ±‚å†…å­˜è¿ç»­ï¼Œè¿”å›è§†å›¾ |
    | `.reshape()` | æ”¹å˜å¼ é‡å½¢çŠ¶ | è‡ªåŠ¨å¤„ç†éè¿ç»­æƒ…å†µ |
    | `.contiguous()` | ç¡®ä¿å†…å­˜è¿ç»­ | å¿…è¦æ—¶åˆ›å»ºå‰¯æœ¬ |
    | `.transpose()` | äº¤æ¢ä¸¤ä¸ªç»´åº¦ | è¿”å›è§†å›¾ï¼Œä¸è¿ç»­ |
    | `.permute()` | ä»»æ„é‡æ’æ‰€æœ‰ç»´åº¦ | è¿”å›è§†å›¾ï¼Œä¸è¿ç»­ |

    ## æ ¸å¿ƒæ¦‚å¿µï¼šè§†å›¾(View) vs æ‹·è´(Copy)

    - **è§†å›¾**ï¼šä¸åŸå¼ é‡å…±äº«å†…å­˜ï¼Œä¿®æ”¹ä¸€ä¸ªä¼šå½±å“å¦ä¸€ä¸ª
    - **æ‹·è´**ï¼šç‹¬ç«‹çš„å†…å­˜ç©ºé—´ï¼Œäº’ä¸å½±å“

    ç†è§£è¿™ä¸ªæ¦‚å¿µå¯¹æ­£ç¡®ä½¿ç”¨è¿™äº› API è‡³å…³é‡è¦ã€‚
    """)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 1. view() - æ”¹å˜å¼ é‡è§†å›¾

    `view(*shape)` è¿”å›ä¸€ä¸ªå…·æœ‰æ–°å½¢çŠ¶çš„å¼ é‡**è§†å›¾**ï¼Œä¸åŸå¼ é‡å…±äº«æ•°æ®ã€‚

    ### å‡½æ•°ç­¾å
    ```python
    Tensor.view(*shape) -> Tensor
    ```

    ### å…³é”®ç‰¹ç‚¹
    - âœ… è¿”å›è§†å›¾ï¼ˆå…±äº«å†…å­˜ï¼‰
    - âœ… æ”¯æŒ `-1` è‡ªåŠ¨æ¨æ–­ç»´åº¦
    - âš ï¸ **è¦æ±‚å¼ é‡å¿…é¡»å†…å­˜è¿ç»­**
    """)
    return


@app.cell
def _(torch):
    # åŸºæœ¬ç”¨æ³•ï¼šå°† 1D å¼ é‡å˜ä¸º 2D
    t1 = torch.arange(12)
    print(f"åŸå§‹å¼ é‡: {t1}")
    print(f"åŸå§‹å½¢çŠ¶: {t1.shape}")

    t1_view = t1.view(3, 4)
    print(f"\nview(3, 4) å:")
    print(t1_view)
    print(f"æ–°å½¢çŠ¶: {t1_view.shape}")
    return t1, t1_view


@app.cell
def _(t1, t1_view):
    # éªŒè¯è§†å›¾å…±äº«å†…å­˜ï¼šä¿®æ”¹ view ä¼šå½±å“åŸå¼ é‡
    t1_view[0, 0] = 999
    print("ä¿®æ”¹ t1_view[0, 0] = 999 å:")
    print(f"t1_view:\n{t1_view}")
    print(f"åŸå§‹ t1: {t1}")  # åŸå¼ é‡ä¹Ÿè¢«ä¿®æ”¹äº†ï¼
    return


@app.cell
def _(torch):
    # ä½¿ç”¨ -1 è‡ªåŠ¨æ¨æ–­ç»´åº¦
    t2 = torch.arange(24)

    # -1 è¡¨ç¤ºè¯¥ç»´åº¦ç”±å…¶ä»–ç»´åº¦è‡ªåŠ¨è®¡ç®—
    print(f"view(2, -1): {t2.view(2, -1).shape}")  # è‡ªåŠ¨æ¨æ–­ä¸º 12
    print(f"view(-1, 6): {t2.view(-1, 6).shape}")  # è‡ªåŠ¨æ¨æ–­ä¸º 4
    print(f"view(2, 3, -1): {t2.view(2, 3, -1).shape}")  # è‡ªåŠ¨æ¨æ–­ä¸º 4
    return


@app.cell
def _(torch):
    # view çš„é™åˆ¶ï¼šå¿…é¡»å†…å­˜è¿ç»­
    t3 = torch.arange(6).view(2, 3)
    print(f"åŸå§‹å¼ é‡:\n{t3}")
    print(f"æ˜¯å¦è¿ç»­: {t3.is_contiguous()}")

    # è½¬ç½®åä¸å†è¿ç»­
    t3_t = t3.t()  # æˆ– t3.transpose(0, 1)
    print(f"\nè½¬ç½®å:\n{t3_t}")
    print(f"æ˜¯å¦è¿ç»­: {t3_t.is_contiguous()}")
    return (t3_t,)


@app.cell
def _(t3_t):
    # å¯¹éè¿ç»­å¼ é‡è°ƒç”¨ view ä¼šæŠ¥é”™
    try:
        t3_t.view(6)
    except RuntimeError as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ: å…ˆè°ƒç”¨ .contiguous()ï¼Œæˆ–ä½¿ç”¨ .reshape()")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 2. reshape() - é‡å¡‘å¼ é‡å½¢çŠ¶

    `reshape(*shape)` ä¸ `view()` ç±»ä¼¼ï¼Œä½†èƒ½è‡ªåŠ¨å¤„ç†éè¿ç»­å¼ é‡ã€‚

    ### å‡½æ•°ç­¾å
    ```python
    Tensor.reshape(*shape) -> Tensor
    ```

    ### ä¸ view() çš„åŒºåˆ«
    | ç‰¹æ€§ | view() | reshape() |
    |------|--------|-----------|
    | å†…å­˜è¿ç»­è¦æ±‚ | å¿…é¡»è¿ç»­ | è‡ªåŠ¨å¤„ç† |
    | è¿”å›ç±»å‹ | å§‹ç»ˆæ˜¯è§†å›¾ | è§†å›¾æˆ–æ‹·è´ |
    | æ€§èƒ½ | æ›´å¿« | å¯èƒ½æ¶‰åŠæ‹·è´ |

    ### ä½¿ç”¨å»ºè®®
    - ç¡®å®šè¿ç»­æ—¶ç”¨ `view()`ï¼ˆæ›´æ˜ç¡®ï¼‰
    - ä¸ç¡®å®šæ—¶ç”¨ `reshape()`ï¼ˆæ›´å®‰å…¨ï¼‰
    """)
    return


@app.cell
def _(torch):
    # reshape åŸºæœ¬ç”¨æ³•ï¼ˆä¸ view ç›¸åŒï¼‰
    r1 = torch.arange(12)
    print(r1)
    r1_reshaped = r1.reshape(3, 4)
    print(f"reshape(3, 4):\n{r1_reshaped}")
    return


@app.cell
def _(torch):
    # reshape å¤„ç†éè¿ç»­å¼ é‡ï¼ˆview åšä¸åˆ°ï¼‰
    r2 = torch.arange(6).view(2, 3)
    r2_t = r2.t()  # è½¬ç½®åä¸è¿ç»­

    print(f"è½¬ç½®åçš„å¼ é‡:\n{r2_t}")
    print(f"æ˜¯å¦è¿ç»­: {r2_t.is_contiguous()}")

    # reshape å¯ä»¥æ­£å¸¸å·¥ä½œ
    r2_flat = r2_t.reshape(6)
    print(f"\nreshape(6) æˆåŠŸ: {r2_flat}")
    return


@app.cell
def _(torch):
    # åˆ¤æ–­ reshape è¿”å›çš„æ˜¯è§†å›¾è¿˜æ˜¯æ‹·è´
    r3 = torch.arange(6).view(2, 3)

    # è¿ç»­å¼ é‡ï¼šè¿”å›è§†å›¾
    r3_reshaped = r3.reshape(3, 2)
    r3_reshaped[0, 0] = 999
    print("è¿ç»­å¼ é‡ reshape åä¿®æ”¹:")
    print(f"r3_reshaped:\n{r3_reshaped}")
    print(f"åŸå§‹ r3:\n{r3}")  # è¢«ä¿®æ”¹äº† = è§†å›¾

    # éè¿ç»­å¼ é‡ï¼šè¿”å›æ‹·è´
    r4 = torch.arange(6).view(2, 3).t()
    r4_reshaped = r4.reshape(6)
    r4_reshaped[0] = 888
    print(f"\néè¿ç»­å¼ é‡ reshape åä¿®æ”¹:")
    print(f"r4_reshaped: {r4_reshaped}")
    print(f"åŸå§‹ r4:\n{r4}")  # æœªè¢«ä¿®æ”¹ = æ‹·è´
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 3. contiguous() - ç¡®ä¿å†…å­˜è¿ç»­

    `contiguous()` è¿”å›ä¸€ä¸ªå†…å­˜è¿ç»­çš„å¼ é‡ã€‚å¦‚æœå·²è¿ç»­ï¼Œè¿”å›è‡ªèº«ï¼›å¦åˆ™åˆ›å»ºå‰¯æœ¬ã€‚

    ### å‡½æ•°ç­¾å
    ```python
    Tensor.contiguous(memory_format=torch.contiguous_format) -> Tensor
    ```

    ### ä»€ä¹ˆæ˜¯å†…å­˜è¿ç»­ï¼Ÿ

    å¼ é‡åœ¨å†…å­˜ä¸­æŒ‰è¡Œä¼˜å…ˆï¼ˆC é¡ºåºï¼‰å­˜å‚¨æ—¶ï¼Œç§°ä¸º**è¿ç»­çš„**ã€‚

    - åˆ›å»ºçš„å¼ é‡é»˜è®¤æ˜¯è¿ç»­çš„
    - `transpose`ã€`permute` ç­‰æ“ä½œä¼šæ”¹å˜å…ƒç´ çš„é€»è¾‘é¡ºåºï¼Œä½†ä¸ç§»åŠ¨å®é™…æ•°æ®ï¼Œå¯¼è‡´ä¸è¿ç»­
    """)
    return


@app.cell
def _(torch):
    # ç†è§£ strideï¼ˆæ­¥é•¿ï¼‰
    c1 = torch.arange(6).view(2, 3)
    print(f"å¼ é‡:\n{c1}")
    print(f"å½¢çŠ¶: {c1.shape}")
    print(f"æ­¥é•¿ stride: {c1.stride()}")
    print("è§£é‡Š: æ²¿ç¬¬0ç»´ç§»åŠ¨1æ­¥éœ€è¦è·³è¿‡3ä¸ªå…ƒç´ ï¼Œæ²¿ç¬¬1ç»´ç§»åŠ¨1æ­¥éœ€è¦è·³è¿‡1ä¸ªå…ƒç´ ")
    return


@app.cell
def _(torch):
    # è½¬ç½®å stride å˜åŒ–
    c2 = torch.arange(6).view(2, 3)
    c2_t = c2.t()

    print(f"åŸå§‹å¼ é‡:\n{c2}")
    print(f"stride: {c2.stride()}, è¿ç»­: {c2.is_contiguous()}")

    print(f"\nè½¬ç½®å:\n{c2_t}")
    print(f"stride: {c2_t.stride()}, è¿ç»­: {c2_t.is_contiguous()}")
    print("è§£é‡Š: è½¬ç½®åæ²¿ç¬¬0ç»´ç§»åŠ¨1æ­¥åªè·³è¿‡1ä¸ªå…ƒç´ ï¼Œä¸ç¬¦åˆè¡Œä¼˜å…ˆé¡ºåº")
    return


@app.cell
def _(torch):
    # contiguous() çš„ä½œç”¨
    c3 = torch.arange(6).view(2, 3).t()
    print(f"éè¿ç»­å¼ é‡:\n{c3}")
    print(f"stride: {c3.stride()}, è¿ç»­: {c3.is_contiguous()}")

    c3_contig = c3.contiguous()
    print(f"\nè°ƒç”¨ contiguous() å:\n{c3_contig}")
    print(f"stride: {c3_contig.stride()}, è¿ç»­: {c3_contig.is_contiguous()}")
    return c3, c3_contig


@app.cell
def _(c3, c3_contig):
    # contiguous() åˆ›å»ºçš„æ˜¯æ‹·è´
    c3_contig[0, 0] = 999
    print("ä¿®æ”¹ c3_contig[0, 0] = 999:")
    print(f"c3_contig:\n{c3_contig}")
    print(f"åŸå§‹ c3:\n{c3}")  # æœªè¢«ä¿®æ”¹
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 4. transpose() - äº¤æ¢ä¸¤ä¸ªç»´åº¦

    `transpose(dim0, dim1)` äº¤æ¢å¼ é‡çš„ä¸¤ä¸ªæŒ‡å®šç»´åº¦ã€‚

    ### å‡½æ•°ç­¾å
    ```python
    Tensor.transpose(dim0, dim1) -> Tensor
    ```

    ### å…³é”®ç‰¹ç‚¹
    - âœ… è¿”å›è§†å›¾ï¼ˆå…±äº«å†…å­˜ï¼‰
    - âš ï¸ ç»“æœé€šå¸¸**ä¸è¿ç»­**
    - ğŸ“ å¯¹äº 2D å¼ é‡ï¼Œ`.t()` æ˜¯ `.transpose(0, 1)` çš„ç®€å†™
    """)
    return


@app.cell
def _(torch):
    # 2D çŸ©é˜µè½¬ç½®
    tr1 = torch.arange(6).view(2, 3)
    print(f"åŸå§‹çŸ©é˜µ (2x3):\n{tr1}")

    tr1_t = tr1.transpose(0, 1)  # ç­‰ä»·äº tr1.t()
    print(f"\ntranspose(0, 1) å (3x2):\n{tr1_t}")
    return


@app.cell
def _(torch):
    # 3D å¼ é‡è½¬ç½®
    tr2 = torch.arange(24).view(2, 3, 4)
    print(f"åŸå§‹å½¢çŠ¶: {tr2.shape}")
    print(f"åŸå§‹å¼ é‡:\n{tr2}")

    # äº¤æ¢ç¬¬1ç»´å’Œç¬¬2ç»´
    tr2_t = tr2.transpose(1, 2)
    print(f"\ntranspose(1, 2) åå½¢çŠ¶: {tr2_t.shape}")
    print(f"è½¬ç½®åå¼ é‡:\n{tr2_t}")
    return


@app.cell
def _(torch):
    # transpose è¿”å›è§†å›¾
    tr3 = torch.arange(6).view(2, 3)
    tr3_t = tr3.transpose(0, 1)

    tr3_t[0, 0] = 999
    print("ä¿®æ”¹ tr3_t[0, 0] = 999:")
    print(f"tr3_t:\n{tr3_t}")
    print(f"åŸå§‹ tr3:\n{tr3}")  # ä¹Ÿè¢«ä¿®æ”¹äº†
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 5. permute() - ä»»æ„é‡æ’æ‰€æœ‰ç»´åº¦

    `permute(*dims)` æŒ‰æŒ‡å®šé¡ºåºé‡æ–°æ’åˆ—å¼ é‡çš„æ‰€æœ‰ç»´åº¦ã€‚

    ### å‡½æ•°ç­¾å
    ```python
    Tensor.permute(*dims) -> Tensor
    ```

    ### ä¸ transpose çš„åŒºåˆ«
    | ç‰¹æ€§ | transpose() | permute() |
    |------|-------------|-----------|
    | æ“ä½œç»´åº¦æ•° | åªèƒ½äº¤æ¢2ä¸ª | å¯é‡æ’æ‰€æœ‰ |
    | å‚æ•° | ä¸¤ä¸ªç»´åº¦ç´¢å¼• | æ–°çš„ç»´åº¦é¡ºåº |
    | å…¸å‹åœºæ™¯ | ç®€å•è½¬ç½® | å¤æ‚ç»´åº¦å˜æ¢ |

    ### å…¸å‹åº”ç”¨
    å›¾åƒæ•°æ®æ ¼å¼è½¬æ¢ï¼š`(H, W, C)` â†” `(C, H, W)`
    """)
    return


@app.cell
def _(torch):
    # permute åŸºæœ¬ç”¨æ³•
    p1 = torch.arange(24).view(2, 3, 4)
    print(f"åŸå§‹å½¢çŠ¶: {p1.shape}")  # (2, 3, 4)

    # å°†ç»´åº¦é¡ºåºä» (0, 1, 2) å˜ä¸º (2, 0, 1)
    p1_permuted = p1.permute(2, 0, 1)
    print(f"permute(2, 0, 1) å: {p1_permuted.shape}")  # (4, 2, 3)
    return


@app.cell
def _(torch):
    # å›¾åƒæ ¼å¼è½¬æ¢ï¼šHWC -> CHW
    # å‡è®¾ä¸€å¼  RGB å›¾åƒï¼Œå½¢çŠ¶ä¸º (é«˜åº¦=4, å®½åº¦=5, é€šé“=3)
    image_hwc = torch.randn(4, 5, 3)
    print(f"HWC æ ¼å¼ (é«˜xå®½xé€šé“): {image_hwc.shape}")

    # PyTorch å·ç§¯å±‚éœ€è¦ CHW æ ¼å¼
    image_chw = image_hwc.permute(2, 0, 1)
    print(f"CHW æ ¼å¼ (é€šé“xé«˜xå®½): {image_chw.shape}")

    # æ‰¹é‡å›¾åƒï¼šNHWC -> NCHW
    batch_nhwc = torch.randn(8, 224, 224, 3)  # 8å¼  224x224 RGBå›¾åƒ
    batch_nchw = batch_nhwc.permute(0, 3, 1, 2)
    print(f"\næ‰¹é‡è½¬æ¢: {batch_nhwc.shape} -> {batch_nchw.shape}")
    return


@app.cell
def _(torch):
    # permute ä¹Ÿè¿”å›è§†å›¾
    p2 = torch.arange(6).view(2, 3)
    p2_permuted = p2.permute(1, 0)  # ç­‰ä»·äº transpose(0, 1)

    p2_permuted[0, 0] = 999
    print("ä¿®æ”¹ p2_permuted[0, 0] = 999:")
    print(f"p2_permuted:\n{p2_permuted}")
    print(f"åŸå§‹ p2:\n{p2}")  # ä¹Ÿè¢«ä¿®æ”¹äº†
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 6. ç»¼åˆå¯¹æ¯”ä¸é€‰æ‹©å»ºè®®

    ### API å¯¹æ¯”è¡¨

    | API | è¿”å›ç±»å‹ | å†…å­˜è¿ç»­è¦æ±‚ | å…¸å‹ç”¨é€” |
    |-----|----------|--------------|----------|
    | `view()` | è§†å›¾ | âœ… å¿…é¡»è¿ç»­ | æ˜ç¡®çŸ¥é“è¿ç»­æ—¶çš„å½¢çŠ¶å˜æ¢ |
    | `reshape()` | è§†å›¾/æ‹·è´ | âŒ æ— è¦æ±‚ | ä¸ç¡®å®šè¿ç»­æ€§æ—¶çš„å½¢çŠ¶å˜æ¢ |
    | `contiguous()` | è‡ªèº«/æ‹·è´ | - | ç¡®ä¿å†…å­˜è¿ç»­ |
    | `transpose()` | è§†å›¾ | âŒ æ— è¦æ±‚ | äº¤æ¢ä¸¤ä¸ªç»´åº¦ |
    | `permute()` | è§†å›¾ | âŒ æ— è¦æ±‚ | ä»»æ„é‡æ’æ‰€æœ‰ç»´åº¦ |

    ### é€‰æ‹©å†³ç­–æ ‘

    ```
    éœ€è¦æ”¹å˜å½¢çŠ¶ï¼Ÿ
    â”œâ”€â”€ æ˜¯ â†’ å¼ é‡ç¡®å®šè¿ç»­ï¼Ÿ
    â”‚       â”œâ”€â”€ æ˜¯ â†’ ç”¨ view()
    â”‚       â””â”€â”€ å¦/ä¸ç¡®å®š â†’ ç”¨ reshape()
    â””â”€â”€ å¦ â†’ éœ€è¦è°ƒæ•´ç»´åº¦é¡ºåºï¼Ÿ
            â”œâ”€â”€ åªäº¤æ¢2ä¸ªç»´åº¦ â†’ ç”¨ transpose()
            â””â”€â”€ é‡æ’å¤šä¸ªç»´åº¦ â†’ ç”¨ permute()

    åç»­éœ€è¦ view()ï¼Ÿ
    â””â”€â”€ æ˜¯ â†’ å…ˆè°ƒç”¨ contiguous()
    ```
    """)
    return


@app.cell
def _(torch):
    # å®æˆ˜ç¤ºä¾‹1ï¼šTransformer ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ç»´åº¦å˜æ¢
    batch_size, seq_len, d_model = 2, 10, 512
    num_heads, d_k = 8, 64

    # è¾“å…¥: (batch, seq_len, d_model)
    x = torch.randn(batch_size, seq_len, d_model)
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")

    # æ‹†åˆ†å¤šå¤´: (batch, seq_len, num_heads, d_k)
    x_split = x.view(batch_size, seq_len, num_heads, d_k)
    print(f"æ‹†åˆ†å¤šå¤´: {x_split.shape}")

    # è°ƒæ•´ä¸º: (batch, num_heads, seq_len, d_k)
    x_transposed = x_split.transpose(1, 2)
    print(f"è½¬ç½®å: {x_transposed.shape}")

    # æˆ–è€…ä¸€æ­¥åˆ°ä½ç”¨ permute
    x_permuted = x_split.permute(0, 2, 1, 3)
    print(f"permute ç»“æœ: {x_permuted.shape}")
    return


@app.cell
def _(torch):
    # å®æˆ˜ç¤ºä¾‹2ï¼šå·ç§¯å±‚è¾“å‡ºå±•å¹³ä¸ºå…¨è¿æ¥å±‚è¾“å…¥
    # å‡è®¾å·ç§¯è¾“å‡º: (batch=4, channels=64, height=7, width=7)
    conv_output = torch.randn(4, 64, 7, 7)
    print(f"å·ç§¯è¾“å‡ºå½¢çŠ¶: {conv_output.shape}")

    # æ–¹æ³•1: ç›´æ¥ view (è¿ç»­å¼ é‡)
    flat1 = conv_output.view(4, -1)  # (4, 64*7*7) = (4, 3136)
    print(f"view å±•å¹³: {flat1.shape}")

    # æ–¹æ³•2: reshape (æ›´å®‰å…¨)
    flat2 = conv_output.reshape(4, -1)
    print(f"reshape å±•å¹³: {flat2.shape}")

    # æ–¹æ³•3: flatten (æ¨èï¼Œè¯­ä¹‰æ›´æ¸…æ™°)
    flat3 = conv_output.flatten(start_dim=1)
    print(f"flatten å±•å¹³: {flat3.shape}")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""
    ## 7. å¸¸è§é”™è¯¯ä¸è§£å†³æ–¹æ¡ˆ

    | é”™è¯¯ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
    |------|------|----------|
    | `view size is not compatible` | å…ƒç´ æ€»æ•°ä¸åŒ¹é… | ç¡®ä¿å˜å½¢å‰åå…ƒç´ æ•°é‡ç›¸åŒ |
    | `cannot view as non-contiguous` | å¯¹éè¿ç»­å¼ é‡è°ƒç”¨ view | å…ˆ `.contiguous()` æˆ–ç”¨ `.reshape()` |
    | ä¿®æ”¹è§†å›¾å½±å“åŸæ•°æ® | view/transpose/permute è¿”å›è§†å›¾ | éœ€è¦ç‹¬ç«‹å‰¯æœ¬æ—¶ç”¨ `.clone()` |
    """)
    return


@app.cell
def _(torch):
    # é”™è¯¯1: å…ƒç´ æ•°é‡ä¸åŒ¹é…
    err1 = torch.arange(12)
    try:
        err1.view(3, 5)  # 12 != 3*5=15
    except RuntimeError as e:
        print(f"âŒ é”™è¯¯: {e}")
    return


@app.cell
def _(torch):
    # å®‰å…¨åˆ›å»ºç‹¬ç«‹å‰¯æœ¬
    original = torch.arange(6).view(2, 3)

    # åˆ›å»ºç‹¬ç«‹å‰¯æœ¬è€Œéè§†å›¾
    independent_copy = original.view(3, 2).clone()
    independent_copy[0, 0] = 999

    print(f"ä¿®æ”¹å‰¯æœ¬å:")
    print(f"å‰¯æœ¬:\n{independent_copy}")
    print(f"åŸå§‹:\n{original}")  # æœªè¢«ä¿®æ”¹
    return


if __name__ == "__main__":
    app.run()
