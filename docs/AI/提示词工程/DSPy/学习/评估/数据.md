---
sidebar_position: 5
---

DSPy 是一个机器学习框架，因此在其中工作涉及训练集、开发集和测试集。对于数据中的每个示例，我们通常区分三种类型的值：输入、中间标签和最终标签。你可以有效地使用 DSPy 而无需任何中间或最终标签，但你至少需要一些示例输入。

## DSPy `Example` 对象

DSPy 中数据的核心数据类型是 `Example`。你将使用 **Example** 来表示训练集和测试集中的项目。

DSPy **Example** 类似于 Python 的 `dict`，但具有一些有用的实用程序。你的 DSPy 模块将返回类型为 `Prediction` 的值，它是 `Example` 的一个特殊子类。

当你使用 DSPy 时，你将进行大量的评估和优化运行。你的单个数据点将是 `Example` 类型：

```python
qa_pair = dspy.Example(question="This is a question?", answer="This is an answer.")

print(qa_pair)
print(qa_pair.question)
print(qa_pair.answer)
```
**输出:**
```text
Example({'question': 'This is a question?', 'answer': 'This is an answer.'}) (input_keys=None)
This is a question?
This is an answer.
```

示例可以有任何字段键和任何值类型，尽管通常值是字符串。

```text
object = Example(field1=value1, field2=value2, field3=value3, ...)
```

你现在可以将你的训练集表示为：

```python
trainset = [dspy.Example(report="LONG REPORT 1", summary="short summary 1"), ...]
```

### 指定输入键

在传统机器学习中，有分离的“输入”和“标签”。

在 DSPy 中，`Example` 对象有一个 `with_inputs()` 方法，可以将特定字段标记为输入。（其余的只是元数据或标签。）

```python
# 单个输入。
print(qa_pair.with_inputs("question"))

# 多个输入；除非你是认真的，否则请小心将你的标签标记为输入。
print(qa_pair.with_inputs("question", "answer"))
```

可以使用 `.`（点）运算符访问值。你可以通过 `object.name` 访问已定义对象 `Example(name="John Doe", job="sleep")` 中键 `name` 的值。

要访问或排除某些键，请使用 `inputs()` 和 `labels()` 方法分别返回仅包含输入或非输入键的新 Example 对象。

```python
article_summary = dspy.Example(article= "This is an article.", summary= "This is a summary.").with_inputs("article")

input_key_only = article_summary.inputs()
non_input_key_only = article_summary.labels()

print("Example object with Input fields only:", input_key_only)
print("Example object with Non-Input fields only:", non_input_key_only)
```

**输出**
```
Example object with Input fields only: Example({'article': 'This is an article.'}) (input_keys={'article'})
Example object with Non-Input fields only: Example({'summary': 'This is a summary.'}) (input_keys=None)
```

<!-- ## 从源加载数据集

在 DSPy 中导入数据集最方便的方法之一是使用 `DataLoader`。第一步是声明一个对象，然后可以使用此对象调用实用程序以不同格式加载数据集：

```python
from dspy.datasets import DataLoader

dl = DataLoader()
```

对于大多数数据集格式，这非常简单，你将文件路径传递给格式的相应方法，你将获得作为回报的数据集的 `Example` 列表：

```python
import pandas as pd

csv_dataset = dl.from_csv(
    "sample_dataset.csv",
    fields=("instruction", "context", "response"),
    input_keys=("instruction", "context")
)

json_dataset = dl.from_json(
    "sample_dataset.json",
    fields=("instruction", "context", "response"),
    input_keys=("instruction", "context")
)

parquet_dataset = dl.from_parquet(
    "sample_dataset.parquet",
    fields=("instruction", "context", "response"),
    input_keys=("instruction", "context")
)

pandas_dataset = dl.from_pandas(
    pd.read_csv("sample_dataset.csv"),    # DataFrame
    fields=("instruction", "context", "response"),
    input_keys=("instruction", "context")
)
```

这些是 `DataLoader` 支持直接从文件加载的一些格式。在后端，这些方法大多利用 `datasets` 库中的 `load_dataset` 方法来加载这些格式。但是在使用文本数据时，你经常使用 HuggingFace 数据集，为了以 `Example` 列表格式导入 HF 数据集，我们可以使用 `from_huggingface` 方法：

```python
blog_alpaca = dl.from_huggingface(
    "intertwine-expel/expel-blog",
    input_keys=("title",)
)
```

你可以通过访问相应的键来访问数据集的拆分：

```python
train_split = blog_alpaca['train']

# 由于这是数据集中的唯一拆分，我们可以通过切片或从训练拆分中采样 75 行进行测试，
# 自己将其拆分为训练和测试拆分。
testset = train_split[:75]
trainset = train_split[75:]
```

使用 `load_dataset` 加载 HuggingFace 数据集的方式与通过 `from_huggingface` 加载数据的方式完全相同。这包括传递特定的拆分、子拆分、读取指令等。有关代码片段，你可以参考用于从 HF 加载的 [备忘单片段](/cheatsheet/#dspy-dataloaders)。 -->
