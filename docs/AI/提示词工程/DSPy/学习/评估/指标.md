---
sidebar_position: 5
---

DSPy 是一个机器学习框架，因此你必须考虑用于评估（跟踪进度）和优化（以便 DSPy 可以使你的程序更有效）的 **自动指标**。

## 什么是指标，我该如何为我的任务定义指标？

指标只是一个函数，它从你的数据中获取示例并获取系统的输出，然后返回一个量化输出好坏的分数。是什么让你的系统输出好或坏？

对于简单的任务，这可能只是“准确性”或“完全匹配”或“F1 分数”。对于简单的分类或简短的问答任务，情况可能如此。

然而，对于大多数应用程序，你的系统将输出长格式的输出。在那里，你的指标可能应该是一个较小的 DSPy 程序，用于检查输出的多个属性（很可能使用来自 LM 的 AI 反馈）。

第一次尝试就做对是不太可能的，但你应该从简单的事情开始并进行迭代。

## 简单指标

DSPy 指标只是 Python 中的一个函数，它接受 `example`（例如，来自你的训练或开发集）和来自你的 DSPy 程序的输出 `pred`，并输出一个 `float`（或 `int` 或 `bool`）分数。

你的指标还应该接受一个名为 `trace` 的可选第三个参数。你可以暂时忽略这一点，但如果你想将指标用于优化，它将启用一些强大的技巧。

这是一个比较 `example.answer` 和 `pred.answer` 的简单指标示例。这个特定的指标将返回一个 `bool`。

```python
def validate_answer(example, pred, trace=None):
    return example.answer.lower() == pred.answer.lower()
```

有些人发现这些（内置）实用程序很方便：

- `dspy.evaluate.metrics.answer_exact_match`
- `dspy.evaluate.metrics.answer_passage_match`

你的指标可能更复杂，例如检查多个属性。如果 `trace is None`（即，如果它用于评估或优化），下面的指标将返回一个 `float`，否则将返回一个 `bool`（即，如果它用于引导演示）。

```python
def validate_context_and_answer(example, pred, trace=None):
    # 检查黄金标签和预测答案是否相同
    answer_match = example.answer.lower() == pred.answer.lower()

    # 检查预测答案是否来自检索到的上下文之一
    context_match = any((pred.answer.lower() in c) for c in pred.context)

    if trace is None: # 如果我们正在进行评估或优化
        return (answer_match + context_match) / 2.0
    else: # 如果我们正在进行引导，即自我生成每一步的良好演示
        return answer_match and context_match
```

定义一个好的指标是一个迭代过程，因此进行一些初始评估并查看你的数据和输出是关键。

## 评估

一旦有了指标，就可以在简单的 Python 循环中运行评估。

```python
scores = []
for x in devset:
    pred = program(**x.inputs())
    score = metric(x, pred)
    scores.append(score)
```

如果你需要一些实用程序，还可以使用内置的 `Evaluate` 实用程序。它可以帮助解决并行评估（多线程）或向你展示输入/输出样本和指标分数等问题。

```python
from dspy.evaluate import Evaluate

# 设置评估器，可以在代码中重复使用。
evaluator = Evaluate(devset=YOUR_DEVSET, num_threads=1, display_progress=True, display_table=5)

# 启动评估。
evaluator(YOUR_PROGRAM, metric=YOUR_METRIC)
```

## 中级：为你的指标使用 AI 反馈

对于大多数应用程序，你的系统将输出长格式的输出，因此你的指标应该使用来自 LM 的 AI 反馈检查输出的多个维度。

这个简单的签名可能会派上用场。

```python
# 定义用于自动评估的签名。
class Assess(dspy.Signature):
    """Assess the quality of a tweet along the specified dimension."""

    assessed_text = dspy.InputField()
    assessment_question = dspy.InputField()
    assessment_answer: bool = dspy.OutputField()
```

例如，下面是一个简单的指标，它检查生成的推文 (1) 是否正确回答了给定问题，以及 (2) 它是否也引人入胜。我们还检查 (3) `len(tweet) <= 280` 个字符。

```python
def metric(gold, pred, trace=None):
    question, answer, tweet = gold.question, gold.answer, pred.output

    engaging = "Does the assessed text make for a self-contained, engaging tweet?"
    correct = f"The text should answer `{question}` with `{answer}`. Does the assessed text contain this answer?"
    
    correct =  dspy.Predict(Assess)(assessed_text=tweet, assessment_question=correct)
    engaging = dspy.Predict(Assess)(assessed_text=tweet, assessment_question=engaging)

    correct, engaging = [m.assessment_answer for m in [correct, engaging]]
    score = (correct + engaging) if correct and (len(tweet) <= 280) else 0

    if trace is not None: return score >= 2
    return score / 2.0
```

在编译时，`trace is not None`，我们要严格判断事物，所以我们只有在 `score >= 2` 时才返回 `True`。否则，我们返回 1.0 分制的分数（即 `score / 2.0`）。

## 高级：使用 DSPy 程序作为你的指标

如果你的指标本身就是一个 DSPy 程序，那么迭代的最强大方法之一就是编译（优化）你的指标本身。这通常很容易，因为指标的输出通常是一个简单的值（例如，5 分制的分数），因此通过收集几个示例很容易定义和优化指标的指标。

### 高级：访问 `trace`

当你的指标在评估运行期间使用时，DSPy 将不会尝试跟踪程序的步骤。

但在编译（优化）期间，DSPy 将跟踪你的 LM 调用。跟踪将包含每个 DSPy 预测器的输入/输出，你可以利用它来验证优化的中间步骤。

```python
def validate_hops(example, pred, trace=None):
    hops = [example.question] + [outputs.query for *_, outputs in trace if 'query' in outputs]

    if max([len(h) for h in hops]) > 100: return False
    if any(dspy.evaluate.answer_exact_match_str(hops[idx], hops[:idx], frac=0.8) for idx in range(2, len(hops))): return False

    return True
```