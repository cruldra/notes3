---
sidebar_position: 1
---


**DSPy 优化器** (原 Teleprompters) 是一种算法，它可以调整 DSPy 程序的参数（即提示和/或 LM 权重），以最大化你指定的指标（如准确性）。

典型的 DSPy 优化器需要三样东西：

- 你的 **DSPy 程序**。这可能是一个模块（例如 `dspy.Predict`）或一个复杂的多模块程序。

- 你的 **指标**。这是一个评估程序输出并为其分配分数（越高越好）的函数。

- 一些 **训练输入**。这可能非常少（即只有 5 或 10 个示例）且不完整（只有程序的输入，没有任何标签）。

如果你恰好有很多数据，DSPy 可以利用它。但你可以从小处着手并获得很好的结果。

**注意：** 以前称为 Teleprompters。我们要进行正式的名称更新，这将反映在整个库和文档中。

## DSPy 优化器调整什么？它如何调整它们？

DSPy 中的不同优化器将通过以下方式调整你的程序质量：**为每个模块合成良好的少样本示例**，如 `dspy.BootstrapRS`，<sup>[1](https://arxiv.org/abs/2310.03714)</sup> **为每个提示提出并智能地探索更好的自然语言指令**，如 `dspy.MIPROv2`，<sup>[2](https://arxiv.org/abs/2406.11695)</sup> 和 `dspy.GEPA`，<sup>[3](https://arxiv.org/abs/2507.19457)</sup> 以及 **为你的模块构建数据集并使用它们来微调系统中的 LM 权重**，如 `dspy.BootstrapFinetune`。<sup>[4](https://arxiv.org/abs/2407.10930)</sup>

<details>
<summary>DSPy 优化器的例子是什么？不同的优化器是如何工作的？</summary>

以 `dspy.MIPROv2` 优化器为例。首先，MIPRO 从**引导（bootstrapping）阶段**开始。它接受你的程序（此时可能未优化），并在不同的输入上多次运行它，以收集每个模块的输入/输出行为轨迹。它过滤这些轨迹，只保留出现在你的指标得分较高的轨迹中的轨迹。其次，MIPRO 进入其**基础建议（grounded proposal）阶段**。它预览你的 DSPy 程序的代码、数据以及运行程序的轨迹，并利用它们为程序中的每个提示起草许多潜在的指令。第三，MIPRO 启动**离散搜索阶段**。它从你的训练集中采样 mini-batch，提出用于构建管道中每个提示的指令和轨迹组合，并在 mini-batch 上评估候选程序。利用由此产生的得分，MIPRO 更新一个代理模型，该模型有助于建议随时间变得更好。

DSPy 优化器之所以如此强大，原因之一是它们可以组合使用。你可以运行 `dspy.MIPROv2` 并将生成的程序再次用作 `dspy.MIPROv2` 的输入，或者，比如说，用作 `dspy.BootstrapFinetune` 的输入以获得更好的结果。这在一定程度上是 `dspy.BetterTogether` 的精髓。或者，你可以运行优化器，然后提取前 5 个候选程序并构建它们的 `dspy.Ensemble`。这允许你以高度系统化的方式扩展*推理时计算*（例如，集成）以及 DSPy 独特的*预推理时计算*（即优化预算）。

</details>

## 目前有哪些可用的 DSPy 优化器？

可以通过 `from dspy.teleprompt import *` 访问优化器。

### 自动少样本学习 (Automatic Few-Shot Learning)

这些优化器通过自动生成并在发送给模型的提示中包含 **优化的** 示例来扩展签名，从而实现少样本学习。

1. **`LabeledFewShot`**: 简单地从提供的标记输入和输出数据点构建少样本示例（演示）。需要 `k`（提示的示例数量）和 `trainset` 以从中随机选择 `k` 个示例。

2. **`BootstrapFewShot`**: 使用 `teacher` 模块（默认为你的程序）为你程序的每个阶段生成完整的演示，以及 `trainset` 中的标记示例。参数包括 `max_labeled_demos`（从 `trainset` 中随机选择的演示数量）和 `max_bootstrapped_demos`（由 `teacher` 生成的附加示例数量）。引导过程使用指标来验证演示，仅包括那些在“编译”提示中通过指标的演示。高级：支持使用 `teacher` 程序，该程序是具有兼容结构的 *不同* DSPy 程序，用于更难的任务。

3. **`BootstrapFewShotWithRandomSearch`**: 多次应用 `BootstrapFewShot` 并在生成的演示上进行随机搜索，并在优化过程中选择最佳程序。参数反映了 `BootstrapFewShot` 的参数，此外还有 `num_candidate_programs`，它指定了优化过程中评估的随机程序的数量，包括未编译程序的候选者、`LabeledFewShot` 优化程序、带有未混洗示例的 `BootstrapFewShot` 编译程序以及带有随机示例集的 `num_candidate_programs` 个 `BootstrapFewShot` 编译程序。

4. **`KNNFewShot`**: 使用 k-最近邻算法为给定输入示例查找最近的训练示例演示。这些最近邻演示随后被用作 BootstrapFewShot 优化过程的训练集。

### 自动指令优化 (Automatic Instruction Optimization)

这些优化器为提示生成最佳指令，在 MIPROv2 的情况下，还可以优化少样本演示集。

5. **`COPRO`**: 为每个步骤生成并优化新指令，并使用坐标上升（使用度量函数和 `trainset` 进行爬山）对其进行优化。参数包括 `depth`，即优化器运行的提示改进迭代次数。

6. **`MIPROv2`**: 在每一步中生成指令 *和* 少样本示例。指令生成是数据感知和演示感知的。使用贝叶斯优化在模块的生成指令/演示空间中进行有效搜索。

7. **`SIMBA`**: 使用随机 mini-batch 采样来识别具有高输出变异性的挑战性示例，然后应用 LLM 进行内省性分析故障并生成自我反思的改进规则或添加成功的演示。

8. **`GEPA`**: 使用 LM 反思 DSPy 程序的轨迹，识别哪些有效，哪些无效，并提出解决差距的提示。此外，GEPA 可以利用特定领域的文本反馈来快速改进 DSPy 程序。

### 自动微调 (Automatic Finetuning)

此优化器用于微调底层 LLM。

9. **`BootstrapFinetune`**: 将基于提示的 DSPy 程序蒸馏为权重更新。输出是一个 DSPy 程序，它具有相同的步骤，但每个步骤由微调后的模型而不是提示的 LM 执行。

### 程序转换 (Program Transformations)

10. **`Ensemble`**: 集成一组 DSPy 程序，并使用完整集合或随机采样一个子集到一个程序中。

## 我应该使用哪个优化器？

归根结底，找到“正确”的优化器以及为你的任务找到最佳配置需要实验。DSPy 的成功仍然是一个迭代过程——在你的任务上获得最佳性能需要你探索和迭代。

话虽如此，以下是入门的一般指导：

- 如果你的 **示例非常少**（大约 10 个），从 `BootstrapFewShot` 开始。
- 如果你有 **更多数据**（50 个示例或更多），尝试 `BootstrapFewShotWithRandomSearch`。
- 如果你更喜欢 **仅进行指令优化**（即你想保持你的提示为 0-shot），使用配置为 0-shot 优化的 `MIPROv2`。
- 如果你愿意使用更多推理调用来执行 **更长的优化运行**（例如 40 次试验或更多），并且有足够的数据（例如 200 个示例或更多以防止过拟合），那么尝试 `MIPROv2`。
- 如果你已经能够使用大型 LM（例如 7B 参数或以上）使用其中之一，并且需要一个非常 **高效的程序**，请使用 `BootstrapFinetune` 为你的任务微调一个小 LM。

## 我如何使用优化器？

它们都共享这个通用接口，关键字参数（超参数）有一些差异。

让我们以最常见的 `BootstrapFewShotWithRandomSearch` 为例。

```python
from dspy.teleprompt import BootstrapFewShotWithRandomSearch

# 设置优化器：我们要为你的程序步骤“引导”（即自动生成）8-shot 示例。
# 优化器将重复此操作 10 次（加上一些初始尝试），然后在开发集上选择最佳尝试。
config = dict(max_bootstrapped_demos=4, max_labeled_demos=4, num_candidate_programs=10, num_threads=4)

teleprompter = BootstrapFewShotWithRandomSearch(metric=YOUR_METRIC_HERE, **config)
optimized_program = teleprompter.compile(YOUR_PROGRAM_HERE, trainset=YOUR_TRAINSET_HERE)
```

!!! info "入门 III：优化 DSPy 程序中的 LM 提示或权重"
    典型的简单优化运行成本约为 2 美元，大约需要十分钟，但在使用非常大的 LM 或非常大的数据集运行优化器时要小心。
    优化器运行的成本可能低至几美分，也可能高达几十美元，具体取决于你的 LM、数据集和配置。

### 示例 1: 优化 ReAct 智能体的提示

这是一个最小但完全可运行的示例，设置了一个 `dspy.ReAct` 智能体，通过维基百科搜索回答问题，然后在 `HotPotQA` 数据集中采样的 500 个问答对上，使用廉价的 `light` 模式的 `dspy.MIPROv2` 对其进行优化。

```python
import dspy
from dspy.datasets import HotPotQA

dspy.configure(lm=dspy.LM('openai/gpt-4o-mini'))

def search(query: str) -> list[str]:
    """Retrieves abstracts from Wikipedia."""
    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)
    return [x['text'] for x in results]

trainset = [x.with_inputs('question') for x in HotPotQA(train_seed=2024, train_size=500).train]
react = dspy.ReAct("question -> answer", tools=[search])

tp = dspy.MIPROv2(metric=dspy.evaluate.answer_exact_match, auto="light", num_threads=24)
optimized_react = tp.compile(react, trainset=trainset)
```

在 DSPy 2.5.29 上类似这样的非正式运行将 ReAct 的得分从 24% 提高到 51%。

### 示例 2: 优化 RAG 的提示

给定一个用于 `search` 的检索索引、你最喜欢的 `dspy.LM` 以及一小组问题和真实答案的 `trainset`，以下代码片段可以针对内置的 `dspy.SemanticF1` 指标（作为 DSPy 模块实现）优化具有长输出的 RAG 系统。

```python
class RAG(dspy.Module):
    def __init__(self, num_docs=5):
        self.num_docs = num_docs
        self.respond = dspy.ChainOfThought('context, question -> response')

    def forward(self, question):
        context = search(question, k=self.num_docs)   # 未在此片段中定义，请参阅上面的链接
        return self.respond(context=context, question=question)

tp = dspy.MIPROv2(metric=dspy.SemanticF1(), auto="medium", num_threads=24)
optimized_rag = tp.compile(RAG(), trainset=trainset, max_bootstrapped_demos=2, max_labeled_demos=2)
```

有关可运行的完整 RAG 示例，请参考 DSPy 官方文档。它将 RAG 系统在 StackExchange 社区子集上的质量从 53% 提高到 61%。

### 示例 3: 优化分类的权重

<details>
<summary>点击显示数据集设置代码</summary>

```python
import random
from typing import Literal

from datasets import load_dataset

import dspy
from dspy.datasets import DataLoader

# Load the Banking77 dataset.
CLASSES = load_dataset("PolyAI/banking77", split="train", trust_remote_code=True).features["label"].names
kwargs = {"fields": ("text", "label"), "input_keys": ("text",), "split": "train", "trust_remote_code": True}

# Load the first 2000 examples from the dataset, and assign a hint to each *training* example.
trainset = [
    dspy.Example(x, hint=CLASSES[x.label], label=CLASSES[x.label]).with_inputs("text", "hint")
    for x in DataLoader().from_huggingface(dataset_name="PolyAI/banking77", **kwargs)[:2000]
]
random.Random(0).shuffle(trainset)
```

</details>

```python
import dspy
lm=dspy.LM('openai/gpt-4o-mini-2024-07-18')

# Define the DSPy module for classification. It will use the hint at training time, if available.
signature = dspy.Signature("text, hint -> label").with_updated_fields('label', type_=Literal[tuple(CLASSES)])
classify = dspy.ChainOfThought(signature)
classify.set_lm(lm)

# Optimize via BootstrapFinetune.
optimizer = dspy.BootstrapFinetune(metric=(lambda x, y, trace=None: x.label == y.label), num_threads=24)
optimized = optimizer.compile(classify, trainset=trainset)

optimized(text="What does a pending cash withdrawal mean?")

# For a complete fine-tuning tutorial, see: https://dspy.ai/tutorials/classification_finetuning/
```

**可能的输出（来自最后一行）:**

```text
Prediction(
    reasoning='A pending cash withdrawal indicates that a request to withdraw cash has been initiated but has not yet been completed or processed. This status means that the transaction is still in progress and the funds have not yet been deducted from the account or made available to the user.',
    label='pending_cash_withdrawal'
)
```

在 DSPy 2.5.29 上类似这样的非正式运行将 GPT-4o-mini 的得分从 66% 提高到 87%。


## 保存和加载优化器输出

通过优化器运行程序后，保存它也很有用。在稍后的时间点，可以从文件加载程序并用于推理。为此，可以使用 `load` 和 `save` 方法。

```python
optimized_program.save(YOUR_SAVE_PATH)
```

结果文件是纯文本 JSON 格式。它包含源程序中的所有参数和步骤。你可以随时阅读它并查看优化器生成的内容。

要从文件加载程序，你可以实例化该类的一个对象，然后对其调用 load 方法。

```python
loaded_program = YOUR_PROGRAM_CLASS()
loaded_program.load(path=YOUR_SAVE_PATH)
```