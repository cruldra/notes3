---
sidebar_position: 1
---

一旦你有了一个系统和一种评估它的方法，你就可以使用 DSPy 优化器来调整程序中的提示或权重。现在，除了用于探索的开发集之外，将你的数据收集工作扩展到构建训练集和保留测试集是很有用的。对于训练集（及其子集，验证集），你通常可以从 30 个示例中获得巨大的价值，但目标是至少 300 个示例。有些优化器只接受 `trainset`。其他优化器要求 `trainset` 和 `valset`。在为大多数提示优化器分割数据时，与深度神经网络相比，我们建议使用一种不寻常的分割：20% 用于训练，80% 用于验证。这种反向分配强调稳定的验证，因为基于提示的优化器通常会对小型训练集过拟合。相比之下，[dspy.GEPA](https://dspy.ai/tutorials/gepa_ai_program/) 优化器遵循更标准的 ML 惯例：最大化训练集大小，同时保持验证集刚好足以反映下游任务（测试集）的分布。

在你最初的几次优化运行之后，你要么对一切都非常满意，要么你已经取得了很大进步，但你不喜欢最终程序或指标的某些方面。此时，回到步骤 1（DSPy 编程）并重新审视主要问题。你的任务定义得好吗？你需要为你的问题收集（或在线查找）更多数据吗？你想更新你的指标吗？你想使用更复杂的优化器吗？你需要考虑像 DSPy Assertions 这样的高级功能吗？或者，也许最重要的是，你想在你的 DSPy 程序本身中添加更多复杂性或步骤吗？你想按顺序使用多个优化器吗？

迭代开发是关键。DSPy 提供了让你逐步做到这一点的组件：迭代你的数据、你的程序结构、你的指标和你的优化步骤。优化复杂的 LM 程序是一个全新的范式，在撰写本文时仅存在于 DSPy 中（更新：现在有许多 DSPy 扩展框架，所以这部分不再是真的了 :-)），所以关于该怎么做的规范自然仍在形成中。如果你需要帮助，我们最近为社区创建了一个 [Discord 服务器](https://discord.gg/XCGy2WDCQB)。