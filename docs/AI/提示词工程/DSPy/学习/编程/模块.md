---
sidebar_position: 3
---

**DSPy 模块** 是使用 LM 的程序的构建块。

- 每个内置模块抽象了一种 **提示技术**（如思维链 Chain of Thought 或 ReAct）。至关重要的是，它们被泛化以处理任何签名。

- DSPy 模块具有 **可学习的参数**（即构成提示的小片段和 LM 权重），并且可以被调用以处理输入并返回输出。

- 多个模块可以组合成更大的模块（程序）。DSPy 模块直接受 PyTorch 中 NN 模块的启发，但应用于 LM 程序。

## 我该如何使用内置模块，如 `dspy.Predict` 或 `dspy.ChainOfThought`？

让我们从最基础的模块 `dspy.Predict` 开始。在内部，所有其他 DSPy 模块都是使用 `dspy.Predict` 构建的。我们假设你已经至少稍微熟悉 [DSPy 签名](signatures.md)，这是用于定义我们在 DSPy 中使用的任何模块行为的声明性规范。

要使用模块，我们首先通过为其提供签名来 **声明** 它。然后我们使用输入参数 **调用** 该模块，并提取输出字段！

```python
sentence = "it's a charming and often affecting journey."  # 来自 SST-2 数据集的示例。

# 1) 用签名声明。
classify = dspy.Predict('sentence -> sentiment: bool')

# 2) 使用输入参数调用。 
response = classify(sentence=sentence)

# 3) 访问输出。
print(response.sentiment)
```
**输出:**
```text
True
```

当我们声明一个模块时，我们可以向其传递配置键。

下面，我们将传递 `n=5` 来请求五个补全。我们也可以传递 `temperature` 或 `max_len` 等。

让我们使用 `dspy.ChainOfThought`。在许多情况下，简单地用 `dspy.ChainOfThought` 替换 `dspy.Predict` 就能提高质量。

```python
question = "What's something great about the ColBERT retrieval model?"

# 1) 用签名声明，并传递一些配置。
classify = dspy.ChainOfThought('question -> answer', n=5)

# 2) 使用输入参数调用。
response = classify(question=question)

# 3) 访问输出。
response.completions.answer
```
**可能的输出:**
```text
['One great thing about the ColBERT retrieval model is its superior efficiency and effectiveness compared to other models.',
 'Its ability to efficiently retrieve relevant information from large document collections.',
 'One great thing about the ColBERT retrieval model is its superior performance compared to other models and its efficient use of pre-trained language models.',
 'One great thing about the ColBERT retrieval model is its superior efficiency and accuracy compared to other models.',
 'One great thing about the ColBERT retrieval model is its ability to incorporate user feedback and support complex queries.']
```

让我们在这里讨论一下输出对象。`dspy.ChainOfThought` 模块通常会在签名的输出字段之前注入 `reasoning`（推理）。

让我们检查（第一个）推理和答案！

```python
print(f"Reasoning: {response.reasoning}")
print(f"Answer: {response.answer}")
```
**可能的输出:**
```text
Reasoning: We can consider the fact that ColBERT has shown to outperform other state-of-the-art retrieval models in terms of efficiency and effectiveness. It uses contextualized embeddings and performs document retrieval in a way that is both accurate and scalable.
Answer: One great thing about the ColBERT retrieval model is its superior efficiency and effectiveness compared to other models.
```

无论我们请求一个还是多个补全，都可以访问它。

我们还可以将不同的补全作为 `Prediction` 列表或多个列表（每个字段一个）来访问。

```python
response.completions[3].reasoning == response.completions.reasoning[3]
```
**输出:**
```text
True
```

## 还有哪些其他 DSPy 模块？我该如何使用它们？

其他的非常相似。它们主要改变实现签名的内部行为！

1. **`dspy.Predict`**: 基本预测器。不修改签名。处理学习的关键形式（即存储指令和演示以及对 LM 的更新）。

2. **`dspy.ChainOfThought`**: 教导 LM 在提交签名的响应之前逐步思考。

3. **`dspy.ProgramOfThought`**: 教导 LM 输出代码，其执行结果将决定响应。

4. **`dspy.ReAct`**: 一个可以使用工具来实现给定签名的智能体。

5. **`dspy.MultiChainComparison`**: 可以比较来自 `ChainOfThought` 的多个输出以产生最终预测。

我们还有一些函数式模块：

6. **`dspy.majority`**: 可以进行基本投票，从一组预测中返回最受欢迎的响应。

!!! info "简单任务上的 DSPy 模块示例。"
    配置好 `lm` 后，尝试下面的示例。调整字段以探索你的 LM 开箱即用地可以很好地完成哪些任务。

    === "数学 (Math)"

        ```python linenums="1"
        math = dspy.ChainOfThought("question -> answer: float")
        math(question="Two dice are tossed. What is the probability that the sum equals two?")
        ```
        
        **可能的输出:**
        ```text
        Prediction(
            reasoning='When two dice are tossed, each die has 6 faces, resulting in a total of 6 x 6 = 36 possible outcomes. The sum of the numbers on the two dice equals two only when both dice show a 1. This is just one specific outcome: (1, 1). Therefore, there is only 1 favorable outcome. The probability of the sum being two is the number of favorable outcomes divided by the total number of possible outcomes, which is 1/36.',
            answer=0.0277776
        )
        ```

    === "检索增强生成 (RAG)"

        ```python linenums="1"       
        def search(query: str) -> list[str]:
            """Retrieves abstracts from Wikipedia."""
            results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)
            return [x['text'] for x in results]
        
        rag = dspy.ChainOfThought('context, question -> response')

        question = "What's the name of the castle that David Gregory inherited?"
        rag(context=search(question), question=question)
        ```
        
        **可能的输出:**
        ```text
        Prediction(
            reasoning='The context provides information about David Gregory, a Scottish physician and inventor. It specifically mentions that he inherited Kinnairdy Castle in 1664. This detail directly answers the question about the name of the castle that David Gregory inherited.',
            response='Kinnairdy Castle'
        )
        ```

    === "分类 (Classification)"

        ```python linenums="1"
        from typing import Literal

        class Classify(dspy.Signature):
            """Classify sentiment of a given sentence."""
            
            sentence: str = dspy.InputField()
            sentiment: Literal['positive', 'negative', 'neutral'] = dspy.OutputField()
            confidence: float = dspy.OutputField()

        classify = dspy.Predict(Classify)
        classify(sentence="This book was super fun to read, though not the last chapter.")
        ```
        
        **可能的输出:**

        ```text
        Prediction(
            sentiment='positive',
            confidence=0.75
        )
        ```

    === "信息提取 (Information Extraction)"

        ```python linenums="1"        
        text = "Apple Inc. announced its latest iPhone 14 today. The CEO, Tim Cook, highlighted its new features in a press release."

        module = dspy.Predict("text -> title, headings: list[str], entities_and_metadata: list[dict[str, str]]")
        response = module(text=text)

        print(response.title)
        print(response.headings)
        print(response.entities_and_metadata)
        ```
        
        **可能的输出:**
        ```text
        Apple Unveils iPhone 14
        ['Introduction', 'Key Features', "CEO's Statement"]
        [{'entity': 'Apple Inc.', 'type': 'Organization'}, {'entity': 'iPhone 14', 'type': 'Product'}, {'entity': 'Tim Cook', 'type': 'Person'}]
        ```

    === "智能体 (Agents)"

        ```python linenums="1"       
        def evaluate_math(expression: str) -> float:
            return dspy.PythonInterpreter({}).execute(expression)

        def search_wikipedia(query: str) -> str:
            results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)
            return [x['text'] for x in results]

        react = dspy.ReAct("question -> answer: float", tools=[evaluate_math, search_wikipedia])

        pred = react(question="What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle?")
        print(pred.answer)
        ```
        
        **可能的输出:**

        ```text
        5761.328
        ```


## 我如何将多个模块组合成一个更大的程序？

DSPy 只是使用模块的 Python 代码，你可以使用任何你喜欢的控制流，只是在 `compile` 时内部有一些魔法来跟踪你的 LM 调用。这意味着，你可以自由地调用模块。

请参阅诸如 [多跳搜索](https://dspy.ai/tutorials/multihop_search/) 之类的教程，其模块如下例所示。

```python linenums="1"        
class Hop(dspy.Module):
    def __init__(self, num_docs=10, num_hops=4):
        self.num_docs, self.num_hops = num_docs, num_hops
        self.generate_query = dspy.ChainOfThought('claim, notes -> query')
        self.append_notes = dspy.ChainOfThought('claim, notes, context -> new_notes: list[str], titles: list[str]')

    def forward(self, claim: str) -> list[str]:
        notes = []
        titles = []

        for _ in range(self.num_hops):
            query = self.generate_query(claim=claim, notes=notes).query
            context = search(query, k=self.num_docs)
            prediction = self.append_notes(claim=claim, notes=notes, context=context)
            notes.extend(prediction.new_notes)
            titles.extend(prediction.titles)
        
        return dspy.Prediction(notes=notes, titles=list(set(titles)))
```

然后你可以创建自定义模块类 `Hop` 的实例，然后通过 `__call__` 方法调用它：

```
hop = Hop()
print(hop(claim="Stephen Curry is the best 3 pointer shooter ever in the human history"))
```

## 我如何跟踪 LM 的使用情况？

!!! note "版本要求"
    LM 使用情况跟踪在 DSPy 版本 2.6.16 及更高版本中可用。

DSPy 提供了跨所有模块调用跟踪语言模型使用情况的内置功能。要启用跟踪：

```python
dspy.configure(track_usage=True)
```

启用后，你可以从任何 `dspy.Prediction` 对象访问使用情况统计信息：

```python
usage = prediction_instance.get_lm_usage()
```

使用数据作为字典返回，该字典将每个语言模型名称映射到其使用情况统计信息。这是一个完整的示例：

```python
import dspy

# 配置 DSPy 启用跟踪
dspy.configure(
    lm=dspy.LM("openai/gpt-4o-mini", cache=False),
    track_usage=True
)

# 定义一个进行多次 LM 调用的简单程序
class MyProgram(dspy.Module):
    def __init__(self):
        self.predict1 = dspy.ChainOfThought("question -> answer")
        self.predict2 = dspy.ChainOfThought("question, answer -> score")

    def __call__(self, question: str) -> str:
        answer = self.predict1(question=question)
        score = self.predict2(question=question, answer=answer)
        return score

# 运行程序并检查使用情况
program = MyProgram()
output = program(question="What is the capital of France?")
print(output.get_lm_usage())
```

这将输出类似以下的使用情况统计信息：

```python
{
    'openai/gpt-4o-mini': {
        'completion_tokens': 61,
        'prompt_tokens': 260,
        'total_tokens': 321,
        'completion_tokens_details': {
            'accepted_prediction_tokens': 0,
            'audio_tokens': 0,
            'reasoning_tokens': 0,
            'rejected_prediction_tokens': 0,
            'text_tokens': None
        },
        'prompt_tokens_details': {
            'audio_tokens': 0,
            'cached_tokens': 0,
            'text_tokens': None,
            'image_tokens': None
        }
    }
}
```

当使用 DSPy 的缓存功能（无论是内存中还是通过 litellm 在磁盘上）时，缓存的响应不会计入使用情况统计信息。例如：

```python
# 启用缓存
dspy.configure(
    lm=dspy.LM("openai/gpt-4o-mini", cache=True),
    track_usage=True
)

program = MyProgram()

# 第一次调用 - 将显示使用情况统计信息
output = program(question="What is the capital of Zambia?")
print(output.get_lm_usage())  # 显示令牌使用情况

# 第二次调用 - 相同的问题，将使用缓存
output = program(question="What is the capital of Zambia?")
print(output.get_lm_usage())  # 显示空字典: {}
```