想象一下，你有一个骰子，每个面出现的概率都是 1/6——这就是**均匀分布**。但现实世界中很多现象不是这样的：大多数人的身高在平均值附近，特别高或特别矮的人很少。这种"中间多、两边少"的分布就是**正态分布**（也叫高斯分布或钟形曲线）。

**标准正态分布**是正态分布的一种特殊形式：
- 平均值（均值）= 0
- 分散程度（标准差）= 1

计算机天生只会生成"公平骰子"式的均匀随机数。那么问题来了：**如何让计算机生成符合正态分布的随机数呢？**

答案就是**Box-Muller 变换**——一种把"公平骰子"变成"钟形曲线"的数学魔法。

## 为什么需要它？

在机器学习和深度学习中，我们经常需要正态分布的随机数：

| 应用场景 | 为什么需要正态分布 |
|---------|------------------|
| **神经网络权重初始化** | 让模型从"中庸"的起点开始学习，避免一开始就"偏激" |
| **数据增强** | 给图片添加自然的噪点，让模型更robust |
| **蒙特卡洛模拟** | 模拟股票价格、天气变化等自然现象 |
| **变分自编码器(VAE)** | 在潜在空间中采样，生成新内容 |

## 直觉理解 Box-Muller 变换

### 飞镖比喻

想象你蒙着眼睛往靶心扔飞镖：

1. **均匀随机**：你随机选一个角度（0° 到 360°），再随机选一个力度
2. **神奇的转换**：如果用特殊的方式选择力度（不是均匀的，而是"对数变换"后的），飞镖落点在 X 轴和 Y 轴的分布就神奇地变成了正态分布！

这就是 Box-Muller 的核心思想：**极坐标系统中的巧妙变换**。

### 数学公式（简化版）

给定两个 (0,1) 之间的均匀随机数 U₁ 和 U₂：

```
Z₀ = √(-2 × ln(U₁)) × cos(2π × U₂)
Z₁ = √(-2 × ln(U₁)) × sin(2π × U₂)
```

**一次变换，两个正态分布随机数！** 就像买一送一。

### 为什么这样有效？

用一个简化的类比：

1. `2π × U₂` 生成了 0 到 360° 的随机角度（像转轮盘）
2. `√(-2 × ln(U₁))` 生成了符合特殊分布的"半径"
3. 通过 cos 和 sin，把极坐标转换为直角坐标
4. 数学上可以证明，这两个直角坐标恰好独立且服从标准正态分布

## PyTorch 实战

### torch.randn - 最简单的方式

```python
import torch

# 生成 5 个标准正态分布随机数
z = torch.randn(5)
print(z)  # 类似: tensor([-0.3623,  1.2315, -0.8472,  0.1236,  1.9823])

# 生成 3x4 的随机矩阵
matrix = torch.randn(3, 4)
```

### 验证它确实是正态分布

```python
# 生成大量样本
samples = torch.randn(100000)

# 检查统计特性
print(f"均值: {samples.mean():.4f}")  # 应该接近 0
print(f"标准差: {samples.std():.4f}")  # 应该接近 1
```

### 调整均值和标准差

标准正态分布的数可以轻松转换为任意正态分布：

```python
mean = 10      # 想要的均值
std = 2        # 想要的标准差

# 公式: X = Z × std + mean
custom_normal = torch.randn(1000) * std + mean
print(f"均值: {custom_normal.mean():.2f}")  # 接近 10
print(f"标准差: {custom_normal.std():.2f}")  # 接近 2
```

## 实际应用示例

### 1. 神经网络权重初始化

```python
import torch.nn as nn

# 创建一个简单的全连接层
layer = nn.Linear(100, 50)

# 用正态分布初始化权重
nn.init.normal_(layer.weight, mean=0, std=0.01)
```

### 2. 给图片添加高斯噪声

```python
def add_gaussian_noise(image, std=0.1):
    """给图片添加正态分布的噪声"""
    noise = torch.randn_like(image) * std
    return image + noise
```

### 3. 随机梯度下降中的噪声注入

```python
# 在训练中注入少量噪声，可能帮助跳出局部最优
gradient = gradient + torch.randn_like(gradient) * noise_scale
```

## 常见问题

### Q: torch.rand 和 torch.randn 有什么区别？

| 函数 | 分布类型 | 取值范围 |
|------|---------|---------|
| `torch.rand` | 均匀分布 | [0, 1) |
| `torch.randn` | 标准正态分布 | (-∞, +∞)，但 99.7% 在 [-3, 3] |

### Q: 为什么叫"标准"正态分布？

因为它是正态分布的"标准形式"——均值为0，标准差为1。就像"标准单位"一样，任何正态分布都可以通过简单变换转换为标准正态分布。

### Q: 生成的随机数会有极端值吗？

会，但非常罕见。理论上可以生成任意大或任意小的值，但：
- 约 68% 的值在 [-1, 1] 之间
- 约 95% 的值在 [-2, 2] 之间
- 约 99.7% 的值在 [-3, 3] 之间

超过 ±6 的值在实践中几乎不会出现。

## 小结

- **标准正态分布随机数**是机器学习的基础工具
- **Box-Muller 变换**是把均匀分布转换为正态分布的经典算法
- PyTorch 的 `torch.randn` 已经帮你封装好了一切
- 通过简单的线性变换，可以生成任意均值和标准差的正态分布

下次当你看到 `torch.randn` 时，你就知道它背后的数学魔法了！

## 参考资料

- [Box–Muller transform - Wikipedia](https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform)
- [The Box-Muller Algorithm - Cupcake Physics](https://cupcakephysics.com/computational%20physics/2015/05/10/the-box-muller-algorithm.html)
- [Box Muller Transform: Simple Definition - Statistics How To](https://www.statisticshowto.com/box-muller-transform-simple-definition/)
- [Demystifying random numbers – Box-Muller Method - The Craft of Coding](https://craftofcoding.wordpress.com/2021/07/06/demystifying-random-numbers-box-muller-method/)
