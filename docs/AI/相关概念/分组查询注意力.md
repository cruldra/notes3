# åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› (Grouped Query Attention, GQA)

> **ä¸€å¥è¯è§£é‡Š**ï¼šGQA æ˜¯ä¸€ç§è®© AI æ¨¡å‹â€œæ—¢è·‘å¾—å¿«ï¼Œåˆè®°å¾—å‡†â€çš„ä¼˜åŒ–æŠ€æœ¯ã€‚å®ƒæ˜¯ä¼ ç»Ÿçš„â€œå¤šå¤´æ³¨æ„åŠ› (MHA)â€å’Œæè‡´çœæµçš„â€œå¤šæŸ¥è¯¢æ³¨æ„åŠ› (MQA)â€ä¹‹é—´çš„å®Œç¾æŠ˜ä¸­æ–¹æ¡ˆã€‚

---

## 1. ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ(ç—›ç‚¹)

åœ¨ ChatGPTã€Llama ç­‰å¤§æ¨¡å‹ä¸­ï¼Œæœ€æ ¸å¿ƒçš„ç»„ä»¶å«â€œæ³¨æ„åŠ›æœºåˆ¶ (Attention)â€ã€‚ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆ AI çš„â€œçœ¼ç›â€ï¼Œç”¨æ¥åœ¨è¯»ä¸€æ®µè¯æ—¶ï¼Œå…³æ³¨é‚£äº›é‡è¦çš„è¯ã€‚

ä½†åœ¨å¤§æ¨¡å‹æ¨ç†ï¼ˆå°¤å…¶æ˜¯ç”Ÿæˆé•¿æ–‡æœ¬ï¼‰æ—¶ï¼Œæœ‰ä¸€ä¸ªå·¨å¤§çš„ç“¶é¢ˆï¼š**æ˜¾å­˜ä¸å¤Ÿç”¨**ã€‚

*   **KV Cache çˆ†ç‚¸**ï¼šæ¨¡å‹ä¸ºäº†è®°ä½ä¹‹å‰çš„å¯¹è¯ï¼Œéœ€è¦æŠŠè®¡ç®—è¿‡çš„â€œè®°å¿†â€ï¼ˆKey å’Œ Value çŸ©é˜µï¼‰å­˜èµ·æ¥ã€‚è¿™ä¸ªç¼“å­˜ï¼ˆKV Cacheï¼‰éå¸¸å å†…å­˜ã€‚
*   **æ¬è¿å¤ªæ…¢**ï¼šæ˜¾å¡è®¡ç®—é€Ÿåº¦å¾ˆå¿«ï¼Œä½†æŠŠè¿™äº›å·¨å¤§çš„è®°å¿†æ•°æ®ä»æ˜¾å­˜æ¬åˆ°è®¡ç®—æ ¸å¿ƒä¸Šå¾ˆæ…¢ï¼ˆå†…å­˜å¸¦å®½å¢™ï¼‰ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç§‘å­¦å®¶ä»¬æƒ³å‡ºäº†ä¸åŒçš„â€œæ³¨æ„åŠ›â€ç®¡ç†åŠæ³•ã€‚

## 2. æ ¸å¿ƒåŸç†ï¼šé€šä¿—æ¯”å–»

æˆ‘ä»¬å¯ä»¥æŠŠ AI å¤„ç†ä¿¡æ¯çš„è¿‡ç¨‹æ¯”ä½œ**â€œå›¾ä¹¦é¦†æŸ¥èµ„æ–™â€**ï¼Œæˆ–è€…æ›´ç®€å•ç‚¹ï¼Œ**â€œé¤å…ç‚¹é¤â€**ã€‚

å‡è®¾æœ‰ 8 ä½é¡¾å®¢ï¼ˆQuery Headsï¼ŒæŸ¥è¯¢å¤´ï¼‰åŒæ—¶è¿›åº—ç‚¹é¤ã€‚

### æ–¹æ¡ˆ Aï¼šå¤šå¤´æ³¨æ„åŠ› (MHA, Multi-Head Attention) â€”â€” è±ªåä½†æ˜‚è´µ
*   **åšæ³•**ï¼šç»™è¿™ 8 ä½é¡¾å®¢ï¼Œ**æ¯äººé… 1 åä¸“å±æœåŠ¡å‘˜**ï¼ˆKey/Value Headsï¼‰ã€‚ä¸€å…±éœ€è¦ 8 åæœåŠ¡å‘˜ã€‚
*   **ä¼˜ç‚¹**ï¼šæœåŠ¡è¶…çº§ç²¾ç»†ï¼Œæ¯ä½é¡¾å®¢çš„éœ€æ±‚éƒ½èƒ½è¢«ç‹¬ç«‹ã€å®Œç¾åœ°ç…§é¡¾ã€‚AI æœ€èªæ˜ã€‚
*   **ç¼ºç‚¹**ï¼š**å¤ªå èµ„æºäº†ï¼** é¤å…ï¼ˆæ˜¾å­˜ï¼‰é‡Œå…¨æ˜¯æœåŠ¡å‘˜ï¼ŒæŒ¤å¾—æ°´æ³„ä¸é€šï¼Œå¼€é”€å·¨å¤§ã€‚

### æ–¹æ¡ˆ Bï¼šå¤šæŸ¥è¯¢æ³¨æ„åŠ› (MQA, Multi-Query Attention) â€”â€” çœé’±ä½†ç²—ç³™
*   **åšæ³•**ï¼š8 ä½é¡¾å®¢ï¼Œ**åªé… 1 åæœåŠ¡å‘˜**ã€‚è¿™åæœåŠ¡å‘˜è¦åŒæ—¶æ‹¿è¿™ 1 å¥—èœå•ï¼ˆKey/Valueï¼‰æœåŠ¡æ‰€æœ‰äººã€‚
*   **ä¼˜ç‚¹**ï¼š**è¶…çº§çœèµ„æº**ï¼Œé€Ÿåº¦é£å¿«ã€‚
*   **ç¼ºç‚¹**ï¼š**å®¹æ˜“ææ··**ã€‚æœåŠ¡å‘˜åˆ†èº«ä¹æœ¯ï¼Œç»†èŠ‚ç…§é¡¾ä¸åˆ°ä½ï¼ŒAI çš„è¡¨ç°ä¼šå˜å·®ï¼ˆæ¯”å¦‚é€»è¾‘å˜ç³Šæ¶‚ï¼‰ã€‚

### æ–¹æ¡ˆ Cï¼šåˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ› (GQA, Grouped Query Attention) â€”â€” å®Œç¾å¹³è¡¡
*   **åšæ³•**ï¼šæŠ˜ä¸­ä¸€ä¸‹ï¼æŠŠ 8 ä½é¡¾å®¢åˆ†æˆ **4 ä¸ªå°ç»„**ï¼Œæ¯ç»„ 2 äººã€‚**æ¯ç»„é… 1 åæœåŠ¡å‘˜**ã€‚ä¸€å…±åªéœ€è¦ 4 åæœåŠ¡å‘˜ã€‚
*   **ä¼˜ç‚¹**ï¼š
    1.  **çœäº†ä¸€åŠèµ„æº**ï¼šæœåŠ¡å‘˜æ•°é‡ä» 8 ä¸ªå‡åˆ° 4 ä¸ªï¼ˆæ˜¾å­˜å ç”¨å¤§å‡ï¼‰ã€‚
    2.  **æœåŠ¡ä¾ç„¶å¾ˆå¥½**ï¼šæ¯ä½æœåŠ¡å‘˜åªç…§é¡¾ 2 äººï¼Œæ¯”ç…§é¡¾ 8 äººä»å®¹å¾—å¤šï¼ŒæœåŠ¡è´¨é‡ï¼ˆAI æ™ºåŠ›ï¼‰å‡ ä¹ä¸ä¸‹é™ã€‚

---

## 3. æŠ€æœ¯ç»†èŠ‚ (ç¨å¾®ä¸“ä¸šä¸€ç‚¹ç‚¹)

åœ¨æŠ€æœ¯å®ç°ä¸Šï¼ŒGQA è°ƒæ•´äº† Query (Q) å’Œ Key-Value (KV) å¤´çš„æ¯”ä¾‹ï¼š

*   **MHA (Multi-Head)**: $N$ ä¸ª Q å¤´ï¼Œé… $N$ ä¸ª KV å¤´ã€‚æ¯”ä¾‹ 1:1ã€‚
*   **MQA (Multi-Query)**: $N$ ä¸ª Q å¤´ï¼Œé… $1$ ä¸ª KV å¤´ã€‚æ¯”ä¾‹ N:1ã€‚
*   **GQA (Grouped-Query)**: $N$ ä¸ª Q å¤´ï¼Œé… $G$ ä¸ª KV å¤´ï¼ˆä¾‹å¦‚ $G=N/2$ æˆ– $N/8$ï¼‰ã€‚æ¯”ä¾‹ N:Gã€‚

**å…³é”®æ­¥éª¤ï¼š**
åœ¨è®¡ç®—æ—¶ï¼Œä¸ºäº†è®©çŸ©é˜µç»´åº¦åŒ¹é…ï¼ŒGQA ä¼šæŠŠé‚£å°‘é‡çš„ KV å¤´è¿›è¡Œ**å¤åˆ¶ (Repeat)**ï¼Œè®©å®ƒä»¬åœ¨æ•°é‡ä¸Šçœ‹èµ·æ¥å’Œ Q å¤´ä¸€æ ·å¤šï¼Œç„¶åå†è¿›è¡Œè®¡ç®—ã€‚

> *æ³¨ï¼šè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆä½ åœ¨ä»£ç ä¸­çœ‹åˆ°äº† `repeat_kv` è¿™ä¸ªå‡½æ•°ã€‚*

## 4. è°åœ¨ç”¨ GQAï¼Ÿ

ç°åœ¨æœ€å…ˆè¿›çš„å¼€æºå¤§æ¨¡å‹å‡ ä¹éƒ½åœ¨ç”¨ GQAï¼Œå› ä¸ºå®ƒæ€§ä»·æ¯”æœ€é«˜ï¼š

*   **Llama 2 (70B) & Llama 3**ï¼šMeta çš„å½“å®¶æ¨¡å‹ã€‚
*   **Mistral 7B**ï¼šè‘—åçš„â€œä»¥å°åšå¤§â€æ¨¡å‹ã€‚
*   **DeepSeek**ï¼šæ·±åº¦æ±‚ç´¢ç³»åˆ—æ¨¡å‹ã€‚

## 5. æ€»ç»“

| ç‰¹æ€§ | MHA (ä¼ ç»Ÿ) | MQA (æè‡´) | **GQA (ä¸»æµ)** |
| :--- | :--- | :--- | :--- |
| **æ˜¾å­˜å ç”¨** | ğŸŸ¥ æå¤§ | ğŸŸ© æå° | **ğŸŸ¨ é€‚ä¸­ (å¾ˆå°)** |
| **æ¨ç†é€Ÿåº¦** | ğŸŸ¥ æ…¢ | ğŸŸ© å¿« | **ğŸŸ© å¿«** |
| **æ¨¡å‹æ•ˆæœ** | ğŸŸ© æœ€å¥½ | ğŸŸ¨ ç•¥å·® | **ğŸŸ© æ¥è¿‘æœ€å¥½** |
| **æ¯”å–»** | 1å¯¹1ä¸“å±æœåŠ¡ | 1å¯¹å¤šå¤§é”…é¥­ | **å°ç»„åˆ¶æœåŠ¡** |

GQA å°±æ˜¯**â€œç”¨å°‘é‡çš„ç²¾åº¦ç‰ºç‰²ï¼Œæ¢å–å·¨å¤§çš„é€Ÿåº¦å’Œæ˜¾å­˜æå‡â€**ï¼Œæ˜¯ç°ä»£å¤§æ¨¡å‹é™æœ¬å¢æ•ˆçš„å¿…å¤‡ç¥å™¨ã€‚

---

## å‚è€ƒèµ„æ–™

1.  [IBM: What is grouped query attention (GQA)?](https://www.ibm.com/think/topics/grouped-query-attention)
2.  [Clarifai: LLM Inference Optimization Techniques](https://www.clarifai.com/blog/llm-inference-optimization/)
3.  [Medium: Navigating the Attention Landscape: MHA, MQA, and GQA Decoded](https://iamshobhitagarwal.medium.com/navigating-the-attention-landscape-mha-mqa-and-gqa-decoded-288217d0a7d1)
4.  [Medium: Attention Mechanisms Made Easy](https://medium.com/@tariqh2388/attention-mechanisms-made-easy-understanding-mha-mqa-and-gqa-with-simple-examples-20b486cd8ea3)
