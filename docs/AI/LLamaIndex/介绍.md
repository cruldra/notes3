LlamaIndex 是一个领先的框架，用于利用 [LLM](https://en.wikipedia.org/wiki/Large_language_model) 和工作流基于您的数据构建 LLM 驱动的智能体。

### 什么是智能体？

智能体是由 LLM 驱动的知识助手，利用工具执行研究、数据提取等任务。智能体的范围从简单的问答系统到能够感知、决策并采取行动以完成任务的复杂系统。

LlamaIndex 提供了一个构建智能体的框架，包括将 RAG 管道作为众多工具之一来完成任务的能力。

### 什么是工作流？

工作流是多步骤过程，结合了一个或多个智能体、数据连接器和其他工具来完成任务。它们是事件驱动的软件，允许您结合 RAG 数据源和多个智能体来创建一个复杂的应用程序，能够执行各种任务，具有反思、纠错和其他高级 LLM 应用程序的特征。您可以随后将这些智能体工作流部署为生产微服务。

### 什么是上下文增强？

LLM 提供了一种人类与数据之间的自然语言接口。LLM 在大量公开可用数据上进行了预训练，但并未在**您的**数据上进行训练。您的数据可能是私有的，或者特定于您试图解决的问题。它可能位于 API 背后、SQL 数据库中，或者被困在 PDF 和幻灯片中。

上下文增强使您的数据可用于 LLM 以解决手头的问题。LlamaIndex 提供了构建任何上下文增强用例的工具，从原型到生产。我们的工具允许您摄取、解析、索引和处理数据，并快速实现结合数据访问与 LLM 提示的复杂查询工作流。

上下文增强最流行的例子是检索增强生成或 RAG，它在推理时将上下文与 LLM 相结合。

### LlamaIndex 是上下文增强 LLM 应用程序的框架

LlamaIndex 对您如何使用 LLM 不施加任何限制。您可以将 LLM 用作自动补全、聊天机器人、智能体等。它只是让使用它们变得更容易。我们提供的工具包括：

* **数据连接器**：从原生源和格式摄取您现有的数据。这些可以是 API、PDF、SQL 等（更多）。
* **数据索引**：将您的数据结构化为中间表示，以便 LLM 能够轻松且高性能地使用。
* **引擎**：提供对数据的自然语言访问。例如：
  + 查询引擎是用于问答的强大接口（例如 RAG 流程）。
  + 聊天引擎是用于与数据进行多轮、“来回”交互的对话接口。
* **智能体**：由 LLM 驱动的知识工作者，通过工具进行增强，从简单的辅助函数到 API 集成等。
* **可观测性/评估**：集成使您能够在良性循环中严格实验、评估和监控您的应用程序。
* **工作流**：允许您将上述所有内容组合成一个事件驱动的系统，比其他基于图的方法更加灵活。

## 用例

LlamaIndex 和上下文增强的一些流行用例包括：

* 问答（检索增强生成，即 RAG）
* 聊天机器人
* 文档理解和数据提取
* 自主智能体，可以执行研究并采取行动
* 多模态应用程序，结合文本、图像和其他数据类型
* 微调模型以提高性能

查看我们的用例文档以获取更多示例和教程链接。

### 👨‍👩‍👧‍👦 LlamaIndex 适合谁？

LlamaIndex 为初学者、高级用户以及介于两者之间的每个人提供工具。

我们的高级 API 允许初学者用户仅用 5 行代码即可使用 LlamaIndex 摄取和查询其数据。

对于更复杂的应用程序，我们的低级 API 允许高级用户自定义和扩展任何模块——数据连接器、索引、检索器、查询引擎和重排序模块——以满足他们的需求。

## 入门

LlamaIndex 提供 Python（本文档）和 [Typescript](https://ts.llamaindex.ai/) 版本。如果您不确定从哪里开始，我们建议阅读如何阅读这些文档，它将根据您的经验水平为您指明正确的方向。

### 30 秒快速入门

使用 [OpenAI API 密钥](https://platform.openai.com/api-keys)设置一个名为 `OPENAI_API_KEY` 的环境变量。安装 Python 库：

终端窗口

```

pip install llama-index

```

将一些文档放入名为 `data` 的文件夹中，然后使用我们著名的 5 行入门代码询问有关它们的问题：

```

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

documents = SimpleDirectoryReader("data").load_data()

index = VectorStoreIndex.from_documents(documents)

query_engine = index.as_query_engine()

response = query_engine.query("Some question about the data should go here")

print(response)

```

如果其中任何部分让您感到困惑，请不要担心！查看我们更全面的入门教程，使用远程 API 如 OpenAI 或任何在您笔记本电脑上运行的模型。

## LlamaCloud

如果您是一名企业开发人员，请查看 [**LlamaCloud**](https://llamaindex.ai/enterprise)。这是一项用于文档解析、提取、索引和检索的端到端托管服务 - 允许您为 AI 智能体获取生产级质量的数据。您可以[注册](https://cloud.llamaindex.ai/)并每月获得 10,000 个免费积分，注册我们的[计划](https://www.llamaindex.ai/pricing)之一，或者如果您对企业解决方案感兴趣，请[联系我们](https://www.llamaindex.ai/contact)。我们提供 SaaS 和自托管计划。

您还可以查看 [LlamaCloud 文档](https://docs.cloud.llamaindex.ai/)以了解更多详情。

* **文档解析 (LlamaParse)**：LlamaParse 是一流的文档解析解决方案。它由 VLM 驱动，非常适合处理即使是最复杂的文档（嵌套表格、嵌入的图表/图像等）。[了解更多](https://www.llamaindex.ai/llamaparse) 或查看 [文档](https://docs.cloud.llamaindex.ai/llamaparse)。
* **文档提取 (LlamaExtract)**：给定人工定义或推断的模式，从任何文档中提取结构化数据。[了解更多](https://www.llamaindex.ai/llamaextract) 或查看 [文档](https://docs.cloud.llamaindex.ai/llamaextract/getting_started)。
* **索引/检索**：设置端到端管道以索引文档集合进行检索。连接您的数据源（例如 Sharepoint、Google Drive、S3）、您的向量数据库数据接收器，我们会自动处理文档处理和同步。[了解更多](https://www.llamaindex.ai/enterprise) 或查看 [文档](https://docs.cloud.llamaindex.ai/llamacloud/getting_started)。

## 社区

需要帮助？有功能建议？加入 LlamaIndex 社区：

* [Twitter](https://twitter.com/llama_index)
* [Discord](https://discord.gg/dGcwcsnxhU)
* [LinkedIn](https://www.linkedin.com/company/llamaindex/)

### 获取库

* LlamaIndex Python
  + [LlamaIndex Python Github](https://github.com/run-llama/llama_index)
  + [Python 文档](https://docs.llamaindex.ai/)（您正在阅读的内容）
  + [PyPi 上的 LlamaIndex](https://pypi.org/project/llama-index/)
* LlamaIndex.TS (Typescript/Javascript 包)：
  + [LlamaIndex.TS Github](https://github.com/run-llama/LlamaIndexTS)
  + [TypeScript 文档](https://ts.llamaindex.ai/)
  + [npm 上的 LlamaIndex.TS](https://www.npmjs.com/package/llamaindex)

### 贡献

我们是开源的，随时欢迎对项目的贡献！查看我们的[贡献指南](https://github.com/run-llama/llama_index/blob/main/CONTRIBUTING.md)，了解有关如何扩展核心库或添加与第三方（如 LLM、向量存储、智能体工具等）集成的详细信息。

## LlamaIndex 生态系统

LlamaIndex 宇宙还有更多内容！查看我们的一些其他项目：

* [llama\_deploy](https://github.com/run-llama/llama_deploy) | 将您的智能体工作流部署为生产微服务
* [LlamaHub](https://llamahub.ai) | 一个庞大（且不断增长！）的自定义数据连接器集合
* [SEC Insights](https://secinsights.ai) | 一个由 LlamaIndex 驱动的金融研究应用程序
* [create-llama](https://www.npmjs.com/package/create-llama) | 一个用于快速搭建 LlamaIndex 项目的 CLI 工具
